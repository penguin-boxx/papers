%! suppress = MissingLabel
%%
%% This is file `effect-system-synergy.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,journal,bibtex,acmsmall')
%%
%% IMPORTANT NOTICE:
%%
%% For the copyright see the source file.
%%
%% Any modified versions of this file must be renamed
%% with new filenames distinct from effect-system-synergy.tex.
%%
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%%
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[acmsmall]{acmart}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
%\AtBeginDocument{%
%    \providecommand\BibTeX{{%
%        Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
%\setcopyright{acmlicensed}
%\copyrightyear{2026}
%\acmYear{2026}
%\acmDOI{XXXXXXX.XXXXXXX}

%%
%% These commands are for a JOURNAL article.
%\acmJournal{JACM}
%\acmVolume{37}
%\acmNumber{4}
%\acmArticle{111}
%\acmMonth{1}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

% Line numbers
% https://tex.stackexchange.com/questions/16010/number-every-line-of-pages
\usepackage{lineno}
\usepackage{mathtools}
\linenumbers
% ------------------------------------------------

\usepackage{multicol}
\usepackage{minted}
\setminted{xleftmargin=\parindent, autogobble, escapeinside=\#\#, numberblanklines=false, fontsize=\small} % todo use lstlisting instead with custom keywords
\usepackage{proof}
\usepackage[inference]{semantic}

\newcommand{\graybox}[1]{\colorbox{lightgray}{$\displaystyle #1$}}
\newcommand{\mathframebox}[1]{\framebox{$\displaystyle #1$}}
\newcommand{\vor}{~|~}
\newcommand{\ap}{~}
\newcommand{\ctx}[1]{ctx(#1)~}
\newcommand{\step}{\rightsquigarrow}
\newcommand{\local}{\top}
\newcommand{\free}{\bot}
\newcommand{\keyword}[1]{\mathbf{#1}}
\newcommand{\identation}{\text{\hspace{2em}}}

%%
%% end of the preamble, start of the body of the document source.
%! suppress = TooLargeSection
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{One Plus One: Effect System as a Synergy of Implicit Parameters and Type-Based Escape Analysis}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
%\author{Ben Trovato}
%\authornote{Both authors contributed equally to this research.}
%\email{trovato@corporation.com}
%\orcid{1234-5678-9012}
%\author{G.K.M. Tobin}
%\authornotemark[1]
%\email{webmaster@marysville-ohio.com}
%\affiliation{%
%    \institution{Institute for Clarity in Documentation}
%    \city{Dublin}
%    \state{Ohio}
%    \country{USA}
%}
%
%\author{Lars Th{\o}rv{\"a}ld}
%\affiliation{%
%    \institution{The Th{\o}rv{\"a}ld Group}
%    \city{Hekla}
%    \country{Iceland}}
%\email{larst@affiliation.org}
%
%\author{Valerie B\'eranger}
%\affiliation{%
%    \institution{Inria Paris-Rocquencourt}
%    \city{Rocquencourt}
%    \country{France}
%}
%
%\author{Aparna Patel}
%\affiliation{%
%    \institution{Rajiv Gandhi University}
%    \city{Doimukh}
%    \state{Arunachal Pradesh}
%    \country{India}}

\author{Andrey Stoyan}
\affiliation{%
    \institution{HSE University}
    \city{Saint Petersburg}
    \country{Russian Federation}}
\email{a.stoyan@hse.ru}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
%\renewcommand{\shortauthors}{Surname et al.}
\renewcommand{\shortauthors}{Andrey Stoyan}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
    Effects are a tool for managing code complexity.
    Some responsibilities can be delegated to a context, while a computation just interacts with it (i.e.\ performs effects), concentrating on other aspects of logic.
    Effect systems bring information about a program's effects to the type level, which makes abstraction boundaries clearer and context validity statically verifiable.
    Unfortunately, effect systems still lack mainstream adoption due to alien design and general unfamiliarity of practitioners with the concept.

    In this paper, we propose a perspective on effect system design as a combination of two properly-designed language features: implicit parameters and type-based escape analysis.
    We believe that both of them are naturally achievable in mainstream languages, familiar to practitioners and useful by themselves.
    We motivate our approach by considering effect systems as systems for tracking free variables.
    We discuss requirements on an implicit parameters design and provide a formal example.
    We also present a novel type-based escape analysis technique that only requires straight-forward dataflow descriptions from a programmer. % todo is it correct to talk about dataflow here?
    Finally, we provide a formal calculus with an effect system built upon these two pieces. % todo adapt
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
%    \begin{CCSXML}
%        <ccs2012>
%        <concept>
%        <concept_id>00000000.0000000.0000000</concept_id>
%        <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%        <concept_significance>500</concept_significance>
%        </concept>
%        <concept>
%        <concept_id>00000000.00000000.00000000</concept_id>
%        <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%        <concept_significance>300</concept_significance>
%        </concept>
%        <concept>
%        <concept_id>00000000.00000000.00000000</concept_id>
%        <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%        <concept_significance>100</concept_significance>
%        </concept>
%        <concept>
%        <concept_id>00000000.00000000.00000000</concept_id>
%        <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%        <concept_significance>100</concept_significance>
%        </concept>
%        </ccs2012>
%    \end{CCSXML}

%\ccsdesc[500]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
%\ccsdesc[300]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
%\ccsdesc{Do Not Use This Code~Generate the Correct Terms for Your Paper}
%\ccsdesc[100]{Do Not Use This Code~Generate the Correct Terms for Your Paper}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{static analysis, type systems, effects, capabilities}

%\received{10 July 2025}
%\received[revised]{12 March 2009}
%\received[accepted]{5 June 2009} todo

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle


\section{Introduction} \label{sec:intro}

% Introducton makes claims, all of them should be supported later.

The art of programming is a lot about managing complexity to be able to focus in a particular piece of code on a limited fragment of behaviour.
Helpful tools here are abstraction and separation of concerns: we delegate some responsibilities to different program entities (e.g.\ functions, modules, etc.).
In many cases, such an entity can be abstractly called \textit{execution context} of a computation, and effects arise naturally here as an interactions of a computation with that context~\cite{kiselyov2013extensible}.

An execution context can be distinguished by at least one of the following properties:
\begin{enumerate}
    \item An act of interaction with it is observable.
    For example, a language memory management subsystem can be considered as such a context: an allocation affects addresses of subsequent allocations.
    In that case the context is responsible for memory cells bookkeeping.
    \item A context can have a limited activity scope: only code in a particular scope can communicate with it.
    For example, an exception handler is an execution context that handles exceptions thrown inside a \texttt{try-catch} block.
    Effect of throwing an exception delegates a handler dealing with an exceptional situation.
    Another example is the inversion of control: an execution context is responsible for providing some functionality only to the code in a specific scope, code from the outside of the scope may have different context.
\end{enumerate}

An effect system reflects effects of a computation on the type level.
It serves two main purposes.
Firstly, it makes effects visible in a type signature, so functional abstraction boundaries become more precise: implementation details will not leak unnoticed as context interactions.
Secondly, an effect system statically controls \textit{effect safety} of a computation use: it should be executed in an appropriate context (as we discussed before, contexts may have limited activity scopes).
For instance, it is a responsibility of an effect system to check whether all functionality requested by the inversion of control will be provided, and all exceptions will be handled.
Note that effect systems may track more information of interest, for example, about divergence.

Many promising designs of effect systems were proposed: row-polymorphic types~\cite{leijen2014koka}, capabilities and contextual polymorphism~\cite{brachthauser2022effects, boruch2023capturing}, modal types~\cite{tang2025modal}, etc.
However, all of them have pros and cons, and overall design space configuration remains unclear.
At the same time we think that it is useful for language designers to see the whole space and freely choose the most suitable point in it, considering specific language characteristics and limitations.

In this paper we argue that effect systems can be understood as a combination of two more simple and grounded language features: implicit parameters and type-based escape analysis.
This understanding from one hand places axis on the effect system design space: different points in it can be chosen by varying designs of these two features.
And from another hand, it can help to smoothly incorporate an effect system into existing mainstream languages, since many of them have at least one of these features, which are quite useful by themselves.

The general idea we present is not new.
For example, recent work in the Scala programming language bases on similar observations~\cite{odersky2021safer, boruch2023capturing}.
However, we phrase the idea explicitly, investigate its consequences and use its inspiration to build a novel practical though minimalistic effect system.

% рассматриваем сразу и модели и системы эффектов, потому что делается type-based translation

Contributions of this paper are summarized as follows:

\begin{itemize}
    \item We propose a perspective on effect system design as a combination of two properly-designed language features: implicit parameters and type-based escape analysis; and motivate our approach by looking at effect systems as systems for managing free variables (Section~\ref{sec:idea}).
    \item We describe required properties of implicit parameters design and provide a suitable one using a formal calculi (Section~\ref{sec:implicits}).
    \item We provide a novel type-based escape analysis technique that only requires straight-forward dataflow descriptions from a programmer (Section~\ref{sec:escape}).
    \item We show that our design is appropriate in the object-oriented setting (Section~\ref{sec:mainstream}). % todo расширить скоуп на просто финтифлюшки делающие дизайн более прикладным
%    \item We explore practical subtleties of our design and its applicability to object-oriented programming languages (Section~\ref{sec:mainstream}).
    \item We compare our approach with previous art and show that other designs can be considered in implicit parameters and escape analysis basis (Section~\ref{sec:related}).
\end{itemize}


\section{Two pieces of an effect system design} \label{sec:idea}

In this section we introduce the main idea of this paper using practical examples.
We also demonstrate that the pragmatics of effect systems arise naturally from everyday programming concerns.

\subsection{The road to implicit parameters} \label{subsec:implicits}

Consider our running example (fig.\ \ref{fig:db}), where a business logic function updates a database storage.

The first version opens a database connection by itself and sends it a query.
Note that this code is not convenient for testing, because there is no simple way to substitute some mock database, for instance, to check the logic.
Another drawback is that this function produces observable side effects, which are definitely a part of its public contract, but they are not mentioned in its signature.

The second version is much better.
A business logic function is abstracted over a database connection, so a call site is able to choose an appropriate semantics for it.
Moreover, note that observable effects become explicit through \texttt{db} parameter!
However, this simple approach has a cost of an additional syntactic noise on the call site caused by administrative parameter passing.
It may sound insignificant, but imagine passing four such parameters everywhere through the call stack, whereas good practices should be at least as approachable as suboptimal ones.

To reduce the boilerplate, in the third version we replace ordinary parameters with dynamically scoped free variables, which obtain their meaning by lookup in the dynamic scope of a function call.
At the same time we loose other benefits: static typing and explicitness of context dependence.

\begin{figure}
    \begin{tabular}{p{0.3\textwidth} rrr}
        \begin{minipage}[t]{0.3\textwidth}
            \begin{minted}{swift}
                func business1() {
                    let db = Db.open(...)
                    db.query("update ...")
                }
            \end{minted}
        \end{minipage}
        &
        \begin{minipage}[t]{0.3\textwidth}
            \begin{minted}{swift}
                func business2(db: Db) {
                    db.query("...")
                }

                func caller() {
                    let db = Db.open(...)
                    business2(db)
                }
            \end{minted}
        \end{minipage}
        &
        \begin{minipage}[t]{0.3\textwidth}
            \begin{minted}{swift}
                func business3() {
                    db.query("...")
                }

                func caller() {
                    let db = Db.open(...)
                    business3()
                }
            \end{minted}
        \end{minipage}
    \end{tabular}
    \caption{The road to dynamically scoped free variables.}
    \label{fig:db}
\end{figure}

To reclaim the static type safety, we approximate dynamically scoped free variables with implicit function parameters~\cite{lewis2000implicit}.
On the declaration site we use \texttt{context} keyword to declare a group of implicit parameters, which will be passed on the call site automatically by a compiler (fig.\ \ref{fig:implicits}).
To make a value participate in the resolution of implicit parameters, we use \texttt{context let} declaration syntax.

\begin{figure}[h]
    \begin{tabular}{p{0.5\textwidth} rl}
        \begin{minipage}[t]{0.3\textwidth}
            \begin{minted}{swift}
                context(db: Db)
                func business4() {
                    db.query("...")
                }
            \end{minted}
        \end{minipage}
        &
        \begin{minipage}[t]{0.3\textwidth}
            \begin{minted}{swift}
                func caller() {
                    context let db = Db.open(...)
                    business4()
                }
            \end{minted}
        \end{minipage}
    \end{tabular}
    \caption{Reclaming static type safety with implicit parameters.}
    \label{fig:implicits}
\end{figure}

In terms of effects and contexts, \texttt{context let} creates an execution context limited with the corresponding lexical scope, providing a functionality of a database storage.
Implicit parameters represent the function's requirements for a context.
To be able to call such a function, context should prove its validity by passing some values to these implicit parameters.
We call these values \textit{capabilities}, and logically they serve as witnesses of context validity.
Nevertheless, note that for now we rely only on the notion of bindings and understanding the abstract concept of effects is not strongly required.

Exceptions and other algebraic operations can be tracked in the same manner~\cite{odersky2021safer}.
For example, a \texttt{throw SomeException()} construct can be recognized as an invocation of a function requiring an implicit parameter of \texttt{Handler<SomeException>} type.
At the same time, handling constructs should provide such witness values.
\begin{minted}{swift}
    func checkingExceptions() {
        try { // provides a capability of type Handler<SomeException>
            throw SomeException() // requires a capability of type Handler<SomeException>
        } catch (e: SomeException) { ... }
    }
\end{minted}

Nowadays, some widespread languages have a feature of implicit parameters and their inference is well-understood~\cite{KEEP-context-parameters, oliveira2010type, lewis2000implicit}.
Moreover, implicit parameters are enough as an evidence-passing technique to implement tail-resumptive algebraic operations~\cite{xie2020effect}.

\subsection{Retain effect safety with escape analysis} \label{subsec:escape}

An effect system should ensure that all computations are executed in appropriate contexts (we call this property \textit{effect safety}).
In our case, context should provide capabilities to proof its validity.
Hence, capabilities should not escape corresponding contexts.
For example, if a \texttt{Handler} value can escape a corresponding \texttt{try-catch} block, we loose a guarantee of handling an exception and the effect safety as well:
\begin{minted}{swift}
    func unsafe() {
        let f = try {
            () => throw SomeException() // captures the Handler<SomeException> capability
        } catch (e: SomeException) { ... }
        f() // throws SomeException
    }
\end{minted}

Note that for the lambda function in the example, the \texttt{Handler<SomeException>} capability is the lexically scoped free variable.
An opportunity to close over capabilities support a technique called \textit{contextual polymorphism}~\cite{brachthauser2020effects, brachthauser2022effects}, which allows higher-order functions to be transparent regarding effects without additional polymorphic type variables ranging over effects.
Namely, a \texttt{map} function type should not bother about effects (we will cover \texttt{scoped} syntax later)\footnote{We use Haskell naming convention, where type names starting with a lowercase letter stand for type variables, which are implicitly universally quantified by default.}:
\begin{minted}{swift}
    func map(xs: List<a>, f: #\color{gray}\texttt{scoped}# (a) -> b): List<b>

    context(io: IO)
    func printAll(xs: List<Int>) {
        map(xs, (x) => io.print(x)) // capability capturing is safe here
    }
\end{minted}

Compare with a similar function type from the Koka language, featuring row-polymorphic types~\cite{leijen2014koka}:
\begin{minted}{kotlin}
    fun map(xs: list<a>, f: (a) -> e b): e list<b>
\end{minted}

To control escaping of capabilities, we need some form of escape analysis. % todo citations
Since effect systems operate the type-level, it is natural to use types for escape analysis as well.
Moreover, we need this analysis to be cross-procedural, so it should affect function signatures.
Let us give an informal brief introduction of the type-based escape analysis technique that we feature in this paper.

We call values that should not escape some scope \textit{tracked} (as well as their types).
For instance, capabilities are tracked by default, so are types of implicit parameters.
To distinguish between tracked and non-tracked types, we augment each type $T$ with a special lifetime label $lab$ using a syntax: \[scoped(lab)\ap T\]
Lifetime labels range over \texttt{free}, \texttt{local} and polymorphic lifetime variables.
\texttt{free} lifetime label is used to type non-tracked values.
We assume it by default for every type.
\texttt{local} present in tracked types, and a type system treats \texttt{local} specially to prevent escaping (for instance, a function cannot return a value of a tracked type).
For example, the \texttt{map} function can explicitly declare that it do not leak an argument function (so it is safe to pass it a closure with capabilities):
\begin{minted}{swift}
    func map(xs: List<a>, f: scoped(local) (a) -> b): List<b>
\end{minted}

To allow a function to leak arguments through a result, a polymorphism over lifetimes can be used.
In fact, it is an explicit function's dataflow specification in a signature. % todo dataflow term and citation
For example, a lazy \texttt{map} function instead of eagerly computing a result, immediately returns a collection that remembers required processing inside.
We specify it by assigning the same lifetime variable \texttt{l} to both argument \texttt{f} and a result type.
Such a function still supports contextual polymorphism since it can leak \texttt{f} only with a result and a call site is aware that this result should not escape:
\begin{minted}{swift}
    func lazyMap(xs: LazyList<a>, f: scoped(l) (a) -> b): scoped(l) LazyList<b>

    context(io: IO) // io: scoped(local) IO
    func printAll(xs: LazyList<Int>) {
        let ys: scoped(local) LazyList<Int> = lazyMap(xs, (x) => io.print(x))
        ys.collect() // force execution
    }
\end{minted}

We use intersection of lifetimes to express capturing two or more lifetime-polymorphic values:
\begin{minted}{swift}
    func compose(f: scoped(l1) (b) -> c, g: scoped(l2) (a) -> b): scoped(l1&l2) (a) -> c
        = (x) => f(g(x))
\end{minted}

For the sake of simplicity, we get rid of lifetime polymorphism for compound datatypes by computing their lifetimes as an intersection of component's lifetimes.
Lifetimes of components themselves on destructuring are approximated with a lifetime of a compound datatype.
\begin{minted}{swift}
    func first(x: scoped(l1) Int, y: scoped(l2) Int): scoped(l1&l2) Int {
        let intPair: scoped(l1&l2) IntPair = IntPair(x, y)
        return intPair.fst
    }
\end{minted}

We establish subtyping in a way that non-tracked values can be used in positions where tracked values are expected.
It increases the number of safe well-typed programs and helps in smooth migration for languages with untyped effects to the effect system.

We allow tracked types to instantiate polymorphic type parameters to make them first-class citizens in a language.
To control, whether tracked types can instantiate a type parameter, we use bounded polymorphism.
For example, the \texttt{lazyMap} function do not leak values of polymorphic types, for instance, through global state, but only returns \texttt{b} back to the caller, so they can be instantiated with tracked types\footnote{We assume that \texttt{Any} is a top of types lattice.}\footnote{To preserve backward compatibility, \texttt{scoped(free) Any} type can be used as a default bound.}:
\begin{minted}{swift}
    func lazyMap(xs: LazyList<a>, f: scoped(l) (a) -> b): scoped(l) LazyList<b>
        where a <: scoped(local) Any, b <: scoped(local) Any
\end{minted}

Various techniques can be used to reduce boilerplate related to the lifetime polymorphism and specification of bounds.
For example, the lifetime elision from the Rust language~\cite{matsakis2014rust} uses heuristics to automatically place lifetime variables (we use \texttt{scoped} keyword without a particular lifetime to trigger an elision mechanism).
We will discuss this and other methods in Section~\ref{subsec:lifetime-elision}.

The type-based escape analysis feature is useful beyond its application to effect system construction.
Namely, it can be used to reduce a number of heap allocations~\cite{lorenzen2024oxidizing}, implement borrowing for an ownership-based resource management~\cite{matsakis2014rust, lorenzen2024oxidizing}, ensure safety of non-local return~\cite{akhin2021kotlin}.

\subsection{Summary} \label{subsec:idea-summary}

An effect system can be seen as a combination of implicit parameters and type-based escape analysis features.
Hence, the design of an effect system naturally splits into two parts and can be approached step-by-step.

In fact, our previous discussion was centered around free variables.
Indeed, a term naturally depends on a context with its free variables: in different contexts it obtains different semantics through them.
So, they are the target for an effect system, while bound once are controlled by canonical type systems.

Two parts of our perspective on effect systems originate from the fact that there are two ways of defining the semantics for free variables: dynamic and lexical scoping.
It is convenient to do it one way or another depending on the situation.
We summarize the correspondence on the fig.\ \ref{fig:free-vars} and discuss the connection with other works on effect system design in Section\ \ref{sec:related}.

\begin{figure}
    \centering
    \begin{tabular}{|l|l|l|}
        \hline
        Free variables & dynamically scoped & lexically scoped \\
        \hline
        Represent & unfulfilled context requirements & fulfilled context requirements \\
        Dealt by & implicit parameters & type-based escape analysis \\
        User specifies & more function parameters & a function’s dataflow \\ % todo other analysis may require something different
        \hline
    \end{tabular}
    \caption{Effect systems are for managing free variables.}
    \label{fig:free-vars}
\end{figure}


\section{Core calculus} \label{sec:core}

In this section we introduce a convenient for us explicitly typed call-by-value core calculus $Core$ that we will extend later with omitting application and type-based escape analysis.

\subsection{Effect handlers} \label{subsec:handlers}

In our formal elaborations we are going to use effect handlers as a universal mechanism for defining effects~\cite{plotkin2003algebraic, plotkin2013handling}, because it is powerful enough to express all effects of interest, thus we do not need to consider them one by one.
At the same time, unlike monad transformers~\cite{liang1995monad, schrijvers2019monad}, dynamic semantics of effect handlers can be defined on its own without any type-directed translation, hence, it does not impose any restrictions on the effect system design.

Let us give a brief introduction to effect handlers and show how to use them to implement effects, discussed in the previous section~\ref{sec:idea}.

The \texttt{handle} construct allows to define an execution context for a particular scope by defining a set of operations.
The \texttt{perform} construct can be used by the code in the scope to call operations defined by a handler as an act of context interaction.
We use lexically scoped handlers which require \texttt{perform} to refer to a specific instance of a handler with a binding~\cite{biernacki2019binders, brachthauser2020effects}.
An implementation of each operation has access to a continuation of a call site, which can be used to return a result.

For example, we can define an execution context providing a specific constant to a computation.
To do so, we provide a handler of a \texttt{Reader} effect that provides \texttt{ask} operation returning a constant.
A computation sums two invocations of \texttt{ask}, so the overall result will be $42$:
\[
    \begin{array}{l}
        \keyword{handle} ~ h : Reader\ap Int ~\keyword{with}~ \{ ask = \lambda k\ldotp k\ap 21 \} ~\keyword{in} \\
        \keyword{perform}~ask~h~() + \keyword{perform}~ask~h~()
    \end{array}
\]

To implement exceptions, \texttt{throw} operation should simply throw away the continuation.
The following program returns a thrown number $42$:
\[
    \begin{array}{l}
        \keyword{handle}~ h : Exception\ap Int ~\keyword{with}~ \{throw = \lambda e~k\ldotp e \} ~\keyword{in} \\
        \keyword{perform}~throw~h~42
    \end{array}
\]

Other algebraic effects like mutable state and nondeterminism can be implemented with \texttt{handle} construct as well. % todo citations

%\begin{equation}
%    \begin{array}{l}
%        \keyword{handle}~ h : State\ap Int ~\keyword{with}~ \{\\
%        \indent get = \lambda k\ldotp\lambda s\ldotp k\ap s\ap s \\
%        \indent put = \lambda s'~k\ldotp\lambda s\ldotp k\ap ()\ap s' \\
%        \} ~\keyword{in}~ \\
%        perform~put~h~42; perform~get~h~42
%    \end{array}
%\end{equation}

\subsection{Syntax of $Core$} \label{subsec:syntax-core}

Let us discuss the syntax of $Core$ (fig.\ \ref{fig:core-syntax}).
By the over-line we denote a bunch of corresponding entries.
Constructs highlighted with gray are used only for an operational semantics.
Our considerations that lead to this syntax are the following:
\begin{itemize}
    \item We split arguments into two groups, first group contains \textit{contextual arguments} that will be inferred automatically later.
    This separation helps us to build algorithmic typing rules as functional type distinguishes contextual and ordinary arguments.
    \item We use uncurried abstraction and application to make future implicit parameters inference local in a sense that typing information available to an application rule is enough~\cite{pierce2000local}.
    \item For the same purpose we couple contextual and ordinary parameters.
    \item Capability constructors $K_{cap}$ are used in an operational semantics as a representation of a capability. % todo cite generalized evidence passing?
    \item $handle$ construct creates a capability associated with a corresponding handler and binds it with a name.
    At the same time $perform$ construct requires a capability to perform an effect.
    This approach helps us to naturally build an effect system from the point of view we discussed before (Section~\ref{sec:idea}).
    \item For brevity, we do not include $return$ block in handlers, because it does not add any expressiveness.
    \item $handler_m$ construct serves as a continuation delimiter with a unique marker $m$ for an operational semantics.
    \item In a function type $\ctx{e} \overline{\tau} \to \sigma$, over-line means a tuple of arguments, where the empty tuple is a unit value.
    So, only an explicit application can cause effects, they cannot happen accidentally with a variable mention.
    \item Typing context distinguishes between regular bindings and \textit{contextual bindings}.
    Contextual ones are only allowed to have monotypes.
    We might have two separate typing contexts, but this would have required us to have different sets for contextual and ordinary bindings.
\end{itemize}

\begin{figure}
    \centering
    \begin{gather*}
        \begin{array}{lrll}
            \text{Variables} & & x, y, z, f, g, op \\
            \text{Values} &v &\Coloneqq x \vor \Lambda \overline{\alpha} \ldotp v \\
            &&\vor K\ap \overline{\tau} \ap \overline{t} \vor \graybox{K_{cap}\ap\overline{\tau}\ap m\ap h} \\
            &&\vor \lambda \overline{x : \tau}~\overline{y : \sigma}\ldotp t
            \\
            \text{Terms} &t, u &\Coloneqq v \vor t\ap\overline{\tau} \vor t \ap \overline{t} \ap \overline{t} \\
            &&\vor match ~ t ~ with ~\{\overline{K \ap \overline{x} \to t}\} \\
            &&\vor perform ~ op \ap x \ap \overline{\tau} \ap \overline{t} \\
            &&\vor handle ~ x : T \ap \overline{\tau} ~with ~h~in ~t \\
            &&\vor \graybox{handler_m ~ t}
            \\
            \text{Handlers} &h &\Coloneqq \{ \overline{op = t} \}
            \\
            \text{Programs} &p &\Coloneqq \epsilon \vor x : s = t, p
        \end{array}
        \begin{array}{lrl}
            \text{Type variables} && \alpha, \beta \\
            \text{Type constructors} && T \\
            \text{Monotypes} & \tau, \sigma, \eta &\Coloneqq \alpha \vor T \ap \overline{\tau} \vor \ctx{e} \overline{\tau} \to \sigma \\
            \text{Type schemas} & s &\Coloneqq \forall\overline{\alpha}\ldotp \tau \\
            \text{Effect rows} & e &\Coloneqq \epsilon\vor \tau, e \\
            \text{Typing contexts} & \Gamma &\Coloneqq \emptyset \vor x : s, \Gamma \vor x :_c \tau, \Gamma \\
            \text{Effect contexts} & \Sigma &\Coloneqq \{\overline{K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap\overline{\alpha}}\} \\
            \text{Effect signatures} & sig &\Coloneqq \{\overline{op : \forall\overline{\alpha}\ldotp\overline{\tau}\to\sigma}\} \\
            \text{Data constructors} & & K : \forall\overline{\alpha}\ldotp \overline{\tau}\to T\ap \overline{\alpha} \\
            \text{Free type variables} & & ftv(\cdot) \\
        \end{array}\\
        \begin{aligned}
            \text{Evaluation context } E \Coloneqq \square \vor E \ap \overline{\tau} \vor E \ap \overline{t}\ap \overline{t} \vor v \ap (\overline{v}, E, \overline{t}) \ap \overline{t} \vor v \ap \overline{v} \ap (\overline{v}, E, \overline{t}) \vor handler_m ~ E
        \end{aligned}\\
    \end{gather*}
    \caption{Syntax of $Core$.}
    \label{fig:core-syntax}
\end{figure}

Note that the type of first-class functions contains a list of implicit parameters.
It allows to type the abstraction over handlers.
For example, the following function establishes en execution context with a handler for an exception type \texttt{E}\footnote{We use informally defined surface syntax for explanations. Its correspondence to our formal definitions is straight-forward.}:
\begin{minted}{swift}
    func withE(f: context(Handler<E>) () -> r): r =
        try { f() } catch (e: E) { ... }
\end{minted}

We assume that an effect context $\Sigma$ is populated by user's \texttt{effect} declarations like ones in Koka. % todo citation
Namely, for a program with the following declaration, $\Sigma = \{EffK : \forall\alpha\ldotp\{id : \forall\beta\ldotp b\to b, yield : a \to Unit\} \to Eff\ap a\}$ (there is a bijection between capability constructors and effect types):
\begin{minted}{swift}
    effect Eff<a> {
        op id(x: b): b
        op yield(x: a): Unit
    }
\end{minted}

\subsection{Operational semantics of $Core$}

Let us get through the most interesting parts of our semantics (fig.\ \ref{fig:core-operational}):
\begin{itemize}
    \item (handle) selects a capability constructor corresponding to a provided effect types $T$ and uses it to create a capability.
    Also, it allocates a fresh marker $m$ and installs it with $handler$ construct.
    \item (perform) destructs a capability, selects an operation and executes it with a current continuation delimited by a corresponding marker.
    We use deep handlers~\cite{hillerstrom2018shallow}, so handler is reinstalled in a continuation.
\end{itemize}

\begin{figure}
    \[
        \begin{array}{llll}
            \text{(tapp)} &(\Lambda \overline{\alpha}\ldotp t) \ap \overline{\tau} &\longrightarrow &[\overline{\alpha\to\tau}]\ap t
            \\
            \text{(app)} &(\lambda \overline{x}~\overline{y}\ldotp t) \ap \overline{v} \ap \overline{v'} &\longrightarrow &[\overline{x\to v}, \overline{y\to v'}]\ap t
            \\
            \text{(match)} &match ~K \ap \overline{v}~ with ~ \{ \overline{K_i \ap \overline{x} \to u_i}\} &\longrightarrow &[\overline{x\to v}]\ap u_k, \text{ where } K = K_k
            \\
            \text{(handle)} &handle ~ x : T \ap \overline{\tau} ~with~h~in~t &\longrightarrow & handler_m ~[x \to K_{cap} \ap\overline{\tau}\ap m \ap h] \ap u
            \\
            &&\text{where} & m \text{ fresh}, {\color{gray}K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap\overline{\alpha} \in \Sigma}
            \\
            \text{(return)} &handler_m ~v &\longrightarrow & v
            \\
            \text{(perform)} &handler_m~E[perform \ap op \ap (K_{cap}\ap\overline{\tau_1}\ap m \ap h)\ap\overline{\tau_2}\ap\overline{v}] &\longrightarrow &t \ap \overline{\tau_2}\ap \overline{v}\ap k
            \\
            &&\text{where} & (op = t) \in h, {\color{gray}\theta = [\overline{\alpha\to\tau_1}, \overline{\beta\to\tau_2}],} \\
            &&& {\color{gray}K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap\overline{\alpha} \in \Sigma,} \\
            &&& {\color{gray}(op : \forall\overline{\beta}\ldotp\overline{\sigma}\to\sigma') \in sig,} \\
            &&& k = \lambda x : \theta\ap\sigma' \ldotp handler_m~E[x]
        \end{array}
    \]
    \vspace{-3em}
    \[
        \hspace{-15em}\infer[\text{(step)}]{E[t]\longrightarrow E[t']}{t\longrightarrow t'}
    \]
    \caption{Operational semantics of $Core$.}
    \label{fig:core-operational}
\end{figure}

Note that every $perform$ addresses a particular handler, so there is no effect encapsulation problem~\cite{lindley2018encapsulating}: an effect cannot be accidentally handled. % todo more citations
For example, the following function will not be able to intercept \texttt{E2} exception potentially thrown in \texttt{f}, because \texttt{withE1} do not explicitly provide \texttt{f} a corresponding capability:
\begin{minted}{swift}
    func withE1(f: context(Handler<E1>) () -> r): r =
        try { f() } catch (e: E1) { ... } catch (e: E2) { /* unreachable */ }
\end{minted}

Since we propagate a handler to an operation call site, we can avoid handler lookup and collection of a continuation if a callee operation is tail-resumptive~\cite{xie2020effect}.
In a low-level implementation such $perform$ can be replaced with a virtual call. % todo citation

TODO theorems % todo theorem about determinism (and mb others)

\subsection{Typing rules for $Core$}

\begin{itemize}
    \item Typing rules for $Core$ (fig.\ \ref{fig:core-typing}) are algorithmic.
    \item We skip type well-formedness conditions and never-changing effect context $\Sigma$ for brevity.
    \item An entry in an effect context $\Sigma$ and be uniquely identified by a capability type, so we use $\Sigma$ as a function: $\Sigma(T) = \forall\overline{\alpha}\ldotp sig \iff K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap\overline{\alpha}\in\Sigma$.
    \item Elements in the typing context be unique with respect to variable names.
\end{itemize}

%! suppress = EscapeAmpersand
\begin{figure}
    \begin{gather*}
        \mathframebox{\Gamma\vdash t : \tau} \\
        \infer[Var]{\Gamma\vdash x\ap\overline{\tau} : [\overline{\alpha\to\tau}]\ap\sigma}{x : \forall\overline{\alpha}\ldotp \sigma \in \Gamma}
        \text{\hspace{2em}}
        \infer[CVar]{\Gamma\vdash x : \tau}{x :_c \tau \in \Gamma} \\
        \infer[Lam]{
            \Gamma\vdash \lambda \overline{x : \tau_1} ~ \overline{y : \tau_2} \ldotp t : ctx(\overline{\tau_1}) ~ \overline{\tau_2} \to \sigma
        }{
            \overline{x :_c \tau_1}, \overline{y : \tau_2}, \Gamma\vdash t : \sigma &
            \overline{\tau_1} \text{ distinct}
        }
        \text{\hspace{2em}}
        \infer[App]{
            \Gamma\vdash t \ap \overline{u_1} \ap \overline{u_2} : \sigma
        } {
            \Gamma\vdash t : ctx(\overline{\tau_1})~\overline{\tau_2}\to\sigma
            &
            \overline{\Gamma\vdash u_1 : \tau_1}
            &
            \overline{\Gamma\vdash u_2 : \tau_2}
        }\\
        \infer[Match]{
            \Gamma\vdash match ~ t ~with ~\{ \overline{K_i\ap \overline{x_j} \to u_i }\}  : \sigma
        }{
            K_i : \forall \overline{\alpha}\ldotp \overline{s_j} \to T\ap\overline{\alpha} &
            \Gamma\vdash t : T \ap\overline{\tau} &
            \overline{x_j : [\overline{\alpha\to\tau}]\ap s_j}, \Gamma \vdash u_i : \sigma
        }\\
        \infer[Perform]{
            \Gamma\vdash perform \ap op\ap \overline{\tau_2}\ap x\ap \overline{t} : \theta\ap\eta
        }{
            \Gamma\vdash x : T\ap \overline{\tau_1} &
            \Sigma(T) = \forall\overline{\alpha}\ldotp sig &
            op : \forall\overline{\beta}\ldotp \overline{\sigma}\to\eta \in sig &
            \theta = [\overline{\alpha\to\tau_1}, \overline{\beta\to\tau_2}] &
            \overline{\Gamma\vdash t : \theta\ap\sigma}
        }\\
        \infer[Handle]{
            \Gamma \vdash handle ~ x : T\ap\overline{\tau}~ with ~ \{\overline{op_i = t_i}\} ~in~u : \eta
        }{
            \begin{gathered}
                x :_c T\ap\overline{\tau}, \Gamma\vdash u : \eta
            \end{gathered}
            &
            \begin{array}{ll}
                \overline{\beta}\not\cap ftv(\eta) & % todo beautify intersection
                \Sigma(T) = \forall\overline{\alpha}\ldotp sig, \hspace{0.5em} op_i : \forall\overline{\beta}\ldotp \overline{\sigma}_i\to\sigma'_i \in sig
                \\
                \theta = [\overline{\alpha\to\tau}] &
                \Gamma\vdash\theta\ap t_i : \forall \overline{\beta}\ldotp \overline{\theta\ap\sigma_i}\to(\theta\ap\sigma_i'\to\eta)\to\eta
            \end{array}
        }\\
        \infer[Cap]{
            \Gamma\vdash K_{cap}\ap\overline{\tau}\ap m\ap h : T\ap\overline{\tau}
        }{
            K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap\overline{\alpha} \in \Sigma
        } % todo looks like a bull shit
        \hspace{2em}
        \infer[Handler]{
            \Gamma\vdash handler_m ~t : \tau
        }{
            \Gamma\vdash t : \tau
        }\\
        \begin{array}{ccccc}
            \mathframebox{\Gamma\vdash t : s} &
            \infer[TLam]{
                \Gamma\vdash\Lambda\overline{\alpha}\ldotp v : \forall\overline{\alpha}\ldotp\tau
            }{
                \Gamma\vdash v : \tau & ftv(\tau) = \overline{\alpha}
            } &
            \mathframebox{\Gamma\vdash p} &
            \infer[\epsilon Prog]{\Gamma\vdash\epsilon}{} &
            \infer[Prog]{\Gamma\vdash x : s = t, p}{\Gamma\vdash t : s & \Gamma\vdash p}
        \end{array}
    \end{gather*}
    \caption{Typing rules for $Core$.}
    \label{fig:core-typing}
\end{figure}

TODO formulate properties % todo

\section{Design of implicit parameters} \label{sec:implicits}

In this section we discuss design decisions for implicit parameters feature that make it more suitable as a component of a practical effect system.
Along the discussion we introduce a formal calculi with implicit parameters $Core^{im}$ as an extension to $Core$.

\subsection{Syntax of $Core^{im}$}

We extend syntax of $Core^{ex}$ with an omitting application, which do not specify the first block of contextual arguments:
\[
    \begin{array}{lcc}
        \text{Terms} & t, u &\Coloneqq \ldots \vor t\ap\overline{t} \vor \ldots
    \end{array}
\]

\subsection{Inference of implicit parameters} \label{subsec:inference}

We give a type-directed translation from $Core^{im}$ to $Core$ (fig.\ \ref{fig:fim-fex-inference}).
Making translation rules for other constructs from typing rules for $Core$ is straight-forward.

$\Gamma\vdash_e \overline{x}$ relation selects from the typing context variables participating in the inference with given effect types.
Note that since the typing context only stores bindings with unique names, a user can shadow a contextual binding with an ordinary one, and it will not participate in the inference anymore.
This issue can be solved, for instance, by making typing context a list with duplications and assigning fresh names to contextual bindings.

\begin{figure}
    %! suppress = EscapeAmpersand
    \begin{gather*}
        \mathframebox{\Gamma\vdash t : \tau \step t_{c}} \\
        \infer[CtxApp]{
            \Gamma\vdash t\ap\overline{u} : \sigma \step t_{c} \ap \overline{x}\ap\overline{u_{c}}
        }{
            \Gamma\vdash t : \ctx{e} \overline{\tau} \to \sigma \step t_{c} &
            \Gamma\vdash_e\overline{x} &
            \overline{\Gamma\vdash u : \tau \step u_{c}}
        } \\
        \mathframebox{\Gamma\vdash_e \overline{x}}
        \text{\hspace{2em}}
        \infer[Infer]{\Gamma\vdash_{\overline{\tau}} \overline{x}}{\overline{x :_c \tau}\subset \Gamma}
    \end{gather*}
    \caption{Inference of implicit parameters.}
    \label{fig:fim-fex-inference}
\end{figure}

There is a design decision to be made, whether inference should rely only on types, or on variable names as well.
The second option is a bit more complicated than the first one, since it requires to store variables names in the effect rows.
Moreover, it excludes renaming of implicit parameters from $\alpha$-equivalence, making a program more fragile regarding renaming.
On the other hand, it allows to use simultaneously multiple effects of the same type.
This problem attracts many attention from researchers. % todo citations
However, we use the first option and argue that in practical programming using multiple effects of the same type is mostly undesired.
We believe that users should provide many domain-specific effects instead of using basic ones directly.
For example, some \texttt{UserRepository} effect is preferable to general \texttt{Database} effect, since it provides higher-level of abstraction.

Another decision is when to substitute implicit parameters, on mentioning or, deferred, on application.
It is a similar question to the type instantiation with first-class polymorphism (type inference infers type parameters)~\cite{emrich2020freezeml}. % todo verify citation
Both ways are useful: the first is convenient with contextually-polymorphic functions \texttt{map(xs, f)}, the second helps with effect abstraction \texttt{withSomeException(f)}. % todo introduce effect abstraction somewhere % todo citations to kotlin, haskell and something
Actually, the decision is about choosing the default, since one behaviour can be changed to another by the $\eta$-expansion. % todo explain better, examples
Namely, assume that the substitution occurs on application:
\begin{minted}{swift}
    f : context(IO) () -> Unit; g : (() -> Unit) -> Unit
    g(() => f())
\end{minted}
Or, assume that substitution occurs on mentioning:
\begin{minted}{swift}
    f : context(IO) () -> Unit; g : (context(IO) () -> Unit) -> Unit
    g(context(_: Eff) () => f()) // abstracts over contextual parameters
\end{minted}
% todo special syntax for explicitly passed implicits
% todo have i introduced surface implicit abstraction somewhere
% todo have i introduced the surface syntax anywhere

TODO properties % todo

\subsection{System $Core^{im+<:}$ with implicit parameters and subtyping} \label{subsec:im-sub}

It is convenient to have some form of subtyping on effect rows, since a function with less context requirements can naturally be used in more permissive contexts.
For example, \texttt{withStd} is a function that provides default implementation for many effects.
We should be able to pass a function that uses only some of them:
\begin{minted}{swift}
    func withStd(f: context(IO, Allocator, Random) () -> r): r
    withStd(g) // g : context(IO) () -> Unit
\end{minted}

% todo find literature
% todo row polymorphism can help somehow?
% todo cite papers about row types
Contexts can be seen as structural record types with width and permutation subtyping.
However, the naive implementation of such records as dictionaries is not very efficient in time and space.

To achieve an efficient implementation of subtyping, we restrict it to be shallow in a sense that one functional type subtypes another only if one effect row subtypes another, while arguments and return types should be the same:
\[
    \infer{\ctx{e} \tau \to \sigma <: \ctx{e'} \tau\to\sigma}{e' <: e}
\]

Now we can implement such shallow subtyping by $\eta$-expansion (fig.\ \ref{sig:fim-sub-app}).
Relation $\Gamma\vdash t\Leftarrow \tau \step t_c$ performs $\eta$-expansion if a functional type is expected.

\begin{figure}
    %! suppress = EscapeAmpersand
    \begin{gather*}
        \mathframebox{\Gamma\vdash t : \tau \step t_c} \\
        \infer[App]{
            \Gamma\vdash t\ap\overline{u} : \eta \step t_c \ap \overline{x} \ap \overline{u_c}
        }{
            \Gamma\vdash t : ctx(\overline{\tau})~\overline{\sigma}\to \eta \step t_c
            &
            \Gamma \vdash_{\overline{\tau}} \overline{x}
            &
            \overline{\Gamma\vdash u \Leftarrow \sigma \step u_c}
        } \\
        \mathframebox{\Gamma\vdash t \Leftarrow \tau \step t_c} \\
        \infer[AppArg]{
            \Gamma\vdash t \Leftarrow \tau \step t_c
        }{
            \Gamma\vdash t : \tau \step t_c
        }
        \text{\hspace{1em}}
        \infer[AppArgCtx]{
            \Gamma \vdash t \Leftarrow ctx(\overline{\tau}) ~\overline{\sigma}\to\eta\step \lambda \overline{x : \tau}~\overline{y : \sigma}\ldotp t_c\ap \overline{x'}\ap\overline{y}
        }{
            \Gamma \vdash t : ctx(\overline{\tau'}) ~\overline{\sigma}\to\eta \step t_c
            &
            \overline{x :_c \tau} \vdash_{\overline{\tau'}} \overline{x'}
            &
            \overline{x~y \text{ fresh}}
        }
    \end{gather*}
    \caption{Application rule for $Core^{im + <:}$.}
    \label{sig:fim-sub-app}
\end{figure}

% todo link to bidirectional typing

% todo big lambda inference

% todo will subtyping break inference?

% todo what if generate application (like for dictionaries) to reorder effect rows (do inhabitation of some form)?

\section{Design of type-based escape analysis} \label{sec:escape}

In this section we develop an extension to the previously discussed systems, which statically ensure that no capabilities escape from corresponding handlers.

% todo a bit about general idea like in the introduction mb
% todo existential types and ST-trick
% todo mb brief lit overview

\subsection{Syntax of $Core_\Delta$}

Let us introduce a $Core_\Delta$, that extends $Core$ with lifetimes, lifetime polymorphism and bounded polymorphism.
Changes in the syntax of types (fig.\ \ref{fig:core-delta-syntax}) are highlighted with gray.
\begin{itemize}
    \item Monotypes are now augmented with a lifetime parameter.
    \item Type schemas support abstraction over lifetimes and bounds.
\end{itemize}

% todo tracked term

%! suppress = MissingLabel
\begin{figure}
    \[
        \begin{array}{lrl}
            \text{Type variables} && \alpha, \beta \\
            \text{Type constructors} && T \\
            \text{Lifetime variables} && \graybox{l} \\
            \text{Lifetimes} & \graybox{\Delta} &\Coloneqq l \vor local \vor free \vor \&\overline{\Delta} \\
            \text{Monotypes} & \tau, \sigma, \eta &\Coloneqq \alpha \vor T \ap \graybox{\Delta} \ap \overline{\tau} \vor \ctx{e} \graybox{\Delta}~\overline{\tau} \to \sigma \\
            \text{Type schemas} & s &\Coloneqq \forall \graybox{\overline{l}}~\overline{(\alpha \graybox{<: \tau})}\ldotp \sigma \\
            \text{Effect rows} & e &\Coloneqq \epsilon\vor \tau, e \\
            \text{Typing contexts} & \Gamma &\Coloneqq \emptyset \vor x : s, \Gamma \vor x :_c \tau, \Gamma \vor \graybox{\alpha <: \tau, \Gamma} \\
            \text{Effect contexts} & \Sigma &\Coloneqq \{\overline{K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap \graybox{local} \ap\overline{\alpha}}\} \\
            \text{Effect signatures} & sig &\Coloneqq \{\overline{op : \forall\overline{(\alpha \graybox{<: \eta})}\ldotp\overline{\tau}\to\sigma}\} \\
            \text{Data constructors} & & K : \forall\graybox{\overline{l}}\ \overline{\alpha}\ldotp \overline{\tau}\to T \ap\graybox{(\&\overline{lt_+(\tau)}\cup\overline{l})}\ap \overline{\alpha} \\
            \text{Free type variables} & & ftv(\cdot) \\
            \text{Positive lifetimes} & & \graybox{lt_+(\cdot)} \\
            \text{Free lifetime variables} & & \graybox{flt_+(\cdot)}, \graybox{flt_-(\cdot)}
        \end{array}
    \]
    \caption{Syntax of types for $Core_\Delta$.}
    \label{fig:core-delta-syntax}
\end{figure}

Syntax of terms follows the changes in the syntax of types:
\[
    \begin{array}{lll}
        \text{Values} & v & \Coloneqq \ldots \vor \Lambda \graybox{\overline{l}}\ap\overline{\alpha}\ldotp v \vor K\ap\graybox{\overline{\Delta}}\ap\overline{\tau}\ap\overline{t} \vor \ldots \\
        \text{Terms} & t, u &\Coloneqq \ldots \vor t\ap\graybox{\overline{\Delta}}\ap\overline{\tau} \vor handle ~ x : T \ap\graybox{local}\ap \overline{\tau} ~with ~h~in ~t \vor \ldots
    \end{array}
\]

\subsection{Typing rules for $Core_\Delta$}

There are three

\begin{itemize}
    \item % todo
\end{itemize}

%! suppress = EscapeAmpersand
\begin{figure}
    \begin{gather*}
        \mathframebox{\Gamma\vdash t : \tau} \\
        \infer[Var]{
            \Gamma\vdash x\ap\overline{\Delta}\ap\overline{\tau} : [\overline{l\to\Delta}]\ap[\overline{\alpha\to\tau}]\ap\sigma
        }{
            x : \forall\overline{l}\ap(\overline{\alpha <: \tau'})\ldotp \sigma \in \Gamma &
            \Gamma\vdash\tau <: [\overline{l\to\Delta}]\ap\tau'
        }
        \text{\hspace{2em}}
        \infer[CVar]{\Gamma\vdash x : \tau}{x :_c \tau \in \Gamma} \\
        \infer[Lam]{
            \Gamma\vdash \lambda \overline{x : \sigma} ~ \overline{y : \sigma'} \ldotp t : ctx(\overline{\sigma}) \left(\&{\overline{lt_+(\tau)}}\right)~ \overline{\sigma'} \to \eta
        }{
            \overline{x :_c \sigma}, \overline{y : \sigma'}, \Gamma\vdash t : \eta &
            \overline{\sigma} \text{ distinct} &
            \Gamma\vdash_{fv(t)}\overline{\tau} &
            local\not\in lt_+(\eta)
        } \\
        \infer[App]{
            \Gamma\vdash t \ap \overline{u_1} \ap \overline{u_2} : \eta
        } {
            \Gamma\vdash t : \ctx{\overline{\tau}} \Delta~\overline{\sigma}\to\eta
            &
            \begin{array}{c}
                \overline{\Gamma\vdash u_1 : \tau'} \\
                \overline{\Gamma\vdash\tau' <: \tau}
            \end{array}
            &
            \begin{array}{c}
                \overline{\Gamma\vdash u_2 : \sigma'} \\
                \overline{\Gamma\vdash\sigma' <: \sigma}
            \end{array}
        }\\
        \infer[Match]{
            \Gamma\vdash match ~ t ~with ~\{ \overline{K_i\ap \overline{x_j} \to u_i }\}  : \eta
        }{
            \begin{array}{c}
                K_i : \forall \overline{l}~\overline{\alpha}\ldotp \overline{\sigma_j} \to T\ap(\&\overline{lt_+(\sigma)}\cup\overline{l})\ap\overline{\alpha}
                \text{\hspace{1em}}
                \Gamma\vdash t : T\ap\Delta \ap\overline{\tau}
                \\
                \overline{x_j : [\overline{\alpha\to\tau}, \overline{flt_+(\sigma_j)\to\Delta}, \overline{flt_{-}(\sigma_j)\to free}]\ap \sigma_j}, \Gamma \vdash u_i : \eta
            \end{array}
        }\\
        \infer[Perform]{
            \Gamma\vdash perform \ap op\ap \overline{\tau_2}\ap x\ap \overline{t} : \theta\ap\eta
        }{
            \begin{array}{ccc}
                \Sigma(T) = \forall\overline{\alpha}\ldotp sig &
                \Gamma\vdash x : T\ap \Delta \ap \overline{\tau_1} &
                \overline{\Gamma\vdash t : \sigma'}
                \\
                op : \forall\overline{\beta}\ldotp \overline{\sigma}\to\eta \in sig &
                \theta = [\overline{\alpha\to\tau_1}, \overline{\beta\to\tau_2}] &
                \overline{\Gamma\vdash\sigma' <: \theta\ap\sigma}
            \end{array}
        }\\
        \infer[Handle]{
            \Gamma \vdash handle ~ x : T\ap\overline{\tau}~ with ~ \{\overline{op_i = t_i}\} ~in~u : \eta
        }{
            \begin{array}{cll}
                x :_c T\ap local\ap\overline{\tau}, \Gamma\vdash u : \eta & \overline{\beta}\not\cap ftv(\eta) & % todo beautify intersection
                \Sigma(T) = \forall\overline{\alpha}\ldotp sig \hspace{1em} op_i : \forall\overline{\beta}\ldotp \overline{\sigma}_i\to\sigma'_i \in sig
                \\
                local \not\in lt_+(\eta)\cup\overline{lt_+(\sigma)} & \theta = [\overline{\alpha\to\tau}] &
                \Gamma\vdash\theta\ap t_i : \forall \overline{\beta}\ldotp \overline{\theta\ap\sigma_i}\to(\theta\ap\sigma_i'\to\eta)\to\eta
            \end{array}
        }\\
        \infer[Cap]{
            \Gamma\vdash K_{cap}\ap\overline{\tau}\ap m\ap h : T\ap local \ap\overline{\tau}
        }{
            K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap\overline{\alpha} \in \Sigma
        }
        \hspace{2em}
        \infer[Handler]{
            \Gamma\vdash handler_m ~t : \tau
        }{
            \Gamma\vdash t : \tau
        }\\
        \begin{array}{cccc}
            \mathframebox{\Gamma\vdash t : s} &
            \infer[TLam]{
                \Gamma\vdash\Lambda\overline{l}\ap\overline{(\alpha <: \sigma)}\ldotp v : \forall\overline{l}\ap\overline{(\alpha <: \sigma)}\ldotp\tau
            }{
                \Gamma\vdash v : \tau & flt(\tau) = \overline{l} & ftv(\tau) = \overline{\alpha}
            } &
            \mathframebox{\Gamma\vdash_{\overline{x}}\overline{\tau}}
            &
            \infer[TypesOf]{\Gamma\vdash_{\overline{x}}\overline{\tau}}{\overline{x :_\cdot \tau} \subset \Gamma}
        \end{array} \\
        \begin{array}{ccc}
            \mathframebox{\Gamma\vdash p} &
            \infer[\epsilon Prog]{\Gamma\vdash\epsilon}{} &
            \infer[Prog]{\Gamma\vdash x : s = t, p}{\Gamma\vdash t : s & \Gamma\vdash p}
        \end{array}\\
        \begin{array}{cccc}
            \mathframebox{\Gamma\vdash \sigma <: \tau} &
            \infer[SubAny]{\Gamma\vdash \sigma <: Any\ap local}{} &
            \infer[SubT]{\Gamma\vdash T\ap\Delta' <: T\ap\Delta}{\Delta' <: \Delta} &
            \infer[SubBound]{\Gamma\vdash \alpha <: \tau}{\alpha <: \tau \in \Gamma}
        \end{array} \\
        \begin{array}{cccc}
            \mathframebox{\Delta' <: \Delta} &
            \infer[SubFree]{free <: \Delta}{} &
            \infer[SubLocal]{\Delta <: local}{} &
            \infer[Sub\&]{\Delta' <: \&\overline{\Delta}}{local\in\overline{\Delta}}
        \end{array}
    \end{gather*}
    % todo где нужна информация про баунд дженерика?
    \caption{Typing rules for $Core_{\Delta}$}
    \label{fig:core-delta-typing}
\end{figure}

% todo integration with implicit inference

% todo higher-rank polymorphism is required for lambdas, иначе ничего не будет работать с абстракцией по хендлерам. Хотя можно просто всё сделать локалом в контексте по умолчанию, но тогда могут быть траблы с кепчурингом. Нужно исследовать, можно ли это как-то попроще добавить.

%todo \cite{hannan1998type, boruch2023capturing}

%todo \section{Semantics} \label{sec:semantics}

% todo Barendregt’s ‘variable convention for simplicity?
%
%TODO % todo or make it a part of a regular discussion

% todo ensure that the innermost handlers receives the operation
% todo refer to a paper that proposed to instantiate a handle_m frame

% todo bounds instead of boxing (from capturing types)
% todo lifetimes in the middle instead of `here` mode (to allow handlers consume tracked things)

% todo link to first class names for effect handlers

% todo lifetime tunelling reduce amount of boilerplate for polymorphic code

% todo невозможность отсылать локальные вещи операциям это слишком жестко, нужно ослабить, иначе даже в массив сложит трекаемые вещи в одном скоупе не получится

% todo update on inference

% todo why tunelling (otherwise too much code duplication on polymorphic code)

% todo resources that can leak


\section{Adoption in mainstream languages} \label{sec:mainstream}

% todo every method is a higher-order function (see citatioon in Capturing types)

\subsection{Simplifying lifetime polymorphism} \label{subsec:lifetime-elision}

% todo OOP
% todo escape hatches

TODO % todo

\subsection{Escaping from an effect system}

% todo unsafe escape hatches



TODO % todo

\subsection{Migrating to an effect system}

TODO % todo

\subsection{Working with OOP}

TODO % todo


% todo abstraction inference
% todo bidirectional semantics and higher-order effects


\section{Related work} \label{sec:related}

% todo capture calculus boxing

% todo row-types
% todo capability-based, Scala
% todo modal effect types
% todo coeffects, coeffect style vs effect style
% todo papers about regions?

TODO % todo

% todo type inference and symilarity with first-class polymorphism


\section{Conclusion} \label{sec:conclusion}

TODO % todo


%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
\begin{acks}
    TODO % todo
\end{acks}

% TODO appendix с полным исчислением

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
% todo add links where possible for convenience of readers
\bibliographystyle{ACM-Reference-Format}
\bibliography{bib}

\end{document}
