%! suppress = MissingLabel
%%
%% This is file `effect-system-synergy.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,journal,bibtex,acmsmall')
%%
%% IMPORTANT NOTICE:
%%
%% For the copyright see the source file.
%%
%% Any modified versions of this file must be renamed
%% with new filenames distinct from effect-system-synergy.tex.
%%
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%%
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[acmsmall]{acmart}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
%\AtBeginDocument{%
%    \providecommand\BibTeX{{%
%        Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
%\setcopyright{acmlicensed}
%\copyrightyear{2026}
%\acmYear{2026}
%\acmDOI{XXXXXXX.XXXXXXX}

%%
%% These commands are for a JOURNAL article.
%\acmJournal{JACM}
%\acmVolume{37}
%\acmNumber{4}
%\acmArticle{111}
%\acmMonth{1}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

% Line numbers
% https://tex.stackexchange.com/questions/16010/number-every-line-of-pages
\usepackage{lineno}
\usepackage{mathtools}
\linenumbers
% ------------------------------------------------

\usepackage{multicol}
\usepackage{minted}
\setminted{xleftmargin=\parindent, autogobble, escapeinside=\#\#, numberblanklines=false, fontsize=\small} % todo use lstlisting instead with custom keywords
\usepackage{proof}
\usepackage[inference]{semantic}

\newcommand{\graybox}[1]{\colorbox{lightgray}{$\displaystyle #1$}}
\newcommand{\mathframebox}[1]{\framebox{$\displaystyle #1$}}
\newcommand{\vor}{~|~}
\newcommand{\ap}{~}
\newcommand{\ctx}[1]{ctx(#1)~}
\newcommand{\step}{\rightsquigarrow}
\newcommand{\local}{\top}
\newcommand{\free}{\bot}
\newcommand{\keyword}[1]{\mathbf{#1}}
\newcommand{\identation}{\text{\hspace{2em}}}

%%
%% end of the preamble, start of the body of the document source.
%! suppress = TooLargeSection
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{One Plus One: Effect System as a Synergy of Implicit Parameters and Type-Based Escape Analysis}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
%\author{Ben Trovato}
%\authornote{Both authors contributed equally to this research.}
%\email{trovato@corporation.com}
%\orcid{1234-5678-9012}
%\author{G.K.M. Tobin}
%\authornotemark[1]
%\email{webmaster@marysville-ohio.com}
%\affiliation{%
%    \institution{Institute for Clarity in Documentation}
%    \city{Dublin}
%    \state{Ohio}
%    \country{USA}
%}
%
%\author{Lars Th{\o}rv{\"a}ld}
%\affiliation{%
%    \institution{The Th{\o}rv{\"a}ld Group}
%    \city{Hekla}
%    \country{Iceland}}
%\email{larst@affiliation.org}
%
%\author{Valerie B\'eranger}
%\affiliation{%
%    \institution{Inria Paris-Rocquencourt}
%    \city{Rocquencourt}
%    \country{France}
%}
%
%\author{Aparna Patel}
%\affiliation{%
%    \institution{Rajiv Gandhi University}
%    \city{Doimukh}
%    \state{Arunachal Pradesh}
%    \country{India}}

\author{Andrey Stoyan}
\affiliation{%
    \institution{HSE University}
    \city{Saint Petersburg}
    \country{Russian Federation}}
\email{a.stoyan@hse.ru}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
%\renewcommand{\shortauthors}{Surname et al.}
\renewcommand{\shortauthors}{Andrey Stoyan}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
    Effects offer a systematic approach to managing code complexity.
    Certain responsibilities can be delegated to an execution context, allowing a computation to interact with this context by performing effects and thereby focusing on other aspects of logic.
    Effect systems elevate information about a program’s side effects to the type level, clarifying abstraction boundaries and enabling static verification of context validity.
    Despite these advantages, effect systems have not seen widespread adoption, largely due to their alien design and the general unfamiliarity of practitioners with the concept.

    In this paper, we propose a perspective on effect system design as a combination of two properly-designed language features: implicit parameters and type-based escape analysis.
    We argue that both features can be naturally realized in mainstream programming languages, are already familiar to practitioners, and provide independent utility.
    We motivate our approach by considering effect systems as mechanism for tracking free variables.
    We detail the requirements for a practical design of implicit parameters and illustrate these concepts with a formal example.
    Furthermore, we introduce a novel type-based escape analysis technique that relies primarily on straightforward programmer-supplied dataflow descriptions. % todo is it correct to talk about dataflow here?
%    Finally, we formalize these ideas by presenting a calculus with an effect system constructed from these two core components. % todo adapt about OOP and other
\end{abstract}

%% todo
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
%    \begin{CCSXML}
%        <ccs2012>
%        <concept>
%        <concept_id>00000000.0000000.0000000</concept_id>
%        <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%        <concept_significance>500</concept_significance>
%        </concept>
%        <concept>
%        <concept_id>00000000.00000000.00000000</concept_id>
%        <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%        <concept_significance>300</concept_significance>
%        </concept>
%        <concept>
%        <concept_id>00000000.00000000.00000000</concept_id>
%        <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%        <concept_significance>100</concept_significance>
%        </concept>
%        <concept>
%        <concept_id>00000000.00000000.00000000</concept_id>
%        <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%        <concept_significance>100</concept_significance>
%        </concept>
%        </ccs2012>
%    \end{CCSXML}

%\ccsdesc[500]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
%\ccsdesc[300]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
%\ccsdesc{Do Not Use This Code~Generate the Correct Terms for Your Paper}
%\ccsdesc[100]{Do Not Use This Code~Generate the Correct Terms for Your Paper}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{static analysis, type systems, effects, capabilities}

%\received{10 July 2025}
%\received[revised]{12 March 2009}
%\received[accepted]{5 June 2009} todo

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle


\section{Introduction} \label{sec:intro}

% Introducton makes claims, all of them should be supported later.

The discipline of programming primarily centers on the management of complexity, enabling developers to concentrate on a specific fragment of behavior within any given code segment.
Abstraction and the separation of concerns are essential strategies in this process: distinct responsibilities are delegated to different program entities, such as functions or modules.
Frequently, such an entity may be abstractly referred to as the \textit{execution context} of a computation, with \texttt{effects} emerging naturally as interactions between the computation and its context~\cite{kiselyov2013extensible}.

An execution context can be characterized by at least one of the following properties:
\begin{enumerate}
    \item Interactions with an execution context are observable.
    For example, the memory management subsystem can be considered as the execution context --- each memory allocation can influence the addresses of subsequent allocations.
    In that case the context is responsible for bookkeeping of memory cells.
    \item The activity of an execution context may be restricted to a particular scope, such that only code within this scope can interact with the context.
    For example, an exception handler operates as an execution context confined to the body of a \texttt{try-catch} block; when an exception is thrown, control is transferred to the handler, which manages the exceptional situation.
    Another case is inversion of control, where an execution context restricts the provision of certain functionality to code within a defined scope, while code outside that scope may interact with a different context and access different functionality.
\end{enumerate}

An effect system reflects effects of a computation at the type level.
It serves two primary purposes.
Firstly, it makes effects explicit in type signatures, allowing functional abstraction boundaries to be specified with greater precision: implementation details are less likely to leak implicitly via context interactions.
Secondly, an effect system provides static enforcement of \textit{effect safety} for a computation’s use: a computation may only be executed within an appropriate context (as previously discussed, contexts may have limited activity scopes).
For example, an effect system is responsible for ensuring that all functionality required by inversion of control is available, and that all exceptions are handled.
It is also worth noting that effect systems can capture additional properties of computations, such as potential for divergence.

Many promising designs of effect systems were proposed: row-polymorphic types~\cite{leijen2014koka}, capabilities and contextual polymorphism~\cite{brachthauser2022effects, boruch2023capturing}, modal types~\cite{tang2025modal}, etc.
However, each of these approaches exhibits its own advantages and drawbacks, and the overall configuration of the design space for effect systems remains underexplored.
At the same time we believe it is important for language designers to have a comprehensive view of the available design options, allowing them to select the most appropriate solution given the specific characteristics and constraints of their target language.

In this paper, we argue that effect systems can be conceptualized as a combination of two simpler and more foundational language features: implicit parameters and type-based escape analysis.
Viewing effect systems from this perspective introduces axes within the effect system design space: varying the designs of these two features yields different possible instantiations.
Moreover, this approach facilitates the seamless integration of effect systems into existing mainstream languages, as many of these languages already support at least one of these features, since each of which is independently practical.

The general idea we present is not novel.
For example, recent work in the Scala programming language bases on similar observations~\cite{odersky2021safer, boruch2023capturing}.
However, our contribution lies in articulating this idea explicitly, systematically exploring its implications, and leveraging these insights to design a new effect system that is both practical and minimalistic.

% рассматриваем сразу и модели и системы эффектов, потому что делается type-based translation

Contributions of this paper are summarized as follows:

\begin{itemize} % todo
    \item We propose a perspective on effect system design as a combination of two properly-designed language features: implicit parameters and type-based escape analysis; and motivate our approach by looking at effect systems as systems for managing free variables (Section~\ref{sec:idea}).
    \item We describe required properties of implicit parameters design and provide a suitable one using a formal calculi (Section~\ref{sec:implicits}).
    \item We provide a novel type-based escape analysis technique that only requires straight-forward dataflow descriptions from a programmer (Section~\ref{sec:escape}).
    \item We show that our design is appropriate in the object-oriented setting (Section~\ref{sec:mainstream}). % todo расширить скоуп на просто финтифлюшки делающие дизайн более прикладным
%    \item We explore practical subtleties of our design and its applicability to object-oriented programming languages (Section~\ref{sec:mainstream}).
    \item We compare our approach with previous art and show that other designs can be considered in implicit parameters and escape analysis basis (Section~\ref{sec:related}).
\end{itemize}


\section{Two pieces of an effect system design} \label{sec:idea}

In this section we introduce the central idea of this paper through practical examples.
We further illustrate that the pragmatic motivations for effect systems emerge organically from common programming scenarios.

\subsection{The road to implicit parameters} \label{subsec:implicits}

In our running example (see fig.\ \ref{fig:db}), where the business logic function performs an update to the database storage.

The first version establishes its own database connection and executes a query.
However, this approach has several notable drawbacks.
Firstly, it hinders testability, as it is not straightforward to replace the database connection with a mock or alternative implementation; consequently, verifying the business logic in isolation becomes challenging.
Secondly, this function produces observable side effects --- such as performing database operations --- which are an integral part of its external contract.
Nevertheless, these effects are not reflected in the function’s type signature.

The second version provides a notable improvement.
Here, the business logic function is parameterized over the database connection, enabling the call site to supply a concrete implementation with the desired semantics.
Furthermore, the observable effects are now made explicit through the \texttt{db} parameter.
However, this approach incurs the overhead of additional syntactic complexity at the call site, as the administrative effort of explicitly passing parameters increases.
While this may appear trivial for a single argument, the burden becomes significant if, for example, four such parameters must be threaded through multiple layers of the call stack.
For best practices to be widely adopted, they should remain at least as accessible and convenient as less optimal alternatives.

To reduce boilerplate, the third version replaces ordinary parameters with dynamically scoped free variables.
These variables acquire their values through lookup within the dynamic scope of the function call.
However, this approach comes at the expense of other benefits: specifically, it sacrifices static typing and the explicit representation of context dependencies.

\begin{figure}
    \begin{tabular}{p{0.3\textwidth} rrr}
        \begin{minipage}[t]{0.3\textwidth}
            \begin{minted}{swift}
                func business1() {
                    let db = Db.open(...)
                    db.query("update ...")
                }
            \end{minted}
        \end{minipage}
        &
        \begin{minipage}[t]{0.3\textwidth}
            \begin{minted}{swift}
                func business2(db: Db) {
                    db.query("...")
                }

                func caller() {
                    let db = Db.open(...)
                    business2(db)
                }
            \end{minted}
        \end{minipage}
        &
        \begin{minipage}[t]{0.3\textwidth}
            \begin{minted}{swift}
                func business3() {
                    db.query("...")
                }

                func caller() {
                    let db = Db.open(...)
                    business3()
                }
            \end{minted}
        \end{minipage}
    \end{tabular}
    \caption{The road to dynamically scoped free variables.}
    \label{fig:db}
\end{figure}

To regain static type safety, we approximate dynamically scoped free variables using implicit function parameters~\cite{lewis2000implicit}.
At the declaration site, we introduce a \texttt{context} keyword to define a group of implicit parameters, which are automatically supplied by the compiler at the call site (see fig.\ \ref{fig:implicits}).
To make a value available for implicit parameter resolution, we employ the \texttt{context let} declaration syntax.

\begin{figure}[h]
    \begin{tabular}{p{0.5\textwidth} rl}
        \begin{minipage}[t]{0.3\textwidth}
            \begin{minted}{swift}
                context(db: Db)
                func business4() {
                    db.query("...")
                }
            \end{minted}
        \end{minipage}
        &
        \begin{minipage}[t]{0.3\textwidth}
            \begin{minted}{swift}
                func caller() {
                    context let db = Db.open(...)
                    business4()
                }
            \end{minted}
        \end{minipage}
    \end{tabular}
    \caption{Reclaming static type safety with implicit parameters.}
    \label{fig:implicits}
\end{figure}

In terms of effects and contexts, \texttt{context let} introduces an execution context, whose scope is restricted to the corresponding lexical region, and provides functionality of access to a database storage.
Implicit parameters express a function's requirements for its context.
In order to invoke such a function, the context must establish its validity by supplying concrete values for these implicit parameters.
We refer to these values as \textit{capabilities}, and logically they serve as witnesses of context validity.
It is important to note, that until this point our discussion was based solely on the mechanism of bindings, and did not require any deep understanding of the abstract notion of effects.

Exceptions and other algebraic operations can be tracked in an analogous manner~\cite{odersky2021safer}.
For example, a \texttt{throw SomeException()} construct can be interpreted as calling a function that requires an implicit parameter of type \texttt{Handler<SomeException>}.
Correspondingly, constructs that handle exceptions must supply appropriate witness values for these implicit parameters.
\begin{minted}{swift}
    func checkingExceptions() {
        try { // provides a capability of type Handler<SomeException>
            throw SomeException() // requires a capability of type Handler<SomeException>
        } catch (e: SomeException) { ... }
    }
\end{minted}

Nowadays, several widely used programming languages provide support for implicit parameters, and the inference mechanisms associated with these parameters is well understood~\cite{KEEP-context-parameters, oliveira2010type, lewis2000implicit}.
Moreover, implicit parameters alone are sufficient as the evidence-passing technique to implement tail-resumptive algebraic operations~\cite{xie2020effect}.

\subsection{Retain effect safety with escape analysis} \label{subsec:escape}

An effect system should ensure that all computations are executed within appropriate contexts --- a property we refer to as \textit{effect safety}.
In our setting, the context must supply capabilities as evidence of its validity.
Consequently, these capabilities must not be allowed to escape their corresponding contexts.
For example, if a \texttt{Handler} value were to escape a corresponding \texttt{try-catch} block, we would lose the guarantee that all exceptions are handled and, thereby, the effect safety itself:
\begin{minted}{swift}
    func unsafe() {
        let f = try {
            () => throw SomeException() // captures the Handler<SomeException> capability
        } catch (e: SomeException) { ... }
        f() // throws SomeException
    }
\end{minted}

Note that, in the example, the \texttt{Handler<SomeException>} capability acts as a lexically scoped free variable for the lambda function.
The ability to close over such capabilities enables the technique known as \textit{contextual polymorphism}~\cite{brachthauser2020effects, brachthauser2022effects}.
This approach allows higher-order functions to remain fully transparent with respect to effects, without introducing explicit polymorphic type variables that range over effect sets.
Specifically, the type of a \texttt{map} function need not be entangled with effect-related parameters (we will discuss the \texttt{scoped} syntax in detail later)\footnote{We adopt the Haskell naming convention, where type names beginning with a lowercase letter denote type variables, which are implicitly universally quantified.}:
\begin{minted}{swift}
    func map(xs: List<a>, f: #\color{gray}\texttt{scoped}# (a) -> b): List<b>

    context(io: IO)
    func printAll(xs: List<Int>) {
        map(xs, (x) => io.print(x)) // capability capturing is safe here
    }
\end{minted}

Compare this with the corresponding function type in the Koka language, which features row-polymorphic types~\cite{leijen2014koka}:
\begin{minted}{kotlin}
    fun map(xs: list<a>, f: (a) -> e b): e list<b>
\end{minted}

To control the escaping of capabilities, some form of escape analysis is required. % todo citations
Given that effect systems operate at the type level, it is natural to employ type-based techniques for escape analysis as well.
Furthermore, since this analysis must account for the flow of capabilities across function boundaries, it should be cross-procedural and directly reflected in function signatures.
In the following, we provide an informal overview of the type-based escape analysis technique introduced in this paper.

We refer to values that must not escape a given scope as \textit{tracked}, and likewise, their types are treated as tracked.
For instance, capabilities are tracked, as are by default the types of implicit parameters.
To distinguish between tracked and non-tracked types, we annotate each type $T$ with a special lifetime label $lab$, denoted by the syntax:
\[scoped(lab)\ap T\]
Lifetime labels range over \texttt{free}, \texttt{local} and polymorphic lifetime variables.
The \texttt{free} label is used for non-tracked values and is assumed by default for all types.
The \texttt{local} label appears in tracked types, which the type system handles specially to prevent their escape; for instance, a function is prohibited from returning a value of a tracked type.

For example, the \texttt{map} function can be explicitly typed to ensure that it does not leak its argument function, thereby making it safe to pass closures that possess capabilities:
\begin{minted}{swift}
    func map(xs: List<a>, f: scoped(local) (a) -> b): List<b>
\end{minted}

To enable a function to propagate its arguments through its result, polymorphism over lifetime labels can be used.
In essence, this is an explicit specification of the function’s dataflow directly in the type signature. % todo dataflow term and citation
For instance, a lazy \texttt{map} function does not eagerly compute and return the final result; instead, it immediately yields a collection that encapsulates the processing logic.
This behavior can be captured by assigning the same lifetime variable~\texttt{l} to both the argument \texttt{f} and the result type.
Consequently, the type system records that any tracked capabilities captured by \texttt{f} may be retained within the result.
Such a function thus continues to support contextual polymorphism, as it can only permit \texttt{f} to escape with the result; furthermore, the call site is made aware~--- via the signature~--- that the result must not escape its prescribed context:
\begin{minted}{swift}
    func lazyMap(xs: LazyList<a>, f: scoped(l) (a) -> b): scoped(l) LazyList<b>

    context(io: IO) // io: scoped(local) IO
    func printAll(xs: LazyList<Int>) {
        let ys: scoped(local) LazyList<Int> = lazyMap(xs, (x) => io.print(x))
        ys.collect() // force execution
    }
\end{minted}

To express the capture of two or more lifetime-polymorphic values within the same scope, we employ the intersection of lifetimes:
\begin{minted}{swift}
    func compose(f: scoped(l1) (b) -> c, g: scoped(l2) (a) -> b): scoped(l1&l2) (a) -> c
        = (x) => f(g(x))
\end{minted}

For the sake of simplicity, we dispense with lifetime polymorphism for compound datatypes by determining each compound's lifetime as the intersection of the lifetimes of its components.
Upon destructuring, the lifetimes of the individual components are, in turn, approximated by the lifetime of the original compound datatype.
\begin{minted}{swift}
    func first(x: scoped(l1) Int, y: scoped(l2) Int): scoped(l1&l2) Int {
        let intPair: scoped(l1&l2) IntPair = IntPair(x, y)
        return intPair.fst
    }
\end{minted}

We define subtyping so that non-tracked values may be used in positions where tracked values are expected.
This design increases the number of safe well-typed programs and facilitates gradual adoption of effect tracking for languages transitioning from untyped effects to an effect system.

We permit tracked types to instantiate polymorphic type parameters, thereby making them first-class citizens in the language.
To control when tracked types are eligible for instantiation, we employ bounded polymorphism.
For example, the \texttt{lazyMap} function is written in such a way that it does not leak values of polymorphic type parameters (e.g., through global state), but rather returns them directly to the caller.
As a result, these parameters may be instantiated with tracked types:\footnote{We assume that \texttt{Any} serves as the top element in the type lattice.} \footnote{For backward compatibility, the type \texttt{scoped(free) Any} may be used as the default bound.}
\begin{minted}{swift}
    func lazyMap(xs: LazyList<a>, f: scoped(l) (a) -> b): scoped(l) LazyList<b>
        where a <: scoped(local) Any, b <: scoped(local) Any
\end{minted}

Various techniques can be employed to reduce boilerplate associated with lifetime polymorphism and the specification of bounds.
For example, the lifetime elision mechanism in the Rust language~\cite{matsakis2014rust} uses heuristics to automatically insert lifetime variables, thereby alleviating the need for explicit annotation.
In our approach, using the \texttt{scoped} keyword without a specific lifetime parameter similarly invokes the elision mechanism.
We will discuss this technique, along with alternative methods, in Section~\ref{subsec:lifetime-elision}.

The utility of type-based escape analysis extends well beyond its role in the construction of effect systems.
Specifically, it can be leveraged to reduce the number of heap allocations~\cite{lorenzen2024oxidizing}, enable borrowing for the ownership-based resource management~\cite{matsakis2014rust, lorenzen2024oxidizing}, and ensure the safety of non-local returns~\cite{akhin2021kotlin}.

\subsection{Summary} \label{subsec:idea-summary}

An effect system can be regarded as the integration of implicit parameters with type-based escape analysis.
Consequently, the design of an effect system naturally decomposes into two distinct components and can be developed incrementally in a step-by-step manner.

In fact, our previous discussion has primarily focused on free variables.
Indeed, a term inherently depends on its context via its free variables, acquiring different semantics depending on the particular context in which it is evaluated.
So, free variables are the target for effect systems, while bound once are regulated by canonical type systems.

Our perspective on effect systems arises from a fundamental observation: the semantics of free variables can be defined by two principal scoping disciplines~--- dynamic and lexical scoping.
Adopting one or the other proves advantageous depending on the programming scenario.
We summarize the correspondence between these two disciplines in Figure~\ref{fig:free-vars} and further discuss the relationship to existing approaches in effect system design in Section~\ref{sec:related}.

\begin{figure}
    \centering
    \begin{tabular}{|l|l|l|}
        \hline
        Free variables & dynamically scoped & lexically scoped \\
        \hline
        Represent & unfulfilled context requirements & fulfilled context requirements \\
        Dealt by & implicit parameters & type-based escape analysis \\
        User specifies & more function parameters & a function’s dataflow \\ % todo other analysis may require something different
        \hline
    \end{tabular}
    \caption{Effect systems are for managing free variables.}
    \label{fig:free-vars}
\end{figure}


\section{Core calculus} \label{sec:core}

In this section we introduce a convenient for us explicitly typed call-by-value core calculus $Core$ that we will extend later with omitting application and type-based escape analysis.

\subsection{Effect handlers} \label{subsec:handlers}

In our formal elaborations we are going to use effect handlers as a universal mechanism for defining effects~\cite{plotkin2003algebraic, plotkin2013handling}, because it is powerful enough to express all effects of interest, thus we do not need to consider them one by one.
At the same time, unlike monad transformers~\cite{liang1995monad, schrijvers2019monad}, dynamic semantics of effect handlers can be defined on its own without any type-directed translation, hence, it does not impose any restrictions on the effect system design.

Let us give a brief introduction to effect handlers and show how to use them to implement effects, discussed in the previous section~\ref{sec:idea}.

The \texttt{handle} construct allows to define an execution context for a particular scope by defining a set of operations.
The \texttt{perform} construct can be used by the code in the scope to call operations defined by a handler as an act of context interaction.
We use lexically scoped handlers which require \texttt{perform} to refer to a specific instance of a handler with a binding~\cite{biernacki2019binders, brachthauser2020effects}.
An implementation of each operation has access to a continuation of a call site, which can be used to return a result.

For example, we can define an execution context providing a specific constant to a computation.
To do so, we provide a handler of a \texttt{Reader} effect that provides \texttt{ask} operation returning a constant.
A computation sums two invocations of \texttt{ask}, so the overall result will be $42$:
\[
    \begin{array}{l}
        \keyword{handle} ~ h : Reader\ap Int ~\keyword{with}~ \{ ask = \lambda k\ldotp k\ap 21 \} ~\keyword{in} \\
        \keyword{perform}~ask~h~() + \keyword{perform}~ask~h~()
    \end{array}
\]

To implement exceptions, \texttt{throw} operation should simply throw away the continuation.
The following program returns a thrown number $42$:
\[
    \begin{array}{l}
        \keyword{handle}~ h : Exception\ap Int ~\keyword{with}~ \{throw = \lambda e~k\ldotp e \} ~\keyword{in} \\
        \keyword{perform}~throw~h~42
    \end{array}
\]

Other algebraic effects like mutable state and nondeterminism can be implemented with \texttt{handle} construct as well. % todo citations

%\begin{equation}
%    \begin{array}{l}
%        \keyword{handle}~ h : State\ap Int ~\keyword{with}~ \{\\
%        \indent get = \lambda k\ldotp\lambda s\ldotp k\ap s\ap s \\
%        \indent put = \lambda s'~k\ldotp\lambda s\ldotp k\ap ()\ap s' \\
%        \} ~\keyword{in}~ \\
%        perform~put~h~42; perform~get~h~42
%    \end{array}
%\end{equation}

\subsection{Syntax of $Core$} \label{subsec:syntax-core}

Let us discuss the syntax of $Core$ (fig.\ \ref{fig:core-syntax}).
By the over-line we denote a bunch of corresponding entries.
Constructs highlighted with gray are used only for an operational semantics.
Our considerations that lead to this syntax are the following:
\begin{itemize}
    \item We split arguments into two groups, first group contains \textit{contextual arguments} that will be inferred automatically later.
    This separation helps us to build algorithmic typing rules as functional type distinguishes contextual and ordinary arguments.
    \item We use uncurried abstraction and application to make future implicit parameters inference local in a sense that typing information available to an application rule is enough~\cite{pierce2000local}.
    \item For the same purpose we couple contextual and ordinary parameters.
    \item Capability constructors $K_{cap}$ are used in an operational semantics as a representation of a capability. % todo cite generalized evidence passing?
    \item $handle$ construct creates a capability associated with a corresponding handler and binds it with a name.
    At the same time $perform$ construct requires a capability to perform an effect.
    This approach helps us to naturally build an effect system from the point of view we discussed before (Section~\ref{sec:idea}).
    \item For brevity, we do not include $return$ block in handlers, because it does not add any expressiveness.
    \item $handler_m$ construct serves as a continuation delimiter with a unique marker $m$ for an operational semantics.
    \item In a function type $\ctx{e} \overline{\tau} \to \sigma$, over-line means a tuple of arguments, where the empty tuple is a unit value.
    So, only an explicit application can cause effects, they cannot happen accidentally with a variable mention.
    \item Typing context distinguishes between regular bindings and \textit{contextual bindings}.
    Contextual ones are only allowed to have monotypes.
    We might have two separate typing contexts, but this would have required us to have different sets for contextual and ordinary bindings.
\end{itemize}

\begin{figure}
    \centering
    \begin{gather*}
        \begin{array}{lrll}
            \text{Variables} & & x, y, z, f, g, op \\
            \text{Values} &v &\Coloneqq x \vor \Lambda \overline{\alpha} \ldotp v \\
            &&\vor K\ap \overline{\tau} \ap \overline{t} \vor \graybox{K_{cap}\ap\overline{\tau}\ap m\ap h} \\
            &&\vor \lambda \overline{x : \tau}~\overline{y : \sigma}\ldotp t
            \\
            \text{Terms} &t, u &\Coloneqq v \vor t\ap\overline{\tau} \vor t \ap \overline{t} \ap \overline{t} \\
            &&\vor match ~ t ~ with ~\{\overline{K \ap \overline{x} \to t}\} \\
            &&\vor perform ~ op \ap x \ap \overline{\tau} \ap \overline{t} \\
            &&\vor handle ~ x : T \ap \overline{\tau} ~with ~h~in ~t \\
            &&\vor \graybox{handler_m ~ t}
            \\
            \text{Handlers} &h &\Coloneqq \{ \overline{op = t} \}
            \\
            \text{Programs} &p &\Coloneqq \epsilon \vor x : s = t, p
        \end{array}
        \begin{array}{lrl}
            \text{Type variables} && \alpha, \beta \\
            \text{Type constructors} && T \\
            \text{Monotypes} & \tau, \sigma, \eta &\Coloneqq \alpha \vor T \ap \overline{\tau} \vor \ctx{e} \overline{\tau} \to \sigma \\
            \text{Type schemas} & s &\Coloneqq \forall\overline{\alpha}\ldotp \tau \\
            \text{Effect rows} & e &\Coloneqq \epsilon\vor \tau, e \\
            \text{Typing contexts} & \Gamma &\Coloneqq \emptyset \vor x : s, \Gamma \vor x :_c \tau, \Gamma \\
            \text{Effect contexts} & \Sigma &\Coloneqq \{\overline{K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap\overline{\alpha}}\} \\
            \text{Effect signatures} & sig &\Coloneqq \{\overline{op : \forall\overline{\alpha}\ldotp\overline{\tau}\to\sigma}\} \\
            \text{Data constructors} & & K : \forall\overline{\alpha}\ldotp \overline{\tau}\to T\ap \overline{\alpha} \\
            \text{Free type variables} & & ftv(\cdot) \\
        \end{array}\\
        \begin{aligned}
            \text{Evaluation context } E \Coloneqq \square \vor E \ap \overline{\tau} \vor E \ap \overline{t}\ap \overline{t} \vor v \ap (\overline{v}, E, \overline{t}) \ap \overline{t} \vor v \ap \overline{v} \ap (\overline{v}, E, \overline{t}) \vor handler_m ~ E
        \end{aligned}\\
    \end{gather*}
    \caption{Syntax of $Core$.}
    \label{fig:core-syntax}
\end{figure}

Note that the type of first-class functions contains a list of implicit parameters.
It allows to type the abstraction over handlers.
For example, the following function establishes en execution context with a handler for an exception type \texttt{E}\footnote{We use informally defined surface syntax for explanations. Its correspondence to our formal definitions is straight-forward.}:
\begin{minted}{swift}
    func withE(f: context(Handler<E>) () -> r): r =
        try { f() } catch (e: E) { ... }
\end{minted}

We assume that an effect context $\Sigma$ is populated by user's \texttt{effect} declarations like ones in Koka. % todo citation
Namely, for a program with the following declaration, $\Sigma = \{EffK : \forall\alpha\ldotp\{id : \forall\beta\ldotp b\to b, yield : a \to Unit\} \to Eff\ap a\}$ (there is a bijection between capability constructors and effect types):
\begin{minted}{swift}
    effect Eff<a> {
        op id(x: b): b
        op yield(x: a): Unit
    }
\end{minted}

\subsection{Operational semantics of $Core$}

Let us get through the most interesting parts of our semantics (fig.\ \ref{fig:core-operational}):
\begin{itemize}
    \item (handle) selects a capability constructor corresponding to a provided effect types $T$ and uses it to create a capability.
    Also, it allocates a fresh marker $m$ and installs it with $handler$ construct.
    \item (perform) destructs a capability, selects an operation and executes it with a current continuation delimited by a corresponding marker.
    We use deep handlers~\cite{hillerstrom2018shallow}, so handler is reinstalled in a continuation.
\end{itemize}

\begin{figure}
    \[
        \begin{array}{llll}
            \text{(tapp)} &(\Lambda \overline{\alpha}\ldotp t) \ap \overline{\tau} &\longrightarrow &[\overline{\alpha\to\tau}]\ap t
            \\
            \text{(app)} &(\lambda \overline{x}~\overline{y}\ldotp t) \ap \overline{v} \ap \overline{v'} &\longrightarrow &[\overline{x\to v}, \overline{y\to v'}]\ap t
            \\
            \text{(match)} &match ~K \ap \overline{v}~ with ~ \{ \overline{K_i \ap \overline{x} \to u_i}\} &\longrightarrow &[\overline{x\to v}]\ap u_k, \text{ where } K = K_k
            \\
            \text{(handle)} &handle ~ x : T \ap \overline{\tau} ~with~h~in~t &\longrightarrow & handler_m ~[x \to K_{cap} \ap\overline{\tau}\ap m \ap h] \ap u
            \\
            &&\text{where} & m \text{ fresh}, {\color{gray}K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap\overline{\alpha} \in \Sigma}
            \\
            \text{(return)} &handler_m ~v &\longrightarrow & v
            \\
            \text{(perform)} &handler_m~E[perform \ap op \ap (K_{cap}\ap\overline{\tau_1}\ap m \ap h)\ap\overline{\tau_2}\ap\overline{v}] &\longrightarrow &t \ap \overline{\tau_2}\ap \overline{v}\ap k
            \\
            &&\text{where} & (op = t) \in h, {\color{gray}\theta = [\overline{\alpha\to\tau_1}, \overline{\beta\to\tau_2}],} \\
            &&& {\color{gray}K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap\overline{\alpha} \in \Sigma,} \\
            &&& {\color{gray}(op : \forall\overline{\beta}\ldotp\overline{\sigma}\to\sigma') \in sig,} \\
            &&& k = \lambda x : \theta\ap\sigma' \ldotp handler_m~E[x]
        \end{array}
    \]
    \vspace{-3em}
    \[
        \hspace{-15em}\infer[\text{(step)}]{E[t]\longrightarrow E[t']}{t\longrightarrow t'}
    \]
    \caption{Operational semantics of $Core$.}
    \label{fig:core-operational}
\end{figure}

Note that every $perform$ addresses a particular handler, so there is no effect encapsulation problem~\cite{lindley2018encapsulating}: an effect cannot be accidentally handled. % todo more citations
For example, the following function will not be able to intercept \texttt{E2} exception potentially thrown in \texttt{f}, because \texttt{withE1} do not explicitly provide \texttt{f} a corresponding capability:
\begin{minted}{swift}
    func withE1(f: context(Handler<E1>) () -> r): r =
        try { f() } catch (e: E1) { ... } catch (e: E2) { /* unreachable */ }
\end{minted}

Since we propagate a handler to an operation call site, we can avoid handler lookup and collection of a continuation if a callee operation is tail-resumptive~\cite{xie2020effect}.
In a low-level implementation such $perform$ can be replaced with a virtual call. % todo citation

TODO theorems % todo theorem about determinism (and mb others)

\subsection{Typing rules for $Core$}

\begin{itemize}
    \item Typing rules for $Core$ (fig.\ \ref{fig:core-typing}) are algorithmic.
    \item We skip type well-formedness conditions and never-changing effect context $\Sigma$ for brevity.
    \item An entry in an effect context $\Sigma$ and be uniquely identified by a capability type, so we use $\Sigma$ as a function: $\Sigma(T) = \forall\overline{\alpha}\ldotp sig \iff K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap\overline{\alpha}\in\Sigma$.
    \item Elements in the typing context be unique with respect to variable names.
\end{itemize}

%! suppress = EscapeAmpersand
\begin{figure}
    \begin{gather*}
        \mathframebox{\Gamma\vdash t : \tau} \\
        \infer[Var]{\Gamma\vdash x\ap\overline{\tau} : [\overline{\alpha\to\tau}]\ap\sigma}{x : \forall\overline{\alpha}\ldotp \sigma \in \Gamma}
        \text{\hspace{2em}}
        \infer[CVar]{\Gamma\vdash x : \tau}{x :_c \tau \in \Gamma} \\
        \infer[Lam]{
            \Gamma\vdash \lambda \overline{x : \tau_1} ~ \overline{y : \tau_2} \ldotp t : ctx(\overline{\tau_1}) ~ \overline{\tau_2} \to \sigma
        }{
            \overline{x :_c \tau_1}, \overline{y : \tau_2}, \Gamma\vdash t : \sigma &
            \overline{\tau_1} \text{ distinct}
        }
        \text{\hspace{2em}}
        \infer[App]{
            \Gamma\vdash t \ap \overline{u_1} \ap \overline{u_2} : \sigma
        } {
            \Gamma\vdash t : ctx(\overline{\tau_1})~\overline{\tau_2}\to\sigma
            &
            \overline{\Gamma\vdash u_1 : \tau_1}
            &
            \overline{\Gamma\vdash u_2 : \tau_2}
        }\\
        \infer[Match]{
            \Gamma\vdash match ~ t ~with ~\{ \overline{K_i\ap \overline{x_j} \to u_i }\}  : \sigma
        }{
            K_i : \forall \overline{\alpha}\ldotp \overline{s_j} \to T\ap\overline{\alpha} &
            \Gamma\vdash t : T \ap\overline{\tau} &
            \overline{x_j : [\overline{\alpha\to\tau}]\ap s_j}, \Gamma \vdash u_i : \sigma
        }\\
        \infer[Perform]{
            \Gamma\vdash perform \ap op\ap \overline{\tau_2}\ap x\ap \overline{t} : \theta\ap\eta
        }{
            \Gamma\vdash x : T\ap \overline{\tau_1} &
            \Sigma(T) = \forall\overline{\alpha}\ldotp sig &
            op : \forall\overline{\beta}\ldotp \overline{\sigma}\to\eta \in sig &
            \theta = [\overline{\alpha\to\tau_1}, \overline{\beta\to\tau_2}] &
            \overline{\Gamma\vdash t : \theta\ap\sigma}
        }\\
        \infer[Handle]{
            \Gamma \vdash handle ~ x : T\ap\overline{\tau}~ with ~ \{\overline{op_i = t_i}\} ~in~u : \eta
        }{
            \begin{gathered}
                x :_c T\ap\overline{\tau}, \Gamma\vdash u : \eta
            \end{gathered}
            &
            \begin{array}{ll}
                \overline{\beta}\not\cap ftv(\eta) & % todo beautify intersection
                \Sigma(T) = \forall\overline{\alpha}\ldotp sig, \hspace{0.5em} op_i : \forall\overline{\beta}\ldotp \overline{\sigma}_i\to\sigma'_i \in sig
                \\
                \theta = [\overline{\alpha\to\tau}] &
                \Gamma\vdash\theta\ap t_i : \forall \overline{\beta}\ldotp \overline{\theta\ap\sigma_i}\to(\theta\ap\sigma_i'\to\eta)\to\eta
            \end{array}
        }\\
        \infer[Cap]{
            \Gamma\vdash K_{cap}\ap\overline{\tau}\ap m\ap h : T\ap\overline{\tau}
        }{
            K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap\overline{\alpha} \in \Sigma
        } % todo looks like a bull shit
        \hspace{2em}
        \infer[Handler]{
            \Gamma\vdash handler_m ~t : \tau
        }{
            \Gamma\vdash t : \tau
        }\\
        \begin{array}{ccccc}
            \mathframebox{\Gamma\vdash t : s} &
            \infer[TLam]{
                \Gamma\vdash\Lambda\overline{\alpha}\ldotp v : \forall\overline{\alpha}\ldotp\tau
            }{
                \Gamma\vdash v : \tau & ftv(\tau) = \overline{\alpha}
            } &
            \mathframebox{\Gamma\vdash p} &
            \infer[\epsilon Prog]{\Gamma\vdash\epsilon}{} &
            \infer[Prog]{\Gamma\vdash x : s = t, p}{\Gamma\vdash t : s & \Gamma\vdash p}
        \end{array}
    \end{gather*}
    \caption{Typing rules for $Core$.}
    \label{fig:core-typing}
\end{figure}

TODO formulate properties % todo

\section{Design of implicit parameters} \label{sec:implicits}

In this section we discuss design decisions for implicit parameters feature that make it more suitable as a component of a practical effect system.
Along the discussion we introduce a formal calculi with implicit parameters $Core^{im}$ as an extension to $Core$.

\subsection{Syntax of $Core^{im}$}

We extend syntax of $Core^{ex}$ with an omitting application, which do not specify the first block of contextual arguments:
\[
    \begin{array}{lcc}
        \text{Terms} & t, u &\Coloneqq \ldots \vor t\ap\overline{t} \vor \ldots
    \end{array}
\]

\subsection{Inference of implicit parameters} \label{subsec:inference}

We give a type-directed translation from $Core^{im}$ to $Core$ (fig.\ \ref{fig:fim-fex-inference}).
Making translation rules for other constructs from typing rules for $Core$ is straight-forward.

$\Gamma\vdash_e \overline{x}$ relation selects from the typing context variables participating in the inference with given effect types.
Note that since the typing context only stores bindings with unique names, a user can shadow a contextual binding with an ordinary one, and it will not participate in the inference anymore.
This issue can be solved, for instance, by making typing context a list with duplications and assigning fresh names to contextual bindings.

\begin{figure}
    %! suppress = EscapeAmpersand
    \begin{gather*}
        \mathframebox{\Gamma\vdash t : \tau \step t_{c}} \\
        \infer[CtxApp]{
            \Gamma\vdash t\ap\overline{u} : \sigma \step t_{c} \ap \overline{x}\ap\overline{u_{c}}
        }{
            \Gamma\vdash t : \ctx{e} \overline{\tau} \to \sigma \step t_{c} &
            \Gamma\vdash_e\overline{x} &
            \overline{\Gamma\vdash u : \tau \step u_{c}}
        } \\
        \mathframebox{\Gamma\vdash_e \overline{x}}
        \text{\hspace{2em}}
        \infer[Infer]{\Gamma\vdash_{\overline{\tau}} \overline{x}}{\overline{x :_c \tau}\subset \Gamma}
    \end{gather*}
    \caption{Inference of implicit parameters.}
    \label{fig:fim-fex-inference}
\end{figure}

There is a design decision to be made, whether inference should rely only on types, or on variable names as well.
The second option is a bit more complicated than the first one, since it requires to store variables names in the effect rows.
Moreover, it excludes renaming of implicit parameters from $\alpha$-equivalence, making a program more fragile regarding renaming.
On the other hand, it allows to use simultaneously multiple effects of the same type.
This problem attracts many attention from researchers. % todo citations
However, we use the first option and argue that in practical programming using multiple effects of the same type is mostly undesired.
We believe that users should provide many domain-specific effects instead of using basic ones directly.
For example, some \texttt{UserRepository} effect is preferable to general \texttt{Database} effect, since it provides higher-level of abstraction.

Another decision is when to substitute implicit parameters, on mentioning or, deferred, on application.
It is a similar question to the type instantiation with first-class polymorphism (type inference infers type parameters)~\cite{emrich2020freezeml}. % todo verify citation
Both ways are useful: the first is convenient with contextually-polymorphic functions \texttt{map(xs, f)}, the second helps with effect abstraction \texttt{withSomeException(f)}. % todo introduce effect abstraction somewhere % todo citations to kotlin, haskell and something
Actually, the decision is about choosing the default, since one behaviour can be changed to another by the $\eta$-expansion. % todo explain better, examples
Namely, assume that the substitution occurs on application:
\begin{minted}{swift}
    f : context(IO) () -> Unit; g : (() -> Unit) -> Unit
    g(() => f())
\end{minted}
Or, assume that substitution occurs on mentioning:
\begin{minted}{swift}
    f : context(IO) () -> Unit; g : (context(IO) () -> Unit) -> Unit
    g(context(_: Eff) () => f()) // abstracts over contextual parameters
\end{minted}
% todo special syntax for explicitly passed implicits
% todo have i introduced surface implicit abstraction somewhere
% todo have i introduced the surface syntax anywhere

TODO properties % todo

\subsection{System $Core^{im+<:}$ with implicit parameters and subtyping} \label{subsec:im-sub}

It is convenient to have some form of subtyping on effect rows, since a function with less context requirements can naturally be used in more permissive contexts.
For example, \texttt{withStd} is a function that provides default implementation for many effects.
We should be able to pass a function that uses only some of them:
\begin{minted}{swift}
    func withStd(f: context(IO, Allocator, Random) () -> r): r
    withStd(g) // g : context(IO) () -> Unit
\end{minted}

% todo find literature
% todo row polymorphism can help somehow?
% todo cite papers about row types
Contexts can be seen as structural record types with width and permutation subtyping.
However, the naive implementation of such records as dictionaries is not very efficient in time and space.

To achieve an efficient implementation of subtyping, we restrict it to be shallow in a sense that one functional type subtypes another only if one effect row subtypes another, while arguments and return types should be the same:
\[
    \infer{\ctx{e} \tau \to \sigma <: \ctx{e'} \tau\to\sigma}{e' <: e}
\]

Now we can implement such shallow subtyping by $\eta$-expansion (fig.\ \ref{sig:fim-sub-app}).
Relation $\Gamma\vdash t\Leftarrow \tau \step t_c$ performs $\eta$-expansion if a functional type is expected.

\begin{figure}
    %! suppress = EscapeAmpersand
    \begin{gather*}
        \mathframebox{\Gamma\vdash t : \tau \step t_c} \\
        \infer[App]{
            \Gamma\vdash t\ap\overline{u} : \eta \step t_c \ap \overline{x} \ap \overline{u_c}
        }{
            \Gamma\vdash t : ctx(\overline{\tau})~\overline{\sigma}\to \eta \step t_c
            &
            \Gamma \vdash_{\overline{\tau}} \overline{x}
            &
            \overline{\Gamma\vdash u \Leftarrow \sigma \step u_c}
        } \\
        \mathframebox{\Gamma\vdash t \Leftarrow \tau \step t_c} \\
        \infer[AppArg]{
            \Gamma\vdash t \Leftarrow \tau \step t_c
        }{
            \Gamma\vdash t : \tau \step t_c
        }
        \text{\hspace{1em}}
        \infer[AppArgCtx]{
            \Gamma \vdash t \Leftarrow ctx(\overline{\tau}) ~\overline{\sigma}\to\eta\step \lambda \overline{x : \tau}~\overline{y : \sigma}\ldotp t_c\ap \overline{x'}\ap\overline{y}
        }{
            \Gamma \vdash t : ctx(\overline{\tau'}) ~\overline{\sigma}\to\eta \step t_c
            &
            \overline{x :_c \tau} \vdash_{\overline{\tau'}} \overline{x'}
            &
            \overline{x~y \text{ fresh}}
        }
    \end{gather*}
    \caption{Application rule for $Core^{im + <:}$.}
    \label{sig:fim-sub-app}
\end{figure}

% todo link to bidirectional typing

% todo big lambda inference

% todo will subtyping break inference?

% todo what if generate application (like for dictionaries) to reorder effect rows (do inhabitation of some form)?

\section{Design of type-based escape analysis} \label{sec:escape}

In this section we develop an extension to the previously discussed systems, which statically ensure that no capabilities escape from corresponding handlers.

% todo a bit about general idea like in the introduction mb
% todo existential types and ST-trick
% todo mb brief lit overview

\subsection{Syntax of $Core_\Delta$}

Let us introduce a $Core_\Delta$, that extends $Core$ with lifetimes, lifetime polymorphism and bounded polymorphism.
Changes in the syntax of types (fig.\ \ref{fig:core-delta-syntax}) are highlighted with gray.
\begin{itemize}
    \item Monotypes are now augmented with a lifetime parameter.
    \item Type schemas support abstraction over lifetimes and bounds.
\end{itemize}

% todo tracked term

%! suppress = MissingLabel
\begin{figure}
    \[
        \begin{array}{lrl}
            \text{Type variables} && \alpha, \beta \\
            \text{Type constructors} && T \\
            \text{Lifetime variables} && \graybox{l} \\
            \text{Lifetimes} & \graybox{\Delta} &\Coloneqq l \vor local \vor free \vor \&\overline{\Delta} \\
            \text{Monotypes} & \tau, \sigma, \eta &\Coloneqq \alpha \vor T \ap \graybox{\Delta} \ap \overline{\tau} \vor \ctx{e} \graybox{\Delta}~\overline{\tau} \to \sigma \\
            \text{Type schemas} & s &\Coloneqq \forall \graybox{\overline{l}}~\overline{(\alpha \graybox{<: \tau})}\ldotp \sigma \\
            \text{Effect rows} & e &\Coloneqq \epsilon\vor \tau, e \\
            \text{Typing contexts} & \Gamma &\Coloneqq \emptyset \vor x : s, \Gamma \vor x :_c \tau, \Gamma \vor \graybox{\alpha <: \tau, \Gamma} \\
            \text{Effect contexts} & \Sigma &\Coloneqq \{\overline{K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap \graybox{local} \ap\overline{\alpha}}\} \\
            \text{Effect signatures} & sig &\Coloneqq \{\overline{op : \forall\overline{(\alpha \graybox{<: \eta})}\ldotp\overline{\tau}\to\sigma}\} \\
            \text{Data constructors} & & K : \forall\graybox{\overline{l}}\ \overline{\alpha}\ldotp \overline{\tau}\to T \ap\graybox{(\&\overline{lt_+(\tau)}\cup\overline{l})}\ap \overline{\alpha} \\
            \text{Free type variables} & & ftv(\cdot) \\
            \text{Positive lifetimes} & & \graybox{lt_+(\cdot)} \\
            \text{Free lifetime variables} & & \graybox{flt_+(\cdot)}, \graybox{flt_-(\cdot)}
        \end{array}
    \]
    \caption{Syntax of types for $Core_\Delta$.}
    \label{fig:core-delta-syntax}
\end{figure}

Syntax of terms follows the changes in the syntax of types:
\[
    \begin{array}{lll}
        \text{Values} & v & \Coloneqq \ldots \vor \Lambda \graybox{\overline{l}}\ap\overline{\alpha}\ldotp v \vor K\ap\graybox{\overline{\Delta}}\ap\overline{\tau}\ap\overline{t} \vor \ldots \\
        \text{Terms} & t, u &\Coloneqq \ldots \vor t\ap\graybox{\overline{\Delta}}\ap\overline{\tau} \vor handle ~ x : T \ap\graybox{local}\ap \overline{\tau} ~with ~h~in ~t \vor \ldots
    \end{array}
\]

\subsection{Typing rules for $Core_\Delta$}

There are three

\begin{itemize}
    \item % todo
\end{itemize}

%! suppress = EscapeAmpersand
\begin{figure}
    \begin{gather*}
        \mathframebox{\Gamma\vdash t : \tau} \\
        \infer[Var]{
            \Gamma\vdash x\ap\overline{\Delta}\ap\overline{\tau} : [\overline{l\to\Delta}]\ap[\overline{\alpha\to\tau}]\ap\sigma
        }{
            x : \forall\overline{l}\ap(\overline{\alpha <: \tau'})\ldotp \sigma \in \Gamma &
            \Gamma\vdash\tau <: [\overline{l\to\Delta}]\ap\tau'
        }
        \text{\hspace{2em}}
        \infer[CVar]{\Gamma\vdash x : \tau}{x :_c \tau \in \Gamma} \\
        \infer[Lam]{
            \Gamma\vdash \lambda \overline{x : \sigma} ~ \overline{y : \sigma'} \ldotp t : ctx(\overline{\sigma}) \left(\&{\overline{lt_+(\tau)}}\right)~ \overline{\sigma'} \to \eta
        }{
            \overline{x :_c \sigma}, \overline{y : \sigma'}, \Gamma\vdash t : \eta &
            \overline{\sigma} \text{ distinct} &
            \Gamma\vdash_{fv(t)}\overline{\tau} &
            local\not\in lt_+(\eta)
        } \\
        \infer[App]{
            \Gamma\vdash t \ap \overline{u_1} \ap \overline{u_2} : \eta
        } {
            \Gamma\vdash t : \ctx{\overline{\tau}} \Delta~\overline{\sigma}\to\eta
            &
            \begin{array}{c}
                \overline{\Gamma\vdash u_1 : \tau'} \\
                \overline{\Gamma\vdash\tau' <: \tau}
            \end{array}
            &
            \begin{array}{c}
                \overline{\Gamma\vdash u_2 : \sigma'} \\
                \overline{\Gamma\vdash\sigma' <: \sigma}
            \end{array}
        }\\
        \infer[Match]{
            \Gamma\vdash match ~ t ~with ~\{ \overline{K_i\ap \overline{x_j} \to u_i }\}  : \eta
        }{
            \begin{array}{c}
                K_i : \forall \overline{l}~\overline{\alpha}\ldotp \overline{\sigma_j} \to T\ap(\&\overline{lt_+(\sigma)}\cup\overline{l})\ap\overline{\alpha}
                \text{\hspace{1em}}
                \Gamma\vdash t : T\ap\Delta \ap\overline{\tau}
                \\
                \overline{x_j : [\overline{\alpha\to\tau}, \overline{flt_+(\sigma_j)\to\Delta}, \overline{flt_{-}(\sigma_j)\to free}]\ap \sigma_j}, \Gamma \vdash u_i : \eta
            \end{array}
        }\\
        \infer[Perform]{
            \Gamma\vdash perform \ap op\ap \overline{\tau_2}\ap x\ap \overline{t} : \theta\ap\eta
        }{
            \begin{array}{ccc}
                \Sigma(T) = \forall\overline{\alpha}\ldotp sig &
                \Gamma\vdash x : T\ap \Delta \ap \overline{\tau_1} &
                \overline{\Gamma\vdash t : \sigma'}
                \\
                op : \forall\overline{\beta}\ldotp \overline{\sigma}\to\eta \in sig &
                \theta = [\overline{\alpha\to\tau_1}, \overline{\beta\to\tau_2}] &
                \overline{\Gamma\vdash\sigma' <: \theta\ap\sigma}
            \end{array}
        }\\
        \infer[Handle]{
            \Gamma \vdash handle ~ x : T\ap\overline{\tau}~ with ~ \{\overline{op_i = t_i}\} ~in~u : \eta
        }{
            \begin{array}{cll}
                x :_c T\ap local\ap\overline{\tau}, \Gamma\vdash u : \eta & \overline{\beta}\not\cap ftv(\eta) & % todo beautify intersection
                \Sigma(T) = \forall\overline{\alpha}\ldotp sig \hspace{1em} op_i : \forall\overline{\beta}\ldotp \overline{\sigma}_i\to\sigma'_i \in sig
                \\
                local \not\in lt_+(\eta)\cup\overline{lt_+(\sigma)} & \theta = [\overline{\alpha\to\tau}] &
                \Gamma\vdash\theta\ap t_i : \forall \overline{\beta}\ldotp \overline{\theta\ap\sigma_i}\to(\theta\ap\sigma_i'\to\eta)\to\eta
            \end{array}
        }\\
        \infer[Cap]{
            \Gamma\vdash K_{cap}\ap\overline{\tau}\ap m\ap h : T\ap local \ap\overline{\tau}
        }{
            K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap\overline{\alpha} \in \Sigma
        }
        \hspace{2em}
        \infer[Handler]{
            \Gamma\vdash handler_m ~t : \tau
        }{
            \Gamma\vdash t : \tau
        }\\
        \begin{array}{cccc}
            \mathframebox{\Gamma\vdash t : s} &
            \infer[TLam]{
                \Gamma\vdash\Lambda\overline{l}\ap\overline{(\alpha <: \sigma)}\ldotp v : \forall\overline{l}\ap\overline{(\alpha <: \sigma)}\ldotp\tau
            }{
                \Gamma\vdash v : \tau & flt(\tau) = \overline{l} & ftv(\tau) = \overline{\alpha}
            } &
            \mathframebox{\Gamma\vdash_{\overline{x}}\overline{\tau}}
            &
            \infer[TypesOf]{\Gamma\vdash_{\overline{x}}\overline{\tau}}{\overline{x :_\cdot \tau} \subset \Gamma}
        \end{array} \\
        \begin{array}{ccc}
            \mathframebox{\Gamma\vdash p} &
            \infer[\epsilon Prog]{\Gamma\vdash\epsilon}{} &
            \infer[Prog]{\Gamma\vdash x : s = t, p}{\Gamma\vdash t : s & \Gamma\vdash p}
        \end{array}\\
        \begin{array}{cccc}
            \mathframebox{\Gamma\vdash \sigma <: \tau} &
            \infer[SubAny]{\Gamma\vdash \sigma <: Any\ap local}{} &
            \infer[SubT]{\Gamma\vdash T\ap\Delta' <: T\ap\Delta}{\Delta' <: \Delta} &
            \infer[SubBound]{\Gamma\vdash \alpha <: \tau}{\alpha <: \tau \in \Gamma}
        \end{array} \\
        \begin{array}{cccc}
            \mathframebox{\Delta' <: \Delta} &
            \infer[SubFree]{free <: \Delta}{} &
            \infer[SubLocal]{\Delta <: local}{} &
            \infer[Sub\&]{\Delta' <: \&\overline{\Delta}}{local\in\overline{\Delta}}
        \end{array}
    \end{gather*}
    % todo где нужна информация про баунд дженерика?
    \caption{Typing rules for $Core_{\Delta}$}
    \label{fig:core-delta-typing}
\end{figure}

% todo integration with implicit inference

% todo higher-rank polymorphism is required for lambdas, иначе ничего не будет работать с абстракцией по хендлерам. Хотя можно просто всё сделать локалом в контексте по умолчанию, но тогда могут быть траблы с кепчурингом. Нужно исследовать, можно ли это как-то попроще добавить.

%todo \cite{hannan1998type, boruch2023capturing}

%todo \section{Semantics} \label{sec:semantics}

% todo Barendregt’s ‘variable convention for simplicity?
%
%TODO % todo or make it a part of a regular discussion

% todo ensure that the innermost handlers receives the operation
% todo refer to a paper that proposed to instantiate a handle_m frame

% todo bounds instead of boxing (from capturing types)
% todo lifetimes in the middle instead of `here` mode (to allow handlers consume tracked things)

% todo link to first class names for effect handlers

% todo lifetime tunelling reduce amount of boilerplate for polymorphic code

% todo невозможность отсылать локальные вещи операциям это слишком жестко, нужно ослабить, иначе даже в массив сложит трекаемые вещи в одном скоупе не получится

% todo update on inference

% todo why tunelling (otherwise too much code duplication on polymorphic code)

% todo resources that can leak


\section{Adoption in mainstream languages} \label{sec:mainstream}

% todo every method is a higher-order function (see citatioon in Capturing types)

\subsection{Simplifying lifetime polymorphism} \label{subsec:lifetime-elision}

% todo OOP
% todo escape hatches

TODO % todo

\subsection{Escaping from an effect system}

% todo unsafe escape hatches



TODO % todo

\subsection{Migrating to an effect system}

TODO % todo

\subsection{Working with OOP}

TODO % todo


% todo abstraction inference
% todo bidirectional semantics and higher-order effects


\section{Related work} \label{sec:related}

% todo capture calculus boxing

% todo row-types
% todo capability-based, Scala
% todo modal effect types
% todo coeffects, coeffect style vs effect style
% todo papers about regions?

TODO % todo

% todo type inference and symilarity with first-class polymorphism


\section{Conclusion} \label{sec:conclusion}

TODO % todo


%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
\begin{acks}
    TODO % todo
\end{acks}

% TODO appendix с полным исчислением

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
% todo add links where possible for convenience of readers
\bibliographystyle{ACM-Reference-Format}
\bibliography{bib}

\end{document}
