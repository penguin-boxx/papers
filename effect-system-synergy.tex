%! suppress = MissingLabel
%%
%% This is file `effect-system-synergy.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,journal,bibtex,acmsmall')
%%
%% IMPORTANT NOTICE:
%%
%% For the copyright see the source file.
%%
%% Any modified versions of this file must be renamed
%% with new filenames distinct from effect-system-synergy.tex.
%%
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%%
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[acmsmall,review,screen]{acmart}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
%\AtBeginDocument{%
%    \providecommand\BibTeX{{%
%        Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
%\setcopyright{acmlicensed}
%\copyrightyear{2026}
%\acmYear{2026}
%\acmDOI{XXXXXXX.XXXXXXX}

%%
%% These commands are for a JOURNAL article.
%\acmJournal{JACM}
%\acmVolume{37}
%\acmNumber{4}
%\acmArticle{111}
%\acmMonth{1}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

% Line numbers
% https://tex.stackexchange.com/questions/16010/number-every-line-of-pages
%\usepackage{lineno}
%\usepackage{mathtools}
%\linenumbers
% ------------------------------------------------

\usepackage{multicol}
\usepackage{minted}
\setminted{xleftmargin=\parindent, autogobble, escapeinside=\#\#, numberblanklines=false, fontsize=\small} % todo use lstlisting instead with custom keywords
\usepackage{listings} % todo setup for colang surface
\usepackage{proof}
\usepackage{mathtools}
\usepackage[inference]{semantic}

\newcommand{\graybox}[1]{\colorbox{lightgray}{$\displaystyle #1$}}
\newcommand{\mathframebox}[1]{\framebox{$\displaystyle #1$}}
\newcommand{\vor}{~|~}
\newcommand{\ap}{~}
\newcommand{\ctx}[1]{ctx(#1)~}
\newcommand{\step}{\rightsquigarrow}
\newcommand{\local}{\top}
\newcommand{\free}{\bot}
\newcommand{\keyword}[1]{\mathbf{#1}}
\newcommand{\identation}{\text{\hspace{2em}}}

%%
%% end of the preamble, start of the body of the document source.
%! suppress = TooLargeSection
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{One Plus One: Effect System as a Synergy of Implicit Parameters and Type-Based Escape Analysis}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
%\author{Ben Trovato}
%\authornote{Both authors contributed equally to this research.}
%\email{trovato@corporation.com}
%\orcid{1234-5678-9012}
%\author{G.K.M. Tobin}
%\authornotemark[1]
%\email{webmaster@marysville-ohio.com}
%\affiliation{%
%    \institution{Institute for Clarity in Documentation}
%    \city{Dublin}
%    \state{Ohio}
%    \country{USA}
%}
%
%\author{Lars Th{\o}rv{\"a}ld}
%\affiliation{%
%    \institution{The Th{\o}rv{\"a}ld Group}
%    \city{Hekla}
%    \country{Iceland}}
%\email{larst@affiliation.org}
%
%\author{Valerie B\'eranger}
%\affiliation{%
%    \institution{Inria Paris-Rocquencourt}
%    \city{Rocquencourt}
%    \country{France}
%}
%
%\author{Aparna Patel}
%\affiliation{%
%    \institution{Rajiv Gandhi University}
%    \city{Doimukh}
%    \state{Arunachal Pradesh}
%    \country{India}}

\author{Andrey Stoyan}
\affiliation{%
    \institution{HSE University}
    \city{Saint Petersburg}
    \country{Russian Federation}}
\email{a.stoyan@hse.ru}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
%\renewcommand{\shortauthors}{Surname et al.}
\renewcommand{\shortauthors}{Andrey Stoyan}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
    Effects offer a systematic approach to managing code complexity.
    Certain responsibilities can be delegated to an execution context, allowing a computation to interact with this context by performing effects and thereby focusing on other aspects of logic.
    Effect systems elevate information about a program’s side effects to the type level, clarifying abstraction boundaries and enabling static verification of context validity.
    Despite these advantages, effect systems have not seen widespread adoption, largely due to their alien design and the general unfamiliarity of practitioners with the concept.

    In this paper, we propose a perspective on effect system design as a combination of two properly-designed language features: implicit parameters and type-based escape analysis.
    We argue that both features can be naturally realized in mainstream programming languages, are already familiar to practitioners, and provide independent utility.
    We motivate our approach by considering effect systems as mechanism for tracking free variables.
    We specify the requirements for a proper design of implicit parameters and illustrate these requirements through a formal example.
    We introduce a novel type-based escape analysis technique based on polymorphic $\lambda$-calculus with subtyping that relies on straightforward programmer-supplied dataflow descriptions. % todo is it correct to talk about dataflow here?
    Furthermore, we combine implicit parameters and type-based escape analysis together to provide an example of a minimalistic effect system.
    Finally, we discuss technical approaches to make an effect system more practical for common programming scenarios.
    % todo about proofs automation
\end{abstract}

%% todo
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
%    \begin{CCSXML}
%        <ccs2012>
%        <concept>
%        <concept_id>00000000.0000000.0000000</concept_id>
%        <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%        <concept_significance>500</concept_significance>
%        </concept>
%        <concept>
%        <concept_id>00000000.00000000.00000000</concept_id>
%        <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%        <concept_significance>300</concept_significance>
%        </concept>
%        <concept>
%        <concept_id>00000000.00000000.00000000</concept_id>
%        <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%        <concept_significance>100</concept_significance>
%        </concept>
%        <concept>
%        <concept_id>00000000.00000000.00000000</concept_id>
%        <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%        <concept_significance>100</concept_significance>
%        </concept>
%        </ccs2012>
%    \end{CCSXML}

%\ccsdesc[500]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
%\ccsdesc[300]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
%\ccsdesc{Do Not Use This Code~Generate the Correct Terms for Your Paper}
%\ccsdesc[100]{Do Not Use This Code~Generate the Correct Terms for Your Paper}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{static analysis, type systems, effects, capabilities}

%\received{10 July 2025}
%\received[revised]{12 March 2009}
%\received[accepted]{5 June 2009} todo

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle


\section{Introduction} \label{sec:intro}

% Introducton makes claims, all of them should be supported later.

% todo картинка с контекстом

The discipline of programming primarily centers on the management of complexity, enabling developers to concentrate on a specific fragment of behavior within any given code segment.
Abstraction and the separation of concerns are essential strategies in this process: distinct responsibilities are delegated to different program entities, such as functions or modules.
Frequently, such an entity may be abstractly referred to as the \textit{execution context} of a computation, with \texttt{effects} emerging naturally as interactions between the computation and its context~\cite{kiselyov2013extensible}.

An execution context can be characterized by at least one of the following properties:
\begin{enumerate}
    \item Interactions with an execution context are observable.
    For example, the memory management subsystem can be considered as the execution context --- each memory allocation can influence the addresses of subsequent allocations.
    In that case the context is responsible for bookkeeping of memory cells.
    \item The activity of an execution context may be restricted to a particular scope, such that only code within this scope can interact with the context.
    For example, an exception handler operates as an execution context confined to the body of a \texttt{try-catch} block; when an exception is thrown, control is transferred to the handler, which manages the exceptional situation.
    Another case is inversion of control, where an execution context restricts the provision of certain functionality to code within a defined scope, while code outside that scope may interact with a different context and access different functionality.
\end{enumerate}

An effect system reflects effects of a computation at the type level.
It serves two primary purposes.
Firstly, it makes effects explicit in type signatures, allowing functional abstraction boundaries to be specified with greater precision: implementation details are less likely to leak implicitly via context interactions.
Secondly, an effect system provides static enforcement of \textit{effect safety} for a computation’s use: a computation may only be executed within an appropriate context (as previously discussed, contexts may have limited activity scopes).
For example, an effect system is responsible for ensuring that all functionality required by inversion of control is available, and that all exceptions are handled.
It is also worth noting that effect systems can capture additional properties of computations, such as potential for divergence.

Many promising designs of effect systems were proposed: row-polymorphic types~\cite{leijen2014koka}, capabilities and contextual polymorphism~\cite{brachthauser2022effects, boruch2023capturing}, modal types~\cite{tang2025modal}, etc.
However, each of these approaches exhibits its own advantages and drawbacks, and the overall configuration of the design space for effect systems remains underexplored.
At the same time we believe it is important for language designers to have a comprehensive view of the available design options, allowing them to select the most appropriate solution given the specific characteristics and constraints of their target language.

In this paper, we argue that effect systems can be conceptualized as a combination of two simpler and more foundational language features: implicit parameters and type-based escape analysis.
Viewing effect systems from this perspective introduces axes within the effect system design space: varying the designs of these two features yields different possible instantiations.
Moreover, this approach facilitates the seamless integration of effect systems into existing mainstream languages, as many of these languages already support at least one of these features, since each of which is independently practical.

The general idea we present is not novel.
For example, recent work in the Scala programming language bases on similar observations~\cite{odersky2021safer, boruch2023capturing}.
However, our contribution lies in articulating this idea explicitly, systematically exploring its implications, and leveraging these insights to design a new effect system that is both practical and minimalistic.

% рассматриваем сразу и модели и системы эффектов, потому что делается type-based translation

Contributions of this paper are summarized as follows:

\begin{itemize} % todo
    \item We propose a perspective on effect system design as a combination of two properly-designed language features: implicit parameters and type-based escape analysis; and motivate our approach by looking at effect systems as systems for managing free variables (Section~\ref{sec:idea}).
    \item We describe required properties of implicit parameters design and provide a suitable one using a formal calculi (Section~\ref{sec:implicits}).
    \item We provide a novel type-based escape analysis technique that only requires straight-forward dataflow descriptions from a programmer (Section~\ref{sec:escape}).
    \item We show that our design is appropriate in the object-oriented setting (Section~\ref{sec:mainstream}). % todo расширить скоуп на просто финтифлюшки делающие дизайн более прикладным
%    \item We explore practical subtleties of our design and its applicability to object-oriented programming languages (Section~\ref{sec:mainstream}).
    \item We compare our approach with previous art and show that other designs can be considered in implicit parameters and escape analysis basis (Section~\ref{sec:related}).
\end{itemize}


\section{Two pieces of an effect system design} \label{sec:idea}

In this section we introduce the central idea of this paper through practical examples.
We further illustrate that the pragmatic motivations for effect systems emerge organically from common programming scenarios.

\subsection{The road to implicit parameters} \label{subsec:implicits}

In our running example (see fig.\ \ref{fig:db}), where the business logic function performs an update to the database storage.

The first version establishes its own database connection and executes a query.
However, this approach has several notable drawbacks.
Firstly, it hinders testability, as it is not straightforward to replace the database connection with a mock or alternative implementation; consequently, verifying the business logic in isolation becomes challenging.
Secondly, this function produces observable side effects --- such as performing database operations --- which are an integral part of its external contract.
Nevertheless, these effects are not reflected in the function’s type signature.

The second version provides a notable improvement.
Here, the business logic function is parameterized over the database connection, enabling the call site to supply a concrete implementation with the desired semantics.
Furthermore, the observable effects are now made explicit through the \texttt{db} parameter.
However, this approach incurs the overhead of additional syntactic complexity at the call site, as the administrative effort of explicitly passing parameters increases.
While this may appear trivial for a single argument, the burden becomes significant if, for example, four such parameters must be threaded through multiple layers of the call stack.
For best practices to be widely adopted, they should remain at least as accessible and convenient as less optimal alternatives.

To reduce boilerplate, the third version replaces ordinary parameters with dynamically scoped free variables.
These variables acquire their values through lookup within the dynamic scope of the function call.
However, this approach comes at the expense of other benefits: specifically, it sacrifices static typing and the explicit representation of context dependencies.

\begin{figure}
    \begin{tabular}{p{0.3\textwidth} rrr}
        \begin{minipage}[t]{0.3\textwidth}
            \begin{minted}{swift}
                func business1() {
                    let db = Db.open(...)
                    db.query("update ...")
                }
            \end{minted}
        \end{minipage}
        &
        \begin{minipage}[t]{0.3\textwidth}
            \begin{minted}{swift}
                func business2(db: Db) {
                    db.query("...")
                }

                func caller() {
                    let db = Db.open(...)
                    business2(db)
                }
            \end{minted}
        \end{minipage}
        &
        \begin{minipage}[t]{0.3\textwidth}
            \begin{minted}{swift}
                func business3() {
                    db.query("...")
                }

                func caller() {
                    let db = Db.open(...)
                    business3()
                }
            \end{minted}
        \end{minipage}
    \end{tabular}
    \caption{The road to dynamically scoped free variables.}
    \label{fig:db}
\end{figure}

To regain static type safety, we approximate dynamically scoped free variables using implicit function parameters~\cite{lewis2000implicit}.
At the declaration site, we introduce a \texttt{context} keyword to define a group of implicit parameters, which are automatically supplied by the compiler at the call site (see fig.\ \ref{fig:implicits}).
To make a value available for implicit parameter resolution, we employ the \texttt{context let} declaration syntax.

\begin{figure}[h]
    \begin{tabular}{p{0.5\textwidth} rl}
        \begin{minipage}[t]{0.3\textwidth}
            \begin{minted}{swift}
                context(db: Db)
                func business4() {
                    db.query("...")
                }
            \end{minted}
        \end{minipage}
        &
        \begin{minipage}[t]{0.3\textwidth}
            \begin{minted}{swift}
                func caller() {
                    context let db = Db.open(...)
                    business4()
                }
            \end{minted}
        \end{minipage}
    \end{tabular}
    \caption{Reclaming static type safety with implicit parameters.}
    \label{fig:implicits}
\end{figure}

In terms of effects and contexts, \texttt{context let} introduces an execution context, whose scope is restricted to the corresponding lexical region, and provides functionality of access to a database storage.
Implicit parameters express a function's requirements for its context.
In order to invoke such a function, the context must establish its validity by supplying concrete values for these implicit parameters.
We refer to these values as \textit{capabilities}, and logically they serve as witnesses of context validity.
It is important to note, that until this point our discussion was based solely on the mechanism of bindings, and did not require any deep understanding of the abstract notion of effects.

Exceptions and other algebraic operations can be tracked in an analogous manner~\cite{odersky2021safer}.
For example, a \texttt{throw SomeException()} construct can be interpreted as calling a function that requires an implicit parameter of type \texttt{Handler<SomeException>}.
Correspondingly, constructs that handle exceptions must supply appropriate witness values for these implicit parameters.
\begin{minted}{swift}
    func checkingExceptions() {
        try { // provides a capability of type Handler<SomeException>
            throw SomeException() // requires a capability of type Handler<SomeException>
        } catch (e: SomeException) { ... }
    }
\end{minted}

Nowadays, several widely used programming languages provide support for implicit parameters, and the inference mechanisms associated with these parameters is well understood~\cite{KEEP-context-parameters, oliveira2010type, lewis2000implicit}.
Moreover, implicit parameters alone are sufficient as the evidence-passing technique to implement tail-resumptive algebraic operations~\cite{xie2020effect}.

\subsection{Retain effect safety with escape analysis} \label{subsec:escape}

An effect system should ensure that all computations are executed within appropriate contexts --- a property we refer to as \textit{effect safety}.
In our setting, the context must supply capabilities as evidence of its validity.
Consequently, these capabilities must not be allowed to escape their corresponding contexts.
For example, if a \texttt{Handler} value were to escape a corresponding \texttt{try-catch} block, we would lose the guarantee that all exceptions are handled and, thereby, the effect safety itself:
\begin{minted}{swift}
    func unsafe() {
        let f = try {
            () => throw SomeException() // captures the Handler<SomeException> capability
        } catch (e: SomeException) { ... }
        f() // throws SomeException
    }
\end{minted}

Note that, in the example, the \texttt{Handler<SomeException>} capability acts as a lexically scoped free variable for the lambda function.
The ability to close over such capabilities enables the technique known as \textit{contextual polymorphism}~\cite{brachthauser2020effects, brachthauser2022effects}.
This approach allows higher-order functions to remain fully transparent with respect to effects, without introducing explicit polymorphic type variables that range over effect sets.
Specifically, the type of the \texttt{map} function need not be entangled with effect-related parameters (we will discuss the \texttt{scoped} syntax in detail later)\footnote{We adopt the Haskell naming convention, where type names beginning with a lowercase letter denote type variables, which are implicitly universally quantified.}: % todo ref
\begin{minted}{swift}
    func map(xs: List<a>, f: #\color{gray}\texttt{scoped(local)}# (a) -> b): List<b>

    context(io: IO)
    func printAll(xs: List<Int>) {
        map(xs, (x) => io.print(x)) // capability capturing is safe here
    }
\end{minted}

Compare this with the corresponding function type in the Koka language, which features row-polymorphic types~\cite{leijen2014koka}:
\begin{minted}{kotlin}
    fun map(xs: list<a>, f: (a) -> e b): e list<b>
\end{minted}

To control the escaping of capabilities, some form of escape analysis is required. % todo citations
Given that effect systems operate at the type level, it is natural to employ type-based techniques for escape analysis as well.
Furthermore, since this analysis must account for the flow of capabilities across function boundaries, it should be cross-procedural and directly reflected in function signatures.
In the following, we provide an informal overview of the type-based escape analysis technique introduced in this paper.

We refer to values that must not escape a given scope as \textit{tracked}, and likewise, their types are treated as tracked.
For instance, capabilities are tracked, as are by default the types of implicit parameters.
To distinguish between tracked and non-tracked types, we annotate each type $T$ with a special lifetime label $lab$, denoted by the syntax:
\[scoped(lab)\ap T\] % todo change the syntax to something more reasonable
Lifetime labels range over \texttt{free}, \texttt{local} and polymorphic lifetime variables.
The \texttt{free} label is used for non-tracked values and is assumed by default for all types.
The \texttt{local} label appears in tracked types, which the type system handles specially to prevent their escape; for instance, a function is prohibited from returning a value of a tracked type.

For example, the \texttt{map} function can be explicitly typed to ensure that it does not leak its argument function, thereby making it safe to pass closures that possess capabilities:
\begin{minted}{swift}
    func map(xs: List<a>, f: scoped(local) (a) -> b): List<b>
\end{minted}

To enable a function to propagate its arguments through its result, polymorphism over lifetime labels can be used.
In essence, this is an explicit specification of the function’s dataflow directly in the type signature. % todo dataflow term and citation
For instance, a lazy \texttt{map} function does not eagerly compute and return the final result; instead, it immediately yields a collection that encapsulates the processing logic.
This behavior can be captured by assigning the same lifetime variable~\texttt{l} to both the argument \texttt{f} and the result type.
Consequently, the type system records that any tracked capabilities captured by \texttt{f} may be retained within the result.
Such a function thus continues to support contextual polymorphism, as it can only permit \texttt{f} to escape with the result; furthermore, the call site is made aware~--- via the signature~--- that the result must not escape its prescribed context:
\begin{minted}{swift}
    func lazyMap(xs: LazyList<a>, f: scoped(l) (a) -> b): scoped(l) LazyList<b>

    context(io: IO) // io: scoped(local) IO
    func printAll(xs: LazyList<Int>) {
        let ys: scoped(local) LazyList<Int> = lazyMap(xs, (x) => io.print(x))
        ys.collect() // force execution
    }
\end{minted}

To express the capture of two or more lifetime-polymorphic values within the same scope, we employ the intersection of lifetimes:
\begin{minted}{swift}
    func compose(f: scoped(l1) (b) -> c, g: scoped(l2) (a) -> b): scoped(l1&l2) (a) -> c
        = (x) => f(g(x))
\end{minted}

For the sake of simplicity, we dispense with lifetime polymorphism for compound datatypes by determining each compound's lifetime as the intersection of the lifetimes of its components.
Upon destructuring, the lifetimes of the individual components are, in turn, approximated by the lifetime of the original compound datatype.
\begin{minted}{swift}
    func first(x: scoped(l1) Int, y: scoped(l2) Int): scoped(l1&l2) Int {
        let intPair: scoped(l1&l2) IntPair = IntPair(x, y)
        return intPair.fst
    }
\end{minted}

We define subtyping so that non-tracked values may be used in positions where tracked values are expected.
This design increases the number of safe well-typed programs and facilitates gradual adoption of effect tracking for languages transitioning from untyped effects to an effect system.

We permit tracked types to instantiate polymorphic type parameters, thereby making them first-class citizens in the language.
To control when tracked types are eligible for instantiation, we employ bounded polymorphism.
For example, the \texttt{lazyMap} function is written in such a way that it does not leak values of polymorphic type parameters (e.g., through global state), but rather returns them directly to the caller.
As a result, these parameters may be instantiated with tracked types:\footnote{We assume that \texttt{Any} serves as the top element in the type lattice.} \footnote{For backward compatibility, the type \texttt{scoped(free) Any} may be used as the default bound.}
\begin{minted}{swift}
    func lazyMap(xs: LazyList<a>, f: scoped(l) (a) -> b): scoped(l) LazyList<b>
        where a <: scoped(local) Any, b <: scoped(local) Any
\end{minted}

% todo our alternative to tunnelling

Various techniques can be employed to reduce boilerplate associated with lifetime polymorphism and the specification of bounds.
For example, the lifetime elision mechanism in the Rust language~\cite{matsakis2014rust} uses heuristics to automatically insert lifetime variables, thereby alleviating the need for explicit annotation.
In our approach, using the \texttt{scoped} keyword without a specific lifetime parameter similarly invokes the elision mechanism.
We will discuss this technique, along with alternative methods, in Section~\ref{subsec:lifetime-elision}.

The utility of type-based escape analysis extends well beyond its role in the construction of effect systems.
Specifically, it can be leveraged to reduce the number of heap allocations~\cite{lorenzen2024oxidizing}, enable borrowing for the ownership-based resource management~\cite{matsakis2014rust, lorenzen2024oxidizing}, and ensure the safety of non-local returns~\cite{akhin2021kotlin}.

\subsection{Summary} \label{subsec:idea-summary}

An effect system can be regarded as the integration of implicit parameters with type-based escape analysis.
Consequently, the design of an effect system naturally decomposes into two distinct components and can be developed incrementally in a step-by-step manner.

In fact, our previous discussion has primarily focused on free variables.
Indeed, a term inherently depends on its context via its free variables, acquiring different semantics depending on the particular context in which it is evaluated or defined.
So, free variables are the target for effect systems, while bound once are regulated by canonical type systems.

Our perspective on effect systems arises from a fundamental observation: the semantics of free variables can be defined by two principal scoping disciplines~--- dynamic and lexical scoping.
Adopting one or the other proves advantageous depending on the programming scenario.
We summarize the correspondence between these two disciplines in Figure~\ref{fig:free-vars} and further discuss the relationship to existing approaches in effect system design in Section~\ref{sec:related}.

\begin{figure}
    \centering
    \begin{tabular}{|l|l|l|}
        \hline
        Free variables & dynamically scoped & lexically scoped \\
        \hline
        Represent & unfulfilled context requirements & fulfilled context requirements \\
        Dealt by & implicit parameters & type-based escape analysis \\
        User specifies & more function parameters & a function’s dataflow \\ % todo other analysis may require something different
        \hline
    \end{tabular}
    \caption{Effect systems are for managing free variables.}
    \label{fig:free-vars}
\end{figure}


\section{Core calculus} \label{sec:core}

In this section, we introduce an explicitly typed, call-by-value core calculus, denoted as $Core$, which serves as the foundational framework for our study.
In subsequent sections, we will extend $Core$ by incorporating features such as omitting application and type-based escape analysis to enhance its expressiveness and safety guarantees. % todo omitting application term

\subsection{Effect handlers} \label{subsec:handlers}

In our formal developments, we adopt effect handlers as a universal mechanism for defining effects~\cite{plotkin2003algebraic, plotkin2013handling}, since they are sufficiently expressive to capture all effects of interest.
This obviates the need to treat individual effects separately.
Furthermore, in contrast to monad transformers~\cite{liang1995monad, schrijvers2019monad}, the dynamic semantics of effect handlers can be defined independently of any type-directed translation.
Consequently, this approach imposes no inherent constraints on the design of the effect system, providing us greater flexibility.

We begin by providing a brief introduction to effect handlers and demonstrate how they can be used to implement the effects discussed in the previous Section~\ref{sec:idea}.

The \texttt{handle} construct allows to define an execution context for a particular scope by specifying a set of effect operations.
Within this scope, the \texttt{perform} construct allows code to invoke these operations, facilitating interaction with the execution context managed by the handler.
The implementation of each operation within a handler is granted access to a delimited continuation of the call site~\cite{dyvbig2007monadic}.
This continuation can be invoked to resume the computation with an operation's result.

In our setting, we employ lexically scoped handlers, which require that each \texttt{perform} invocation is associated with a specific handler instance~\cite{biernacki2019binders, brachthauser2020effects}.

For example, consider defining an execution context that supplies a specific constant value to a computation.
This can be achieved by providing a handler for a \texttt{Reader} effect, which offers an \texttt{ask} operation that returns the designated constant.
The following computation sums the results of two invocations of \texttt{ask}; with implementation returning the constant $21$, the overall result of the computation will be $42$:
\[
    \begin{array}{l}
        \keyword{handle} ~ h : Reader\ap Int ~\keyword{with}~ \{ ask = \lambda k\ldotp k\ap 21 \} ~\keyword{in} \\
        \keyword{perform}~ask~h~() + \keyword{perform}~ask~h~()
    \end{array}
\]

To implement exception handling, the \texttt{throw} operation can be defined to discard the current continuation, effectively aborting the remainder of the computation.
For instance, the following program returns the first thrown value $1$:
\[
    \begin{array}{l}
        \keyword{handle}~ h : Exception\ap Int ~\keyword{with}~ \{throw = \lambda e~k\ldotp e \} ~\keyword{in} \\
        \keyword{perform}~throw~h~1 + \keyword{perform}~throw~h~2
    \end{array}
\]

Other algebraic effects, such as mutable state and nondeterminism, can likewise be implemented using the \texttt{handle} construct. % todo citations

%\begin{equation}
%    \begin{array}{l}
%        \keyword{handle}~ h : State\ap Int ~\keyword{with}~ \{\\
%        \indent get = \lambda k\ldotp\lambda s\ldotp k\ap s\ap s \\
%        \indent put = \lambda s'~k\ldotp\lambda s\ldotp k\ap ()\ap s' \\
%        \} ~\keyword{in}~ \\
%        perform~put~h~42; perform~get~h~42
%    \end{array}
%\end{equation}

\subsection{Syntax of $Core$} \label{subsec:syntax-core}

Let us introduce the syntax of $Core$, as illustrated in Figure~\ref{fig:core-syntax}.
We use an overline to denote a sequence of corresponding entries.
Constructs highlighted in gray are included solely to support the operational semantics.

% todo ensure consistent terminology: implicit/contextual

The main considerations that have shaped this syntax are as follows:
\begin{itemize}
    \item The functional type $\ctx{e}\overline{\tau}\to\sigma$ ensures that implicit parameters are always followed by ordinary parameters to prevent computations from being prematurely triggered by the inference of implicits (the overline denotes a tuple of argument types, with the empty tuple interpreted as the unit type).
    \item Corresponding to the functional type, at the term level we partition function arguments into two categories: \emph{contextual arguments}, which are intended to be inferred automatically by the type system in future extensions, and ordinary arguments, which must be provided explicitly by the programmer.
    \item Capability constructors $K_{cap}$ are used in an operational semantics to represent a capability. % todo cite generalized evidence passing?
    \item  The \texttt{handle} construct introduces a capability associated with the newly created handler instance and binds it to a name.
    The \texttt{perform} construct, in turn, requires a capability in order to perform an effectful operation.
    This approach helps us to naturally build an effect system from the perspective discussed in Section~\ref{sec:idea}.
    \item For conciseness, we omit \texttt{return} blocks in handlers, since they do not contribute additional expressiveness.
    \item The $handler_m$ construct acts as a continuation delimiter, identified by a unique marker $m$ for operational semantics purposes.
    \item The typing context differentiates regular bindings from \emph{contextual bindings}, the latter of which are restricted to monotypes.
    While separate typing contexts for each binding class would be possible, this would necessitate different variable domains for contextual and ordinary bindings.
\end{itemize}

% todo можно ли вызвать сейчас конструктор нормально?
\begin{figure}
    \centering
    \begin{gather*}
        \begin{array}{lrll}
            \text{Variables} & & x, y, z, f, g, op \\
            \text{Values} &v &\Coloneqq x \vor K \vor \Lambda \overline{\alpha} \ldotp v \\
            &&\vor K\ap \overline{\tau} \ap \overline{v} \vor \graybox{K_{cap}\ap\overline{\tau}\ap m\ap h} \\
            &&\vor \lambda \overline{x : \tau}~\overline{y : \sigma}\ldotp t
            \\
            \text{Terms} &t, u &\Coloneqq v \vor t\ap\overline{\tau} \vor t \ap \overline{t} \ap \overline{t} \\
            &&\vor match ~ t ~ with ~\{\overline{K \ap \overline{x} \to t}\} \\
            &&\vor perform ~ op \ap x \ap \overline{\tau} \ap \overline{t} \\
            &&\vor handle ~ x : T \ap \overline{\tau} ~with ~h~in ~t \\
            &&\vor \graybox{handler_m ~ t}
            \\
            \text{Handlers} &h &\Coloneqq \{ \overline{op = t} \}
            \\
            \text{Programs} &p &\Coloneqq \epsilon \vor x : s = t, p
        \end{array}
        \begin{array}{lrl}
            \text{Type variables} && \alpha, \beta \\
            \text{Type constructors} && T \\
            \text{Monotypes} & \tau, \sigma, \eta &\Coloneqq \alpha \vor T \ap \overline{\tau} \vor \ctx{e} \overline{\tau} \to \sigma \\
            \text{Type schemas} & s &\Coloneqq \forall\overline{\alpha}\ldotp \tau \\
            \text{Effect rows} & e &\Coloneqq \epsilon\vor \tau, e \\
            \text{Typing contexts} & \Gamma &\Coloneqq \emptyset \vor x : s, \Gamma \vor x :_c \tau, \Gamma \\
            &&\vor K : \forall\overline{\alpha}\ldotp \overline{\tau}\to T\ap \overline{\alpha}, \Gamma \\
            \text{Effect contexts} & \Sigma &\Coloneqq \{\overline{K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap\overline{\alpha}}\} \\
            \text{Effect signatures} & sig &\Coloneqq \{\overline{op : \forall\overline{\alpha}\ldotp\overline{\tau}\to\sigma}\} \\
            \text{Free type variables} & & ftv(\cdot) \\
        \end{array}\\
        \begin{aligned}
            \text{Evaluation context } E \Coloneqq \square \vor E \ap \overline{\tau} \vor E \ap \overline{t}\ap \overline{t} \vor v \ap (\overline{v}, E, \overline{t}) \ap \overline{t} \vor v \ap \overline{v} \ap (\overline{v}, E, \overline{t}) \vor K\ap\overline{\tau}\ap(\overline{v}, E, \overline{t}) \vor handler_m ~ E
        \end{aligned}\\
    \end{gather*}
    \caption{Syntax of $Core$.}
    \label{fig:core-syntax}
\end{figure}

Note that the type of first-class functions contains a list of implicit parameters.
This enables us to type abstractions over handlers.
For example, the following function establishes an execution context by introducing a handler for an exception type \texttt{E}\footnote{We employ an informally defined surface syntax for explanatory purposes; its correspondence to our formal definitions is straightforward.}:
\begin{minted}{swift}
    func withE(f: context(Handler<E>) () -> r): r =
        try { f() } catch (e: E) { ... }
\end{minted}

We assume that the effect context $\Sigma$ is populated by user-defined \texttt{effect} declarations, analogous to those found in Koka. % todo citation
Specifically, for a program containing the following declaration,
\begin{minted}{swift}
    effect Eff<a> {
        op id(x: b): b
        op yield(x: a): Unit
    }
\end{minted}
we have \[\Sigma = \{EffK_{cap} : \forall\alpha\ldotp\{id : \forall\beta\ldotp b\to b, yield : a \to Unit\} \to Eff\ap a\}\]
There exists a bijection between capability constructors and effect types.

\subsection{Operational semantics of $Core$}

% todo refer to a paper that proposed to instantiate a handle_m frame

Let us highlight the most significant aspects of our operational semantics, as presented in Figure~\ref{fig:core-operational}:
\begin{itemize}
    \item \textbf{(handle)} rule selects the capability constructor associated with the specified effect type $T$ and uses it to create a new capability.
    Additionally, it allocates a fresh marker $m$ and installs it with the $handler$ construct.
    \item \textbf{(perform)} rule deconstructs the provided capability, identifies the targeted operation, and invokes it with the current continuation, which is delimited by the associated marker $m$.
    Since we adopt deep handlers~\cite{hillerstrom2018shallow}, the handler is reinstalled within the continuation.
\end{itemize}

\begin{figure}
    \[
        \begin{array}{llll}
            \text{(tapp)} &(\Lambda \overline{\alpha}\ldotp t) \ap \overline{\tau} &\longrightarrow &[\overline{\alpha\to\tau}]\ap t
            \\
            \text{(app)} &(\lambda \overline{x}~\overline{y}\ldotp t) \ap \overline{v} \ap \overline{v'} &\longrightarrow &[\overline{x\to v}, \overline{y\to v'}]\ap t
            \\
            \text{(match)} &match ~K \ap \overline{v}~ with ~ \{ \overline{K_i \ap \overline{x} \to u_i}\} &\longrightarrow &[\overline{x\to v}]\ap u_k, \text{ where } K = K_k
            \\
            \text{(handle)} &handle ~ x : T \ap \overline{\tau} ~with~h~in~t &\longrightarrow & handler_m ~[x \to K_{cap} \ap\overline{\tau}\ap m \ap h] \ap u
            \\
            &&\text{where} & m \text{ fresh}, {\color{gray}(K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap\overline{\alpha}) \in \Sigma}
            \\
            \text{(return)} &handler_m ~v &\longrightarrow & v
            \\
            \text{(perform)} &handler_m~E[perform \ap op \ap (K_{cap}\ap\overline{\tau_1}\ap m \ap h)\ap\overline{\tau_2}\ap\overline{v}] &\longrightarrow &t \ap \overline{\tau_2}\ap \overline{v}\ap k
            \\
            &&\text{where} & (op = t) \in h, {\color{gray}\theta = [\overline{\alpha\to\tau_1}, \overline{\beta\to\tau_2}],} \\
            &&& {\color{gray}(K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap\overline{\alpha}) \in \Sigma,} \\
            &&& {\color{gray}(op : \forall\overline{\beta}\ldotp\overline{\sigma}\to\sigma') \in sig,} \\
            &&& k = \lambda x : \theta\ap\sigma' \ldotp handler_m~E[x]
        \end{array}
    \]
    \vspace{-3em}
    \[
        \hspace{-15em}\infer[\text{(step)}]{E[t]\longrightarrow E[t']}{t\longrightarrow t'}
    \]
    \caption{Operational semantics of $Core$.}
    \label{fig:core-operational}
\end{figure}

It is important to note that every \texttt{perform} operation in our system is explicitly directed to a particular handler instance.
As a result, there is no issue of accidental effect handling, so the effect encapsulation is achieved by default~\cite{lindley2018encapsulating}. % todo more citations

For instance, consider a function \texttt{withE1} that installs a handler for exception \texttt{E1}.
If a computation \texttt{f} potentially raises exception \texttt{E2}, \texttt{withE1} will not be able to intercept this exception, since it does not provide \texttt{f} with the corresponding capability for \texttt{E2}:
\begin{minted}{swift}
    func withE1(f: context(Handler<E1>) () -> r): r =
        try { f() } catch (e: E1) { ... } catch (e: E2) { /* unreachable */ }
\end{minted}

Since handlers are propagated explicitly to the operation call site, our approach eliminates the need for dynamic handler lookup and the collection of the continuation when the callee operation is tail-resumptive~\cite{xie2020effect}.
In a low-level implementation, such a \texttt{perform} construct can thus be compiled to a direct virtual call, further improving efficiency. % todo citation

%TODO theorems % todo theorem about determinism (and mb others)

\subsection{Typing rules for $Core$} \label{subsec:core-typing}

\begin{itemize}
    \item The typing rules for $Core$ (see Figure~\ref{fig:core-typing}) are presented in algorithmic form.
    \item For conciseness, we omit both type well-formedness conditions and the (invariant) effect context~$\Sigma$.
    \item Each entry in the effect context~$\Sigma$ can be uniquely identified by its capability type; thus, we treat~$\Sigma$ as a mapping: $\Sigma(T) = \forall\overline{\alpha}\ldotp sig \iff K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap\overline{\alpha}\in\Sigma$.
    \item All variable bindings within the typing context are assumed to be unique with respect to variable names, so rules $Var$ and $CVar$ do not contradict each other.
\end{itemize}

%! suppress = EscapeAmpersand
\begin{figure}
    \begin{gather*}
        \mathframebox{\Gamma\vdash t : s} \\
        \begin{array}{ccc}
            \infer[Var]{\Gamma\vdash x : s}{x : s \in \Gamma} &
            \infer[CVar]{\Gamma\vdash x : \tau}{x :_c \tau \in \Gamma} &
            \infer[Ctor]{\Gamma\vdash K : \forall \overline{\alpha}\ldotp \tau\to T\ap\overline{\alpha}}{K : \forall \overline{\alpha}\ldotp \tau\to T\ap\overline{\alpha} \in \Gamma} % todo can avoid this rule?
        \end{array} \\
        \begin{array}{cc}
            \infer[TLam]{
                \Gamma\vdash\Lambda\overline{\alpha}\ldotp v : \forall\overline{\alpha}\ldotp\tau
            }{
                \Gamma\vdash v : \tau
            } &
            \infer[TApp]{
                \Gamma\vdash t\ap\overline{\tau} : [\overline{\alpha\to\tau}]\ap\sigma
            }{
                \Gamma \vdash t : \forall\overline{\alpha}\ldotp \sigma
            }
        \end{array} \\
        \infer[Lam]{
            \Gamma\vdash \lambda \overline{x : \tau_1} ~ \overline{y : \tau_2} \ldotp t : ctx(\overline{\tau_1}) ~ \overline{\tau_2} \to \sigma
        }{
            \overline{x :_c \tau_1}, \overline{y : \tau_2}, \Gamma\vdash t : \sigma
        }
        \text{\hspace{2em}}
        \infer[App]{
            \Gamma\vdash t \ap \overline{u_1} \ap \overline{u_2} : \sigma
        } {
            \Gamma\vdash t : ctx(\overline{\tau_1})~\overline{\tau_2}\to\sigma
            &
            \overline{\Gamma\vdash u_1 : \tau_1}
            &
            \overline{\Gamma\vdash u_2 : \tau_2}
        }\\
        \infer[Match]{
            \Gamma\vdash match ~ t ~with ~\{ \overline{K_i\ap \overline{x_j} \to u_i }\} : \eta
        }{
            \Gamma\vdash t : T \ap\overline{\tau} &
            K_i : \forall \overline{\alpha}\ldotp \overline{\sigma_j} \to T\ap\overline{\alpha} \in \Gamma &
            \overline{x_j : [\overline{\alpha\to\tau}]\ap \sigma_j}, \Gamma \vdash u_i : \eta
        }\\
        \infer[Perform]{
            \Gamma\vdash perform \ap op\ap \overline{\tau_2}\ap x\ap \overline{t} : \theta\ap\eta
        }{
            \Gamma\vdash x : T\ap \overline{\tau_1} &
            \Sigma(T) = \forall\overline{\alpha}\ldotp sig &
            op : \forall\overline{\beta}\ldotp \overline{\sigma}\to\eta \in sig &
            \theta = [\overline{\alpha\to\tau_1}, \overline{\beta\to\tau_2}] &
            \overline{\Gamma\vdash t : \theta\ap\sigma}
        }\\
        \infer[Handle]{
            \Gamma \vdash handle ~ x : T\ap\overline{\tau}~ with ~ \{\overline{op_i = t_i}\} ~in~u : \eta
        }{
            \begin{gathered}
                x :_c T\ap\overline{\tau}, \Gamma\vdash u : \eta
            \end{gathered}
            &
            \begin{array}{ll}
                \overline{\beta}_i\not\cap ftv(\eta) & % todo beautify intersection
                \Sigma(T) = \forall\overline{\alpha}\ldotp sig \hspace{0.6em} op_i : \forall\overline{\beta}_i\ldotp \overline{\sigma}_i\to\sigma'_i \in sig
                \\
                \theta = [\overline{\alpha\to\tau}] &
                \Gamma\vdash\theta\ap t_i : \forall \overline{\beta}_i\ldotp \overline{\theta\ap\sigma_i}\to(\theta\ap\sigma_i'\to\eta)\to\eta
            \end{array}
        }\\
        \infer[Cap]{
            \Gamma\vdash K_{cap}\ap\overline{\tau}\ap m\ap h : T\ap\overline{\tau}
        }{
            K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap\overline{\alpha} \in \Sigma
        }
        \hspace{2em}
        \infer[Handler]{
            \Gamma\vdash handler_m ~t : \tau
        }{
            \Gamma\vdash t : \tau
        }\\
        \begin{array}{ccc}
            \mathframebox{\Gamma\vdash p} &
            \infer[\epsilon Prog]{\Gamma\vdash\epsilon}{} &
            \infer[Prog]{
                \Gamma\vdash x : \forall\overline{\alpha}\ldotp \tau = t, p
            }{
                \Gamma\vdash t : \forall\overline{\alpha}\ldotp \tau &
                ftv(t) = \overline{\alpha} &
                \Gamma\vdash p
            }
        \end{array}
    \end{gather*}
    \caption{Typing rules for $Core$.}
    \label{fig:core-typing}
\end{figure}

%TODO formulate properties

\section{Design of implicit parameters} \label{sec:implicits}

In this section we discuss design decisions for implicit parameters feature that enhance its suitability as a component of a practical effect system.
Throughout the discussion, we introduce a formal calculus with implicit parameters, denoted as $Core^{im}$, which extends the $Core$ calculus.

\subsection{Syntax of $Core^{im}$}

We extend the syntax of $Core$ by introducing omitted application, which allows the first block of contextual arguments to be unspecified:
\[
    \begin{array}{lcc}
        \text{Terms} & t, u &\Coloneqq \ldots \vor t\ap\overline{t} \vor \ldots
    \end{array}
\]

\subsection{Inference of implicit parameters} \label{subsec:inference}

We define a type-directed translation from $Core^{im}$ to $Core$, as presented in Figure~\ref{fig:core-im-core-implicit-inference}.
Deriving translation rules for other constructs from the typing rules for $Core$ is straightforward.

The relation $\Gamma\vdash_e \overline{x}$ selects from the typing context those variables that participate in inference with the specified effect types.
Note that, since the typing context maintains only bindings with unique names (see Section\ \ref{subsec:core-typing}), it is possible for a user to shadow a contextual binding with an ordinary one, causing it to be excluded from subsequent inference.
This issue can be addressed, for example, by representing the typing context as a list that permits duplicating entries and by assigning additional fresh names to contextual bindings.
Implicits inference should use these names to refer directly to contextual binding avoiding shadowing.

\begin{figure}
    %! suppress = EscapeAmpersand
    \begin{gather*}
        \mathframebox{\Gamma\vdash t : \tau \step t_{c}} \\
        \infer[CtxApp]{
            \Gamma\vdash t\ap\overline{u} : \sigma \step t_{c} \ap \overline{x}\ap\overline{u_{c}}
        }{
            \Gamma\vdash t : \ctx{e} \overline{\tau} \to \sigma \step t_{c} &
            \Gamma\vdash_e\overline{x} &
            \overline{\Gamma\vdash u : \tau \step u_{c}}
        } \\
        \mathframebox{\Gamma\vdash_e \overline{x}}
        \text{\hspace{2em}}
        \infer[Infer]{\Gamma\vdash_{\overline{\tau}} \overline{x}}{\overline{x :_c \tau}\subset \Gamma}
    \end{gather*}
    \caption{Inference of implicit parameters.}
    \label{fig:core-im-core-implicit-inference}
\end{figure}

There is a design decision to be made, whether inference should depend solely on types, or additionally rely on variable names.
The latter approach is more complex, as it necessitates storing variable names in effect rows and, furthermore, precludes the renaming of implicit parameters under $\alpha$-equivalence.
This restriction can make programs more fragile with respect to renaming.
On the other hand, this approach permits simultaneous use of multiple effects of the same type.
This problem has attracted significant attention in the research community. % todo citations

However, in this work, we use the first approach and argue that, in practical programming, relying on multiple effects of the same type is generally undesirable.
Instead, we advocate for the definition and use of domain-specific effects rather than directly employing general-purpose ones.
For instance, a domain-specific effect such as \texttt{UserRepository} offers a higher level of abstraction compared to a general-purpose \texttt{Database} effect.

Another design decision concerns the timing of implicit parameter substitution: should it occur immediately upon variable mention, or should it be deferred until application?
This question is analogous to type instantiation in the presence of first-class polymorphism, where type inference determines type parameters~\cite{emrich2020freezeml}. % todo verify citation
Both strategies have their advantages: immediate substitution is convenient when working with contextually polymorphic functions, such as \texttt{map(xs, f)}, whereas deferred substitution facilitates effect abstraction, as in constructs like \texttt{withSomeException(f)}. % todo introduce effect abstraction somewhere % todo citations to kotlin, haskell and something

Actually, this choice determines the default behavior, since either approach can be emulated by the other via $\eta$-expansion.
For instance, let us assume that substitution is performed at application time:
\begin{minted}{swift}
    f : context(IO) () -> Unit; g : (() -> Unit) -> Unit
    g(() => f())
\end{minted}
Alternatively, assume that substitution occurs at the point where a function is mentioned:
\begin{minted}{swift}
    f : context(IO) () -> Unit; g : (context(IO) () -> Unit) -> Unit
    g(context(_: Eff) () => f()) // abstracts over contextual parameters
\end{minted}
% todo special syntax for explicitly passed implicits

%TODO properties

\subsection{System $Core^{im+<:}$ with implicit parameters and subtyping} \label{subsec:im-sub}

It is desirable to support a form of subtyping on effect rows, as this allows functions with fewer contextual requirements to be used in more permissive contexts in a natural way.
For example, \texttt{withStd} is a function that provides default implementation for several effects.
We should therefore be able to pass to \texttt{withStd} a function that only utilizes a subset of those effects:
\begin{minted}{swift}
    func withStd(f: context(IO, Allocator, Random) () -> r): r
    withStd(g) // g : context(IO) () -> Unit
\end{minted}

% todo find literature
% todo row polymorphism can help somehow?
% todo cite papers about row types
Contexts can be modeled as structural record types with width and permutation subtyping.
However, a straightforward implementation of such records as dictionaries tends to be inefficient in terms of both time and space complexity.

To enable efficient subtyping, we restrict subtyping to be shallow, meaning that one function type is a subtype of another only if their effect rows are in a subtyping relationship, while the argument and return types remain identical:
\[
    \infer[FunSub]{\ctx{e} \tau \to \sigma <: \ctx{e'} \tau\to\sigma}{e' <: e}
\]

With this restriction, shallow subtyping can be implemented via $\eta$-expansion (see Figure~\ref{sig:fim-sub-app}).
The relation $\Gamma\vdash t\Leftarrow \tau \step t_c$ applies $\eta$-expansion to $t$ when a functional type $\tau$ is expected.

\begin{figure}
    %! suppress = EscapeAmpersand
    \begin{gather*}
        \mathframebox{\Gamma\vdash t : \tau \step t_c} \\
        \infer[App]{
            \Gamma\vdash t\ap\overline{u} : \eta \step t_c \ap \overline{x} \ap \overline{u_c}
        }{
            \Gamma\vdash t : ctx(\overline{\tau})~\overline{\sigma}\to \eta \step t_c
            &
            \Gamma \vdash_{\overline{\tau}} \overline{x}
            &
            \overline{\Gamma\vdash u : \sigma'}
            &
            \overline{\sigma' <: \sigma}
            &
            \overline{\Gamma\vdash u \Leftarrow \sigma \step u_c}
        } \\
        \mathframebox{\Gamma\vdash t \Leftarrow \tau \step t_c} \\
        \begin{array}{cc}
            \infer[AppArg]{
                \Gamma\vdash t \Leftarrow \tau \step t_c
            }{
                \Gamma\vdash t : \tau \step t_c
            }
            &
            \infer[AppArgCtx]{
                \Gamma \vdash t \Leftarrow ctx(\overline{\tau}) ~\overline{\sigma}\to\eta\step \lambda \overline{x : \tau}~\overline{y : \sigma}\ldotp t_c\ap \overline{x'}\ap\overline{y}
            }{
                \Gamma \vdash t : ctx(\overline{\tau'}) ~\overline{\sigma}\to\eta \step t_c
                &
                \overline{x :_c \tau} \vdash_{\overline{\tau'}} \overline{x'}
                &
                \overline{x~y \text{ fresh}}
            }
        \end{array}
    \end{gather*}
    \caption{Application rule for $Core^{im + <:}$.}
    \label{sig:fim-sub-app}
\end{figure}

% todo link to bidirectional typing

% todo big lambda inference

% todo will subtyping break inference?

% todo what if generate application (like for dictionaries) to reorder effect rows (do inhabitation of some form)?

\section{Design of type-based escape analysis} \label{sec:escape}

In this section we develop an extension to the previously discussed systems that statically guarantees that no capabilities escape their corresponding handlers.
The core aspects of this design have already been introduced in Section~\ref{subsec:escape}.

\subsection{Syntax of $Core_\Delta$}

Let us introduce $Core_\Delta$, an extension of $Core$ that incorporates lifetimes, lifetime polymorphism, and bounded polymorphism.
Modifications to the type syntax are presented in Figure~\ref{fig:core-delta-syntax}, with changes highlighted in gray.
\begin{itemize}
    \item Monotypes are now annotated with explicit lifetime labels.
    The syntax is deliberately chosen to be identical to that of type arguments to emphasize that lifetimes can be regarded as ordinary types, albeit of a distinct kind.
    \item Type schemas support abstraction over lifetime variables and permit the specification of polymorphic bounds.
    \item We introduce utility operations that, given a type, return the set of lifetimes appearing in specified positions~--- positive and negative. % todo cite positions
    \item The resulting lifetime associated with data constructors is computed as the intersection of all lifetimes corresponding to those values that may later be extracted~--- that is, lifetimes encountered in positive positions.
\end{itemize}

% todo say about the default constraints
% todo syntax of lifetimes deliberately choosen to resemble a generic parameter

%! suppress = MissingLabel
\begin{figure}
    \[
        \begin{array}{lrl}
            \text{Type variables} && \alpha, \beta \\
            \text{Type constructors} && T \\
            \text{Lifetime variables} && \graybox{l} \\
            \text{Lifetimes} & \graybox{\Delta} &\Coloneqq l \vor local \vor free \vor \&\overline{\Delta} \\
            \text{Monotypes} & \tau, \sigma, \eta &\Coloneqq \alpha \vor T \ap \graybox{\Delta} \ap \overline{\tau} \vor \ctx{e} \graybox{\Delta}~\overline{\tau} \to \sigma \\
            \text{Type schemas} & s &\Coloneqq \forall \graybox{\overline{l}}~\overline{(\alpha \graybox{<: \tau})}\ldotp \sigma \\
            \text{Free type variables} & & ftv(\cdot) \\
            \text{Lifetimes in positive positions} & & \graybox{lt_\Gamma^+(\cdot)}, \graybox{lt_\Gamma^-(\cdot)} \\
            \text{Free lifetime variables} & & \graybox{flt^+(\cdot)}, \graybox{flt^-(\cdot)} \\
            \text{Least upper bound} & & \graybox{lub(\cdot)} \\
            \text{Effect rows} & e &\Coloneqq \epsilon\vor \tau, e \\
            \text{Typing contexts} & \Gamma &\Coloneqq \emptyset \vor x : s, \Gamma \vor x :_c \tau, \Gamma \vor \graybox{\alpha <: \tau, \Gamma} \\
            & &\vor K : \forall\graybox{\overline{l}}\ \overline{\alpha}\ldotp \overline{\tau}\to T \ap\graybox{(\&\overline{lt_\emptyset^+(\tau)})}\ap \overline{\alpha}, \Gamma \\
            \text{Effect contexts} & \Sigma &\Coloneqq \{\overline{K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap \graybox{local} \ap\overline{\alpha}}\} \\
            \text{Effect signatures} & sig &\Coloneqq \{\overline{op : \forall\overline{\alpha}\ldotp\overline{\tau}\to\sigma}\}
        \end{array}
    \]
    \caption{Syntax of types for $Core_\Delta$.}
    \label{fig:core-delta-syntax}
\end{figure}

Let us specify $lt_\Gamma^+(\cdot)$ explicitly, other operations are straight-forward:
\[
    \begin{array}{lll}
        lt_\Gamma^+(\alpha) & = & lt_\Gamma^+(\tau) \text{ if } \alpha <: \tau \in \Gamma, \{\} \text{ otherwise} \\
        lt_\Gamma^+(T\ap\Delta\ap\overline{\tau}) & = & \overline{lt_\Gamma^+(\tau)} \cup \overline{lt_\Gamma^-(\tau)} \cup \{\Delta\} \\
        lt_\Gamma^-(T\ap\Delta\ap\overline{\tau}) & = & \overline{lt_\Gamma^+(\tau)} \cup \overline{lt_\Gamma^-(\tau)} \\
        lt_\Gamma^{+}(\ctx{\overline{\tau}}\Delta~\overline{\sigma}\to\overline{\eta}) & = & \overline{lt_\Gamma^{-}(\tau)} \cup \overline{lt_\Gamma^{-}(\sigma)} \cup \overline{lt_\Gamma^{+}(\eta)} \cup \{\Delta\} \\
        lt_\Gamma^{-}(\ctx{\overline{\tau}}\Delta~\overline{\sigma}\to\overline{\eta}) & = & \overline{lt_\Gamma^{+}(\tau)} \cup \overline{lt_\Gamma^{+}(\sigma)} \cup \overline{lt_\Gamma^{-}(\eta)}
    \end{array}
\]
The lifetime of a type variable is approximated by the lifetime of its bounding type, if such a bound exists.
In some cases, we intentionally employ an empty context to exclude the influence of bounds.
Also, since type constructor parameters are invariant, they are treated as both positive and negative simultaneously.

Syntax of terms follows the changes in the syntax of types:
\[
    \begin{array}{lll}
        \text{Values} & v & \Coloneqq \ldots \vor \Lambda \graybox{\overline{l}}\ap\overline{\alpha}\ldotp v \vor K\ap\graybox{\overline{\Delta}}\ap\overline{\tau}\ap\overline{v} \vor \ldots \\
        \text{Terms} & t, u &\Coloneqq \ldots \vor t\ap\graybox{\overline{\Delta}}\ap\overline{\tau} \vor handle ~ x : T \ap\graybox{local}\ap \overline{\tau} ~with ~h~in ~t \vor \ldots
    \end{array}
\]

\subsection{Typing rules for $Core_\Delta$}

Let us highlight some of the key aspects of the typing rules (fig.\ \ref{fig:core-delta-typing}):
\begin{itemize} % todo make rule names explicit for other enumerations as well
    \item \textbf{Lam:} The typing rule for $\lambda$-abstractions guarantees that no tracked value can escape the scope of the function via its return value.
    Analogous to the treatment of data constructors, the lifetime associated with a function type is determined as the intersection of the lifetimes of all captured variables.
    This ensures that the function itself cannot outlive any tracked resources it closes over. % todo explain zero set
    \item \textbf{Match:} Lifetime parameters appearing in positive positions are conservatively approximated by the lifetime of the enclosing composite data type.
    Since data types are covariant with respect to their lifetime parameters, lifetimes appearing in negative positions are replaced with the bottom lifetime \texttt{free}, analogous to covariant projections. % todo link to covariant projections
    \item \textbf{Handle:} The $Handle$ rule plays crucial role in ensuring effect safety.
    First, it annotates capabilities created within the handler with the lifetime label \texttt{local} and prohibits occurrences of \texttt{local} in positive positions within the result type $\eta$.
    This restriction prevents capabilities from escaping the handler’s scope via returned values.
    Second, the rule enforces a well-formedness condition on effect signatures to ensure that no capabilities are passed as arguments to operation calls. % todo explain better, generics are bounded with free
    Without this constraint, a capability introduced by an inner handler could be propagated to an operation in an outer handler, thus escaping its scope.
    This restriction can be relaxed under certain conditions; further discussion is provided in Section. % todo ref
    \item \textbf{TypesOf:} This rule extracts the types of designated variables from the typing context without discriminating between ordinary bindings and contextual bindings.
\end{itemize}

% todo rename lifetime intersection

%! suppress = EscapeAmpersand
\begin{figure}
    \begin{gather*}
        \mathframebox{\Gamma\vdash t : s} \\
        \begin{array}{ccc}
            \infer[Var]{\Gamma\vdash x : s}{x : s \in \Gamma} &
            \infer[CVar]{\Gamma\vdash x : \tau}{x :_c \tau \in \Gamma} &
            \infer[Ctor]{\Gamma\vdash K : \forall\overline{l}\ \overline{\alpha}\ldotp \overline{\tau}\to T \ap(\&\overline{lt_\emptyset^+(\tau)})\ap \overline{\alpha}}{K : \forall\overline{l}\ \overline{\alpha}\ldotp \overline{\tau}\to T \ap(\&\overline{lt_\emptyset^+(\tau)})\ap \overline{\alpha} \in \Gamma} % todo can avoid this rule?
        \end{array} \\
        \begin{array}{cc}
            \infer[TLam]{
                \Gamma\vdash\Lambda\overline{l}\ap\overline{(\alpha <: \sigma)}\ldotp t : \forall\overline{l}\ap\overline{(\alpha <: \sigma)}\ldotp\tau
            }{
                \overline{\alpha <: \sigma}, \Gamma\vdash t : \tau
            } &
            \infer[TApp]{
                \Gamma\vdash x\ap\overline{\Delta}\ap\overline{\tau'} : [\overline{\alpha\to\tau'}]\ap[\overline{l\to\Delta}]\ap\sigma
            }{
                x : \forall\overline{l}\ap(\overline{\alpha <: \tau})\ldotp \sigma \in \Gamma
                &
                \overline{\Gamma\vdash\tau' <: [\overline{l\to\Delta}]\ap\tau}
            }
        \end{array} \\
        \infer[Lam]{
            \Gamma\vdash \lambda \overline{x : \tau} ~ \overline{y : \sigma} \ldotp t : ctx(\overline{\tau}) \left(\&{\overline{lt_\Gamma^+(s)}}\right)~ \overline{\sigma} \to \eta
        }{
            \overline{x :_c \tau}, \overline{y : \sigma}, \Gamma\vdash t : \eta
            &
            \Gamma\vdash_{fv(t)\setminus \overline{x}\setminus\overline{y}}\overline{s}
            &
            local\not\in lt_\emptyset^+(\eta)
        } \\
        \infer[App]{
            \Gamma\vdash t \ap \overline{u_1} \ap \overline{u_2} : \eta
        } {
            \Gamma\vdash t : \ctx{\overline{\tau}} \Delta~\overline{\sigma}\to\eta
            &
            \begin{array}{c}
                \overline{\Gamma\vdash u_1 : \tau'} \\
                \overline{\Gamma\vdash\tau' <: \tau}
            \end{array}
            &
            \begin{array}{c}
                \overline{\Gamma\vdash u_2 : \sigma'} \\
                \overline{\Gamma\vdash\sigma' <: \sigma}
            \end{array}
        }\\
        \infer[Match]{
            \Gamma\vdash match ~ t ~with ~\{ \overline{K_i\ap \overline{x_j} \to u_i }\}  : lub(\overline{\eta_i})
        }{
            \begin{array}{cc}
                K_i : \forall \overline{l}~\overline{\alpha}\ldotp \overline{\sigma}_j \to T\ap(\&\overline{lt_\emptyset^+(\sigma)})\ap\overline{\alpha} \in \Gamma
                &
                \Gamma\vdash t : T\ap\Delta \ap\overline{\tau}
                \\
                \theta = [\overline{flt_+(\sigma_j)\to\Delta}, \overline{flt_{-}(\sigma_j)\to free}] \hspace{1em} flt_+(\overline{\sigma}_j) \not\cap flt_{-}(\overline{\sigma}_j)
                &
                \overline{x_j : [\overline{\alpha\to\tau}]\ap\theta\ap\sigma_j'}, \Gamma \vdash u_i : \eta_i
            \end{array}
        }\\
        \infer[Perform]{
            \Gamma\vdash perform \ap op\ap \overline{\tau_2}\ap x\ap \overline{t} : \theta\ap\eta
        }{
            \begin{array}{ccc}
                \Sigma(T) = \forall\overline{\alpha}\ldotp sig &
                \Gamma\vdash x : T\ap \Delta \ap \overline{\tau_1} &
                \overline{\Gamma\vdash t : \sigma'}
                \\
                op : \forall\overline{\beta}\ldotp \overline{\sigma}\to\eta \in sig &
                \theta = [\overline{\alpha\to\tau_1}, \overline{\beta\to\tau_2}] &
                \overline{\Gamma\vdash\sigma' <: \theta\ap\sigma}
            \end{array}
        }\\
        \infer[Handle]{
            \Gamma \vdash handle ~ x : T\ap local\ap\overline{\tau}~ with ~ \{\overline{op_i = t_i}\} ~in~u : \eta
        }{
            \begin{array}{ccc}
                x :_c T\ap local\ap\overline{\tau}, \Gamma\vdash u : \eta
                &
                \overline{\beta}_i\not\cap ftv(\eta)
                &
                \Sigma(T) = \forall\overline{\alpha}\ldotp sig
                \hspace{1em}
                op_i : \forall\overline{\beta}_i\ldotp \overline{\sigma}_i\to\sigma'_i \in sig
                \\
                local \not\in lt_\emptyset^+(\eta)\cup\overline{lt_\emptyset^+(\theta\ap\sigma_i)}
                &
                \theta = [\overline{\alpha\to\tau}]
                &
                \Gamma\vdash\theta\ap t_i : \forall \overline{\beta}\ldotp \overline{\theta\ap\sigma_i}\to(\theta\ap\sigma_i'\to\eta)\to\eta
            \end{array}
        }\\
        \infer[Cap]{
            \Gamma\vdash K_{cap}\ap\overline{\tau}\ap m\ap h : T\ap local \ap\overline{\tau}
        }{
            K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap local\ap\overline{\alpha} \in \Sigma
        }
        \hspace{2em}
        \infer[Handler]{
            \Gamma\vdash handler_m ~t : \tau
        }{
            \Gamma\vdash t : \tau
        }\\
        \begin{array}{ccccc}
            \mathframebox{\Gamma\vdash_{\overline{x}}\overline{\tau}} &
            \infer[TypesOf]{\Gamma\vdash_{\overline{x}}\overline{\tau}}{\overline{x :_\cdot \tau} \subset \Gamma} &
            \mathframebox{\Gamma\vdash p} &
            \infer[\epsilon Prog]{\Gamma\vdash\epsilon}{} &
            \infer[Prog]{\Gamma\vdash x : s = t, p}{\Gamma\vdash t : s & \Gamma\vdash p}
        \end{array}\\
        \begin{array}{cccc}
            \mathframebox{\Gamma\vdash \sigma <: \tau} &
            \infer[SubAny]{\Gamma\vdash \sigma <: Any\ap local}{} &
            \infer[SubT]{\Gamma\vdash T\ap\Delta' <: T\ap\Delta}{\Delta' <: \Delta} &
            \infer[SubBound]{\Gamma\vdash \alpha <: \tau}{\alpha <: \tau \in \Gamma}
        \end{array} \\
        \begin{array}{cccc}
            \mathframebox{\Delta' <: \Delta} &
            \infer[SubFree]{free <: \Delta}{} &
            \infer[SubLocal]{\Delta <: local}{} &
            \infer[Sub\&]{\Delta' <: \&\overline{\Delta}}{local\in\overline{\Delta}}
        \end{array}
    \end{gather*}
    \caption{Typing rules for $Core_{\Delta}$}
    \label{fig:core-delta-typing}
    % todo кажется, сабтайпинг не работает нормально без сабтайпинга на конструкторах
\end{figure}

% todo about the default generic bound for operations
% todo equality up to normalization
% todo (local \in) check respects normalization
% todo careful checks of escaping for handlers (State example)

\subsection{Lifetime tunnelling}

Unlike OCaml modal types~\cite{lorenzen2024oxidizing}, our system permits types annotated with lifetimes to instantiate generic parameters.
Following the terminology introduced by Boruch-Gruszecki et al.~\cite{boruch2023capturing}, we refer to this mechanism as \emph{lifetime tunnelling}.
In the following, we discuss alternative approaches to this problem and provide a comparative analysis. % todo highlighting the benefits and trade-offs of our solution.

Consider, for example, a function that updates the first component of a pair.
In our approach, it suffices to specify appropriate bounds for the generic parameters to ensure that the function correctly operates on tracked values.
Furthermore, note that if the function is instantiated with untracked types, its result will likewise remain untracked: no superfluous constraints will be imposed.
\begin{minted}{swift}
    func mapFirst(p: Pair<a, b>, f: (a) -> c): Pair<c, b>
            where a <: scoped(local) Any, b <: scoped(local) Any, c <: scoped(local) Any {
        Pair(f(fst(p)), snd(p))
    }
\end{minted}

% todo mention somewhere that our generics are invariant, with lifetimes as a special case

% todo лайфтаймами нельзя инстанциировать полиморфные параметры, но конструкторы данных можно
%A second approach would be to prohibit the instantiation of function type parameters with lifetimes, while still permitting lifetimes to instantiate data constructors.
%This method does not involve bounded polymorphism; however, it requires that all generic occurrences be explicitly annotated with a lifetime.
%Additionally, it necessitates support for variance and mandates that the result's lifetime be tracked independently of the argument lifetimes.
%
%\begin{minted}{swift}
%    func mapFirst(
%        p: Pair<scoped(local) a, scoped(local) b>,
%        f: (scoped(local) a) -> scoped(local) c
%    ): Pair<scoped(local) c, scoped(local) b> {
%        Pair(f(fst(p)), snd(p))
%    }
%\end{minted}
%
%A third approach would be to propagate lifetimes of generics outside of a type constructor.



% todo пропагирование лайфтаймов за конструктор

% todo решение с перегрузкой

% todo решение с полиморфизмом


%Another approach is to propagate lifetimes of generics outside of a type constructor.
%This will force us to return a tracked pair, since it will contain components that with lifetime approximated to a constructor's lifetime.
%Modal OCaml allows to return locals by \texttt{exclave} feature~\cite{lorenzen2024oxidizing}:
%\begin{minted}{ocaml}
%    val mapFirst : 'a 'b pair @ local -> ('a @ local -> 'c @ local) -> 'c 'b pair @ local
%    let mapFirst p f = exclave pair (f (fst p)) (snd p)
%\end{minted}

TODO % todo reduce amount of boilerplate for polymorphic code
% todo bounds instead of boxing (from capturing types)
% todo why tunelling (otherwise too much code duplication on polymorphic code)

\subsection{Integration with implicit parameters}

To extend $Core_\Delta$ with implicit parameters, resulting in $Core_\Delta^{im}$, it is necessary to incorporate omitted application into both the syntax and the translation rules, as described in Section~\ref{sec:implicits}.
However, several details require careful consideration.

Previously, to select appropriate implicit arguments, we employed type equality between the type of the contextual binding and the expected type of the implicit parameter (see Fig.\ \ref{fig:core-im-core-implicit-inference}).
However, types in $Core_\Delta$ also include lifetimes, which should not participate in the inference process.
At the same time, lifetime correctness must still be enforced.
Therefore, we revise the rules as shown in Figure~\ref{fig:core-im-delta-core-implicit-inference}, where $erase(\cdot)$ denotes an operation that erases all lifetime information by setting all lifetimes to $free$.

\begin{figure}
    %! suppress = EscapeAmpersand
    \begin{gather*}
        \mathframebox{\Gamma\vdash t : \tau \step t_{c}} \\
        \infer[CtxApp]{
            \Gamma\vdash t\ap\overline{u} : \sigma \step t_{c} \ap \overline{x}\ap\overline{u_{c}}
        }{
            \Gamma\vdash t : \ctx{\overline{\tau_1}} \overline{\tau} \to \sigma \step t_{c} &
            \Gamma\vdash_{\overline{\tau_1}}\overline{x} &
            \overline{\Gamma\vdash x : \tau_2} &
            \overline{\Gamma\vdash \tau_2 <: \tau_1} &
            \overline{\Gamma\vdash u : \tau \step u_{c}}
        } \\
        \mathframebox{\Gamma\vdash_{\overline{\tau}} \overline{x}}
        \text{\hspace{2em}}
        \infer[Infer]{\Gamma\vdash_{\overline{\tau}} \overline{x}}{\overline{x :_c erase(\tau)}\subset erase(\Gamma)}
    \end{gather*}
    \caption{Inference of implicit parameters for $Core_\Delta^{im}$.}
    \label{fig:core-im-delta-core-implicit-inference}
\end{figure}

% TODO extend to subtyping on arguments

% todo \overline{\sigma} \text{ distinct} &

TODO % todo


\subsection{Using effects with tracked values}

Note that, at present, it is not possible to pass tracked values to effectful operations.
This limitation arises from the fact that capabilities are tracked, and their usage always requires an associated delimited continuation~--- the corresponding marker becomes invalid outside the scope of the relevant handler.
However, if the use of a tracked value does not involve a continuation, it is safe to lend it to an operation call.
Examples of such values include tracked resources or capabilities that witness tail-resumptive operations. % todo citations

To enable this, we can introduce an additional lifetime, $regional$, with the ordering $free <: regional <: local$.
This $regional$ lifetime differs from $local$ in two key aspects: it can bound generics of effectful operations, and it can appear within the parameter types of operations.

In fact, permitting the passing of arbitrary capabilities to an operation effectively corresponds to representing a higher-order effect~\cite{wu2014effect, zhang2020handling, van2022handling}.
We defer the investigation of this matter to future work.




% todo check "effectful operation" term

% todo невозможность отсылать локальные вещи операциям это слишком жестко, нужно ослабить, иначе даже в массив сложит трекаемые вещи в одном скоупе не получится
% todo lifetimes in the middle instead of `here` mode (to allow handlers consume tracked things)

%todo \cite{hannan1998type, boruch2023capturing}

% todo future work: higher-ranked types, type inference
% todo higher-rank polymorphism is required for lambdas, иначе ничего не будет работать с абстракцией по хендлерам. Хотя можно просто всё сделать локалом в контексте по умолчанию, но тогда могут быть траблы с кепчурингом. Нужно исследовать, можно ли это как-то попроще добавить.

% todo some safety theorem


\section{Adoption in mainstream languages} \label{sec:mainstream}

%Adoption of such a big feature as an effect system in a mainstream language is a big challenge.
%An effect system design should be simple and make use of available developer experience.
%Furthermore, it should not require boilerplate and be convenient in use with various popular language features.
%Finally, an effect system design should provide a clear path of gradual adoption as well as escape hatches allowing to solve complicated scenarios outside of an effect system and integrate with it afterwards.
%
%% todo похвалить предложенный дизайн в чём-т
%In this section we informally discuss possible extensions to an effect system design that are supposed to make it better in terms of aforementioned requirements.



\subsection{Simplifying lifetime polymorphism} \label{subsec:lifetime-elision}


TODO % todo

\subsection{Escaping from an effect system}

% todo unsafe escape hatches

TODO % todo

\subsection{Migrating to an effect system}

TODO % todo

\subsection{Working with OOP}

% todo every method is a higher-order function (see citatioon in Capturing types)

TODO % todo

% todo abstraction inference
% todo bidirectional semantics and higher-order effects

\section{Related work} \label{sec:related}

% todo capture calculus boxing

% todo row-types
% todo capability-based, Scala
% todo modal effect types
% todo coeffects, coeffect style vs effect style
% todo papers about regions?

TODO % todo

% todo type inference and symilarity with first-class polymorphism

% todo обобщить текущую систему через дженерики, кайнды и нормальный варианс


\section{Conclusion} \label{sec:conclusion}

TODO % todo


%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
\begin{acks}
    TODO % todo
\end{acks}

% TODO appendix с полным исчислением

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
% todo add doi links where possible for convenience of readers
\bibliographystyle{ACM-Reference-Format}
\bibliography{bib}

\end{document}
