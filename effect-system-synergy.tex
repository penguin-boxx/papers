%! suppress = MissingLabel
%%
%% This is file `effect-system-synergy.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,journal,bibtex,acmsmall')
%%
%% IMPORTANT NOTICE:
%%
%% For the copyright see the source file.
%%
%% Any modified versions of this file must be renamed
%% with new filenames distinct from effect-system-synergy.tex.
%%
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%%
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[acmsmall]{acmart}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
%\AtBeginDocument{%
%    \providecommand\BibTeX{{%
%        Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
%\setcopyright{acmlicensed}
%\copyrightyear{2026}
%\acmYear{2026}
%\acmDOI{XXXXXXX.XXXXXXX}

%%
%% These commands are for a JOURNAL article.
%\acmJournal{JACM}
%\acmVolume{37}
%\acmNumber{4}
%\acmArticle{111}
%\acmMonth{1}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

% Line numbers
% https://tex.stackexchange.com/questions/16010/number-every-line-of-pages
\usepackage{lineno}
\usepackage{mathtools}
\linenumbers
% ------------------------------------------------

\usepackage{multicol}
\usepackage{minted}
\setminted{xleftmargin=\parindent, autogobble, escapeinside=\#\#, numberblanklines=false, fontsize=\small} % todo use lstlisting instead with custom keywords
\usepackage{proof}
\usepackage[inference]{semantic}

\newcommand{\graybox}[1]{\colorbox{lightgray}{$\displaystyle #1$}}
\newcommand{\mathframebox}[1]{\framebox{$\displaystyle #1$}}
\newcommand{\vor}{~|~}
\newcommand{\ap}{~}
\newcommand{\ctx}[1]{ctx(#1)~}
\newcommand{\step}{\rightsquigarrow}
\newcommand{\local}{\top}
\newcommand{\free}{\bot}
\newcommand{\keyword}[1]{\mathbf{#1}}
\newcommand{\identation}{\text{\hspace{2em}}}

%%
%% end of the preamble, start of the body of the document source.
%! suppress = TooLargeSection
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{One Plus One: Effect System as a Synergy of Implicit Parameters and Type-Based Escape Analysis}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
%\author{Ben Trovato}
%\authornote{Both authors contributed equally to this research.}
%\email{trovato@corporation.com}
%\orcid{1234-5678-9012}
%\author{G.K.M. Tobin}
%\authornotemark[1]
%\email{webmaster@marysville-ohio.com}
%\affiliation{%
%    \institution{Institute for Clarity in Documentation}
%    \city{Dublin}
%    \state{Ohio}
%    \country{USA}
%}
%
%\author{Lars Th{\o}rv{\"a}ld}
%\affiliation{%
%    \institution{The Th{\o}rv{\"a}ld Group}
%    \city{Hekla}
%    \country{Iceland}}
%\email{larst@affiliation.org}
%
%\author{Valerie B\'eranger}
%\affiliation{%
%    \institution{Inria Paris-Rocquencourt}
%    \city{Rocquencourt}
%    \country{France}
%}
%
%\author{Aparna Patel}
%\affiliation{%
%    \institution{Rajiv Gandhi University}
%    \city{Doimukh}
%    \state{Arunachal Pradesh}
%    \country{India}}

\author{Andrey Stoyan}
\affiliation{%
    \institution{HSE University}
    \city{Saint Petersburg}
    \country{Russian Federation}}
\email{a.stoyan@hse.ru}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
%\renewcommand{\shortauthors}{Surname et al.}
\renewcommand{\shortauthors}{Andrey Stoyan}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
    Effects offer a systematic approach to managing code complexity.
    Certain responsibilities can be delegated to an execution context, allowing a computation to interact with this context by performing effects and thereby focusing on other aspects of logic.
    Effect systems elevate information about a program’s side effects to the type level, clarifying abstraction boundaries and enabling static verification of context validity.
    Despite these advantages, effect systems have not seen widespread adoption, largely due to their alien design and the general unfamiliarity of practitioners with the concept.

    In this paper, we propose a perspective on effect system design as a combination of two properly-designed language features: implicit parameters and type-based escape analysis.
    We argue that both features can be naturally realized in mainstream programming languages, are already familiar to practitioners, and provide independent utility.
    We motivate our approach by considering effect systems as mechanism for tracking free variables.
    We detail the requirements for a practical design of implicit parameters and illustrate these concepts with a formal example.
    Furthermore, we introduce a novel type-based escape analysis technique that relies primarily on straightforward programmer-supplied dataflow descriptions. % todo is it correct to talk about dataflow here?
%    Finally, we formalize these ideas by presenting a calculus with an effect system constructed from these two core components. % todo adapt about OOP and other
\end{abstract}

%% todo
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
%    \begin{CCSXML}
%        <ccs2012>
%        <concept>
%        <concept_id>00000000.0000000.0000000</concept_id>
%        <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%        <concept_significance>500</concept_significance>
%        </concept>
%        <concept>
%        <concept_id>00000000.00000000.00000000</concept_id>
%        <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%        <concept_significance>300</concept_significance>
%        </concept>
%        <concept>
%        <concept_id>00000000.00000000.00000000</concept_id>
%        <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%        <concept_significance>100</concept_significance>
%        </concept>
%        <concept>
%        <concept_id>00000000.00000000.00000000</concept_id>
%        <concept_desc>Do Not Use This Code, Generate the Correct Terms for Your Paper</concept_desc>
%        <concept_significance>100</concept_significance>
%        </concept>
%        </ccs2012>
%    \end{CCSXML}

%\ccsdesc[500]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
%\ccsdesc[300]{Do Not Use This Code~Generate the Correct Terms for Your Paper}
%\ccsdesc{Do Not Use This Code~Generate the Correct Terms for Your Paper}
%\ccsdesc[100]{Do Not Use This Code~Generate the Correct Terms for Your Paper}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{static analysis, type systems, effects, capabilities}

%\received{10 July 2025}
%\received[revised]{12 March 2009}
%\received[accepted]{5 June 2009} todo

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle


\section{Introduction} \label{sec:intro}

% Introducton makes claims, all of them should be supported later.

The discipline of programming primarily centers on the management of complexity, enabling developers to concentrate on a specific fragment of behavior within any given code segment.
Abstraction and the separation of concerns are essential strategies in this process: distinct responsibilities are delegated to different program entities, such as functions or modules.
Frequently, such an entity may be abstractly referred to as the \textit{execution context} of a computation, with \texttt{effects} emerging naturally as interactions between the computation and its context~\cite{kiselyov2013extensible}.

An execution context can be characterized by at least one of the following properties:
\begin{enumerate}
    \item Interactions with an execution context are observable.
    For example, the memory management subsystem can be considered as the execution context --- each memory allocation can influence the addresses of subsequent allocations.
    In that case the context is responsible for bookkeeping of memory cells.
    \item The activity of an execution context may be restricted to a particular scope, such that only code within this scope can interact with the context.
    For example, an exception handler operates as an execution context confined to the body of a \texttt{try-catch} block; when an exception is thrown, control is transferred to the handler, which manages the exceptional situation.
    Another case is inversion of control, where an execution context restricts the provision of certain functionality to code within a defined scope, while code outside that scope may interact with a different context and access different functionality.
\end{enumerate}

An effect system reflects effects of a computation at the type level.
It serves two primary purposes.
Firstly, it makes effects explicit in type signatures, allowing functional abstraction boundaries to be specified with greater precision: implementation details are less likely to leak implicitly via context interactions.
Secondly, an effect system provides static enforcement of \textit{effect safety} for a computation’s use: a computation may only be executed within an appropriate context (as previously discussed, contexts may have limited activity scopes).
For example, an effect system is responsible for ensuring that all functionality required by inversion of control is available, and that all exceptions are handled.
It is also worth noting that effect systems can capture additional properties of computations, such as potential for divergence.

Many promising designs of effect systems were proposed: row-polymorphic types~\cite{leijen2014koka}, capabilities and contextual polymorphism~\cite{brachthauser2022effects, boruch2023capturing}, modal types~\cite{tang2025modal}, etc.
However, each of these approaches exhibits its own advantages and drawbacks, and the overall configuration of the design space for effect systems remains underexplored.
At the same time we believe it is important for language designers to have a comprehensive view of the available design options, allowing them to select the most appropriate solution given the specific characteristics and constraints of their target language.

In this paper, we argue that effect systems can be conceptualized as a combination of two simpler and more foundational language features: implicit parameters and type-based escape analysis.
Viewing effect systems from this perspective introduces axes within the effect system design space: varying the designs of these two features yields different possible instantiations.
Moreover, this approach facilitates the seamless integration of effect systems into existing mainstream languages, as many of these languages already support at least one of these features, since each of which is independently practical.

The general idea we present is not novel.
For example, recent work in the Scala programming language bases on similar observations~\cite{odersky2021safer, boruch2023capturing}.
However, our contribution lies in articulating this idea explicitly, systematically exploring its implications, and leveraging these insights to design a new effect system that is both practical and minimalistic.

% рассматриваем сразу и модели и системы эффектов, потому что делается type-based translation

Contributions of this paper are summarized as follows:

\begin{itemize} % todo
    \item We propose a perspective on effect system design as a combination of two properly-designed language features: implicit parameters and type-based escape analysis; and motivate our approach by looking at effect systems as systems for managing free variables (Section~\ref{sec:idea}).
    \item We describe required properties of implicit parameters design and provide a suitable one using a formal calculi (Section~\ref{sec:implicits}).
    \item We provide a novel type-based escape analysis technique that only requires straight-forward dataflow descriptions from a programmer (Section~\ref{sec:escape}).
    \item We show that our design is appropriate in the object-oriented setting (Section~\ref{sec:mainstream}). % todo расширить скоуп на просто финтифлюшки делающие дизайн более прикладным
%    \item We explore practical subtleties of our design and its applicability to object-oriented programming languages (Section~\ref{sec:mainstream}).
    \item We compare our approach with previous art and show that other designs can be considered in implicit parameters and escape analysis basis (Section~\ref{sec:related}).
\end{itemize}


\section{Two pieces of an effect system design} \label{sec:idea}

In this section we introduce the central idea of this paper through practical examples.
We further illustrate that the pragmatic motivations for effect systems emerge organically from common programming scenarios.

\subsection{The road to implicit parameters} \label{subsec:implicits}

In our running example (see fig.\ \ref{fig:db}), where the business logic function performs an update to the database storage.

The first version establishes its own database connection and executes a query.
However, this approach has several notable drawbacks.
Firstly, it hinders testability, as it is not straightforward to replace the database connection with a mock or alternative implementation; consequently, verifying the business logic in isolation becomes challenging.
Secondly, this function produces observable side effects --- such as performing database operations --- which are an integral part of its external contract.
Nevertheless, these effects are not reflected in the function’s type signature.

The second version provides a notable improvement.
Here, the business logic function is parameterized over the database connection, enabling the call site to supply a concrete implementation with the desired semantics.
Furthermore, the observable effects are now made explicit through the \texttt{db} parameter.
However, this approach incurs the overhead of additional syntactic complexity at the call site, as the administrative effort of explicitly passing parameters increases.
While this may appear trivial for a single argument, the burden becomes significant if, for example, four such parameters must be threaded through multiple layers of the call stack.
For best practices to be widely adopted, they should remain at least as accessible and convenient as less optimal alternatives.

To reduce boilerplate, the third version replaces ordinary parameters with dynamically scoped free variables.
These variables acquire their values through lookup within the dynamic scope of the function call.
However, this approach comes at the expense of other benefits: specifically, it sacrifices static typing and the explicit representation of context dependencies.

\begin{figure}
    \begin{tabular}{p{0.3\textwidth} rrr}
        \begin{minipage}[t]{0.3\textwidth}
            \begin{minted}{swift}
                func business1() {
                    let db = Db.open(...)
                    db.query("update ...")
                }
            \end{minted}
        \end{minipage}
        &
        \begin{minipage}[t]{0.3\textwidth}
            \begin{minted}{swift}
                func business2(db: Db) {
                    db.query("...")
                }

                func caller() {
                    let db = Db.open(...)
                    business2(db)
                }
            \end{minted}
        \end{minipage}
        &
        \begin{minipage}[t]{0.3\textwidth}
            \begin{minted}{swift}
                func business3() {
                    db.query("...")
                }

                func caller() {
                    let db = Db.open(...)
                    business3()
                }
            \end{minted}
        \end{minipage}
    \end{tabular}
    \caption{The road to dynamically scoped free variables.}
    \label{fig:db}
\end{figure}

To regain static type safety, we approximate dynamically scoped free variables using implicit function parameters~\cite{lewis2000implicit}.
At the declaration site, we introduce a \texttt{context} keyword to define a group of implicit parameters, which are automatically supplied by the compiler at the call site (see fig.\ \ref{fig:implicits}).
To make a value available for implicit parameter resolution, we employ the \texttt{context let} declaration syntax.

\begin{figure}[h]
    \begin{tabular}{p{0.5\textwidth} rl}
        \begin{minipage}[t]{0.3\textwidth}
            \begin{minted}{swift}
                context(db: Db)
                func business4() {
                    db.query("...")
                }
            \end{minted}
        \end{minipage}
        &
        \begin{minipage}[t]{0.3\textwidth}
            \begin{minted}{swift}
                func caller() {
                    context let db = Db.open(...)
                    business4()
                }
            \end{minted}
        \end{minipage}
    \end{tabular}
    \caption{Reclaming static type safety with implicit parameters.}
    \label{fig:implicits}
\end{figure}

In terms of effects and contexts, \texttt{context let} introduces an execution context, whose scope is restricted to the corresponding lexical region, and provides functionality of access to a database storage.
Implicit parameters express a function's requirements for its context.
In order to invoke such a function, the context must establish its validity by supplying concrete values for these implicit parameters.
We refer to these values as \textit{capabilities}, and logically they serve as witnesses of context validity.
It is important to note, that until this point our discussion was based solely on the mechanism of bindings, and did not require any deep understanding of the abstract notion of effects.

Exceptions and other algebraic operations can be tracked in an analogous manner~\cite{odersky2021safer}.
For example, a \texttt{throw SomeException()} construct can be interpreted as calling a function that requires an implicit parameter of type \texttt{Handler<SomeException>}.
Correspondingly, constructs that handle exceptions must supply appropriate witness values for these implicit parameters.
\begin{minted}{swift}
    func checkingExceptions() {
        try { // provides a capability of type Handler<SomeException>
            throw SomeException() // requires a capability of type Handler<SomeException>
        } catch (e: SomeException) { ... }
    }
\end{minted}

Nowadays, several widely used programming languages provide support for implicit parameters, and the inference mechanisms associated with these parameters is well understood~\cite{KEEP-context-parameters, oliveira2010type, lewis2000implicit}.
Moreover, implicit parameters alone are sufficient as the evidence-passing technique to implement tail-resumptive algebraic operations~\cite{xie2020effect}.

\subsection{Retain effect safety with escape analysis} \label{subsec:escape}

An effect system should ensure that all computations are executed within appropriate contexts --- a property we refer to as \textit{effect safety}.
In our setting, the context must supply capabilities as evidence of its validity.
Consequently, these capabilities must not be allowed to escape their corresponding contexts.
For example, if a \texttt{Handler} value were to escape a corresponding \texttt{try-catch} block, we would lose the guarantee that all exceptions are handled and, thereby, the effect safety itself:
\begin{minted}{swift}
    func unsafe() {
        let f = try {
            () => throw SomeException() // captures the Handler<SomeException> capability
        } catch (e: SomeException) { ... }
        f() // throws SomeException
    }
\end{minted}

Note that, in the example, the \texttt{Handler<SomeException>} capability acts as a lexically scoped free variable for the lambda function.
The ability to close over such capabilities enables the technique known as \textit{contextual polymorphism}~\cite{brachthauser2020effects, brachthauser2022effects}.
This approach allows higher-order functions to remain fully transparent with respect to effects, without introducing explicit polymorphic type variables that range over effect sets.
Specifically, the type of a \texttt{map} function need not be entangled with effect-related parameters (we will discuss the \texttt{scoped} syntax in detail later)\footnote{We adopt the Haskell naming convention, where type names beginning with a lowercase letter denote type variables, which are implicitly universally quantified.}:
\begin{minted}{swift}
    func map(xs: List<a>, f: #\color{gray}\texttt{scoped}# (a) -> b): List<b>

    context(io: IO)
    func printAll(xs: List<Int>) {
        map(xs, (x) => io.print(x)) // capability capturing is safe here
    }
\end{minted}

Compare this with the corresponding function type in the Koka language, which features row-polymorphic types~\cite{leijen2014koka}:
\begin{minted}{kotlin}
    fun map(xs: list<a>, f: (a) -> e b): e list<b>
\end{minted}

To control the escaping of capabilities, some form of escape analysis is required. % todo citations
Given that effect systems operate at the type level, it is natural to employ type-based techniques for escape analysis as well.
Furthermore, since this analysis must account for the flow of capabilities across function boundaries, it should be cross-procedural and directly reflected in function signatures.
In the following, we provide an informal overview of the type-based escape analysis technique introduced in this paper.

We refer to values that must not escape a given scope as \textit{tracked}, and likewise, their types are treated as tracked.
For instance, capabilities are tracked, as are by default the types of implicit parameters.
To distinguish between tracked and non-tracked types, we annotate each type $T$ with a special lifetime label $lab$, denoted by the syntax:
\[scoped(lab)\ap T\]
Lifetime labels range over \texttt{free}, \texttt{local} and polymorphic lifetime variables.
The \texttt{free} label is used for non-tracked values and is assumed by default for all types.
The \texttt{local} label appears in tracked types, which the type system handles specially to prevent their escape; for instance, a function is prohibited from returning a value of a tracked type.

For example, the \texttt{map} function can be explicitly typed to ensure that it does not leak its argument function, thereby making it safe to pass closures that possess capabilities:
\begin{minted}{swift}
    func map(xs: List<a>, f: scoped(local) (a) -> b): List<b>
\end{minted}

To enable a function to propagate its arguments through its result, polymorphism over lifetime labels can be used.
In essence, this is an explicit specification of the function’s dataflow directly in the type signature. % todo dataflow term and citation
For instance, a lazy \texttt{map} function does not eagerly compute and return the final result; instead, it immediately yields a collection that encapsulates the processing logic.
This behavior can be captured by assigning the same lifetime variable~\texttt{l} to both the argument \texttt{f} and the result type.
Consequently, the type system records that any tracked capabilities captured by \texttt{f} may be retained within the result.
Such a function thus continues to support contextual polymorphism, as it can only permit \texttt{f} to escape with the result; furthermore, the call site is made aware~--- via the signature~--- that the result must not escape its prescribed context:
\begin{minted}{swift}
    func lazyMap(xs: LazyList<a>, f: scoped(l) (a) -> b): scoped(l) LazyList<b>

    context(io: IO) // io: scoped(local) IO
    func printAll(xs: LazyList<Int>) {
        let ys: scoped(local) LazyList<Int> = lazyMap(xs, (x) => io.print(x))
        ys.collect() // force execution
    }
\end{minted}

To express the capture of two or more lifetime-polymorphic values within the same scope, we employ the intersection of lifetimes:
\begin{minted}{swift}
    func compose(f: scoped(l1) (b) -> c, g: scoped(l2) (a) -> b): scoped(l1&l2) (a) -> c
        = (x) => f(g(x))
\end{minted}

For the sake of simplicity, we dispense with lifetime polymorphism for compound datatypes by determining each compound's lifetime as the intersection of the lifetimes of its components.
Upon destructuring, the lifetimes of the individual components are, in turn, approximated by the lifetime of the original compound datatype.
\begin{minted}{swift}
    func first(x: scoped(l1) Int, y: scoped(l2) Int): scoped(l1&l2) Int {
        let intPair: scoped(l1&l2) IntPair = IntPair(x, y)
        return intPair.fst
    }
\end{minted}

We define subtyping so that non-tracked values may be used in positions where tracked values are expected.
This design increases the number of safe well-typed programs and facilitates gradual adoption of effect tracking for languages transitioning from untyped effects to an effect system.

We permit tracked types to instantiate polymorphic type parameters, thereby making them first-class citizens in the language.
To control when tracked types are eligible for instantiation, we employ bounded polymorphism.
For example, the \texttt{lazyMap} function is written in such a way that it does not leak values of polymorphic type parameters (e.g., through global state), but rather returns them directly to the caller.
As a result, these parameters may be instantiated with tracked types:\footnote{We assume that \texttt{Any} serves as the top element in the type lattice.} \footnote{For backward compatibility, the type \texttt{scoped(free) Any} may be used as the default bound.}
\begin{minted}{swift}
    func lazyMap(xs: LazyList<a>, f: scoped(l) (a) -> b): scoped(l) LazyList<b>
        where a <: scoped(local) Any, b <: scoped(local) Any
\end{minted}

Various techniques can be employed to reduce boilerplate associated with lifetime polymorphism and the specification of bounds.
For example, the lifetime elision mechanism in the Rust language~\cite{matsakis2014rust} uses heuristics to automatically insert lifetime variables, thereby alleviating the need for explicit annotation.
In our approach, using the \texttt{scoped} keyword without a specific lifetime parameter similarly invokes the elision mechanism.
We will discuss this technique, along with alternative methods, in Section~\ref{subsec:lifetime-elision}.

The utility of type-based escape analysis extends well beyond its role in the construction of effect systems.
Specifically, it can be leveraged to reduce the number of heap allocations~\cite{lorenzen2024oxidizing}, enable borrowing for the ownership-based resource management~\cite{matsakis2014rust, lorenzen2024oxidizing}, and ensure the safety of non-local returns~\cite{akhin2021kotlin}.

\subsection{Summary} \label{subsec:idea-summary}

An effect system can be regarded as the integration of implicit parameters with type-based escape analysis.
Consequently, the design of an effect system naturally decomposes into two distinct components and can be developed incrementally in a step-by-step manner.

In fact, our previous discussion has primarily focused on free variables.
Indeed, a term inherently depends on its context via its free variables, acquiring different semantics depending on the particular context in which it is evaluated.
So, free variables are the target for effect systems, while bound once are regulated by canonical type systems.

Our perspective on effect systems arises from a fundamental observation: the semantics of free variables can be defined by two principal scoping disciplines~--- dynamic and lexical scoping.
Adopting one or the other proves advantageous depending on the programming scenario.
We summarize the correspondence between these two disciplines in Figure~\ref{fig:free-vars} and further discuss the relationship to existing approaches in effect system design in Section~\ref{sec:related}.

\begin{figure}
    \centering
    \begin{tabular}{|l|l|l|}
        \hline
        Free variables & dynamically scoped & lexically scoped \\
        \hline
        Represent & unfulfilled context requirements & fulfilled context requirements \\
        Dealt by & implicit parameters & type-based escape analysis \\
        User specifies & more function parameters & a function’s dataflow \\ % todo other analysis may require something different
        \hline
    \end{tabular}
    \caption{Effect systems are for managing free variables.}
    \label{fig:free-vars}
\end{figure}


\section{Core calculus} \label{sec:core}

In this section, we introduce an explicitly typed, call-by-value core calculus, denoted as $Core$, which serves as the foundational framework for our study.
In subsequent sections, we will extend $Core$ by incorporating features such as omitting application and type-based escape analysis to enhance its expressiveness and safety guarantees.

\subsection{Effect handlers} \label{subsec:handlers}

In our formal developments, we adopt effect handlers as a universal mechanism for defining effects~\cite{plotkin2003algebraic, plotkin2013handling}, since they are sufficiently expressive to capture all effects of interest.
This obviates the need to treat individual effects separately.
Furthermore, in contrast to monad transformers~\cite{liang1995monad, schrijvers2019monad}, the dynamic semantics of effect handlers can be defined independently of any type-directed translation.
Consequently, this approach imposes no inherent constraints on the design of the effect system, providing us greater flexibility.

We begin by providing a brief introduction to effect handlers and demonstrate how they can be used to implement the effects discussed in the previous Section~\ref{sec:idea}.

The \texttt{handle} construct allows to define an execution context for a particular scope by specifying a set of effect operations.
Within this scope, the \texttt{perform} construct allows code to invoke these operations, facilitating interaction with the execution context managed by the handler.
The implementation of each operation within a handler is granted access to the continuation at the call site.
This continuation can be invoked to resume the computation with an operation's result.

In our setting, we employ lexically scoped handlers, which require that each \texttt{perform} invocation is associated with a specific handler instance through explicit binding~\cite{biernacki2019binders, brachthauser2020effects}.

For example, consider defining an execution context that supplies a specific constant value to a computation.
This can be achieved by providing a handler for a \texttt{Reader} effect, which offers an \texttt{ask} operation that returns the designated constant.
The following computation sums the results of two invocations of \texttt{ask}; with implementation returning the constant $21$, the overall result of the computation will be $42$:
\[
    \begin{array}{l}
        \keyword{handle} ~ h : Reader\ap Int ~\keyword{with}~ \{ ask = \lambda k\ldotp k\ap 21 \} ~\keyword{in} \\
        \keyword{perform}~ask~h~() + \keyword{perform}~ask~h~()
    \end{array}
\]

To implement exception handling, the \texttt{throw} operation can be defined to discard the current continuation, effectively aborting the remainder of the computation.
For instance, the following program returns the thrown value $42$:
\[
    \begin{array}{l}
        \keyword{handle}~ h : Exception\ap Int ~\keyword{with}~ \{throw = \lambda e~k\ldotp e \} ~\keyword{in} \\
        \keyword{perform}~throw~h~42
    \end{array}
\]

Other algebraic effects, such as mutable state and nondeterminism, can likewise be implemented using the \texttt{handle} construct. % todo citations

%\begin{equation}
%    \begin{array}{l}
%        \keyword{handle}~ h : State\ap Int ~\keyword{with}~ \{\\
%        \indent get = \lambda k\ldotp\lambda s\ldotp k\ap s\ap s \\
%        \indent put = \lambda s'~k\ldotp\lambda s\ldotp k\ap ()\ap s' \\
%        \} ~\keyword{in}~ \\
%        perform~put~h~42; perform~get~h~42
%    \end{array}
%\end{equation}

\subsection{Syntax of $Core$} \label{subsec:syntax-core}

Let us introduce the syntax of $Core$, as illustrated in Figure~\ref{fig:core-syntax}.
We use an overline to denote a sequence of corresponding entries.
Constructs highlighted in gray are included solely to support the operational semantics.

The main considerations that have shaped this syntax are as follows:
\begin{itemize}
    \item We split function arguments into two groups: \emph{contextual arguments}, which will be inferred automatically in future extensions, and ordinary arguments.
    This separation facilitates the development of algorithmic typing rules, because the functional type distinguishes contextual arguments from ordinary ones.
    \item Abstractions and applications are uncurried, ensuring that inference of future implicit parameters is local.
    That is, all necessary type information is available at the application rule~\cite{pierce2000local}.
    \item For the same purpose we couple contextual and ordinary parameters.
    \item Capability constructors $K_{cap}$ are used in an operational semantics to represent a capability. % todo cite generalized evidence passing?
    \item  The \texttt{handle} construct introduces a capability associated with the newly created handler instance and binds it to a name.
    The \texttt{perform} construct, in turn, requires a capability in order to perform an effectful operation.
    This approach helps us to naturally build an effect system from the perspective discussed in Section~\ref{sec:idea}.
    \item For conciseness, we omit \texttt{return} blocks in handlers, since they do not contribute additional expressiveness.
    \item The $handler_m$ construct acts as a continuation delimiter, identified by a unique marker $m$ for operational semantics purposes.
    \item In the function type $\ctx{e} \overline{\tau} \to \sigma$, the overline denotes a tuple of argument types, with the empty tuple interpreted as the unit type.
    This design ensures that only explicit application can trigger effectful computation; effects cannot arise accidentally from merely mentioning a variable.
    \item The typing context differentiates regular bindings from \emph{contextual bindings}, the latter of which are restricted to monotypes.
    While separate typing contexts for each binding class would be possible, this would necessitate different variable domains for contextual and ordinary bindings.
\end{itemize}

% todo можно ли вызвать сейчас конструктор нормально?
\begin{figure}
    \centering
    \begin{gather*}
        \begin{array}{lrll}
            \text{Variables} & & x, y, z, f, g, op \\
            \text{Values} &v &\Coloneqq x \vor \Lambda \overline{\alpha} \ldotp v \\
            &&\vor K\ap \overline{\tau} \ap \overline{v} \vor \graybox{K_{cap}\ap\overline{\tau}\ap m\ap h} \\
            &&\vor \lambda \overline{x : \tau}~\overline{y : \sigma}\ldotp t
            \\
            \text{Terms} &t, u &\Coloneqq v \vor t\ap\overline{\tau} \vor t \ap \overline{t} \ap \overline{t} \\
            &&\vor match ~ t ~ with ~\{\overline{K \ap \overline{x} \to t}\} \\
            &&\vor perform ~ op \ap x \ap \overline{\tau} \ap \overline{t} \\
            &&\vor handle ~ x : T \ap \overline{\tau} ~with ~h~in ~t \\
            &&\vor \graybox{handler_m ~ t}
            \\
            \text{Handlers} &h &\Coloneqq \{ \overline{op = t} \}
            \\
            \text{Programs} &p &\Coloneqq \epsilon \vor x : s = t, p
        \end{array}
        \begin{array}{lrl}
            \text{Type variables} && \alpha, \beta \\
            \text{Type constructors} && T \\
            \text{Monotypes} & \tau, \sigma, \eta &\Coloneqq \alpha \vor T \ap \overline{\tau} \vor \ctx{e} \overline{\tau} \to \sigma \\
            \text{Type schemas} & s &\Coloneqq \forall\overline{\alpha}\ldotp \tau \\
            \text{Effect rows} & e &\Coloneqq \epsilon\vor \tau, e \\
            \text{Typing contexts} & \Gamma &\Coloneqq \emptyset \vor x : s, \Gamma \vor x :_c \tau, \Gamma \\
            \text{Effect contexts} & \Sigma &\Coloneqq \{\overline{K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap\overline{\alpha}}\} \\
            \text{Effect signatures} & sig &\Coloneqq \{\overline{op : \forall\overline{\alpha}\ldotp\overline{\tau}\to\sigma}\} \\
            \text{Data constructors} & & K : \forall\overline{\alpha}\ldotp \overline{\tau}\to T\ap \overline{\alpha} \\
            \text{Free type variables} & & ftv(\cdot) \\
        \end{array}\\
        \begin{aligned}
            \text{Evaluation context } E \Coloneqq \square \vor E \ap \overline{\tau} \vor E \ap \overline{t}\ap \overline{t} \vor v \ap (\overline{v}, E, \overline{t}) \ap \overline{t} \vor v \ap \overline{v} \ap (\overline{v}, E, \overline{t}) \vor K\ap\overline{\tau}\ap(\overline{v}, E, \overline{t}) \vor handler_m ~ E
        \end{aligned}\\
    \end{gather*}
    \caption{Syntax of $Core$.}
    \label{fig:core-syntax}
\end{figure}

Note that the type of first-class functions contains a list of implicit parameters.
This enables us to type abstractions over handlers.
For example, the following function establishes an execution context by introducing a handler for an exception type \texttt{E}\footnote{We employ an informally defined surface syntax for explanatory purposes; its correspondence to our formal definitions is straightforward.}:
\begin{minted}{swift}
    func withE(f: context(Handler<E>) () -> r): r =
        try { f() } catch (e: E) { ... }
\end{minted}

We assume that the effect context $\Sigma$ is populated by user-defined \texttt{effect} declarations, analogous to those found in Koka. % todo citation
Specifically, for a program containing the following declaration,
\begin{minted}{swift}
    effect Eff<a> {
        op id(x: b): b
        op yield(x: a): Unit
    }
\end{minted}
we have \[\Sigma = \{EffK_{cap} : \forall\alpha\ldotp\{id : \forall\beta\ldotp b\to b, yield : a \to Unit\} \to Eff\ap a\}\]
There exists a bijection between capability constructors and effect types.

\subsection{Operational semantics of $Core$}

% todo refer to a paper that proposed to instantiate a handle_m frame

Let us highlight the most significant aspects of our operational semantics, as presented in Figure~\ref{fig:core-operational}:
\begin{itemize}
    \item \textbf{(handle)} rule selects the capability constructor associated with the specified effect type $T$ and uses it to instantiate a new capability.
    Additionally, it allocates a fresh marker $m$ and installs it with the $handler$ construct.
    \item \textbf{(perform)} rule deconstructs the provided capability, identifies the targeted operation, and invokes it with the current continuation, which is delimited by the associated marker $m$.
    Since we adopt deep handlers~\cite{hillerstrom2018shallow}, the handler is reinstalled within the continuation.
\end{itemize}

\begin{figure}
    \[
        \begin{array}{llll}
            \text{(tapp)} &(\Lambda \overline{\alpha}\ldotp t) \ap \overline{\tau} &\longrightarrow &[\overline{\alpha\to\tau}]\ap t
            \\
            \text{(app)} &(\lambda \overline{x}~\overline{y}\ldotp t) \ap \overline{v} \ap \overline{v'} &\longrightarrow &[\overline{x\to v}, \overline{y\to v'}]\ap t
            \\
            \text{(match)} &match ~K \ap \overline{v}~ with ~ \{ \overline{K_i \ap \overline{x} \to u_i}\} &\longrightarrow &[\overline{x\to v}]\ap u_k, \text{ where } K = K_k
            \\
            \text{(handle)} &handle ~ x : T \ap \overline{\tau} ~with~h~in~t &\longrightarrow & handler_m ~[x \to K_{cap} \ap\overline{\tau}\ap m \ap h] \ap u
            \\
            &&\text{where} & m \text{ fresh}, {\color{gray}K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap\overline{\alpha} \in \Sigma}
            \\
            \text{(return)} &handler_m ~v &\longrightarrow & v
            \\
            \text{(perform)} &handler_m~E[perform \ap op \ap (K_{cap}\ap\overline{\tau_1}\ap m \ap h)\ap\overline{\tau_2}\ap\overline{v}] &\longrightarrow &t \ap \overline{\tau_2}\ap \overline{v}\ap k
            \\
            &&\text{where} & (op = t) \in h, {\color{gray}\theta = [\overline{\alpha\to\tau_1}, \overline{\beta\to\tau_2}],} \\
            &&& {\color{gray}K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap\overline{\alpha} \in \Sigma,} \\
            &&& {\color{gray}(op : \forall\overline{\beta}\ldotp\overline{\sigma}\to\sigma') \in sig,} \\
            &&& k = \lambda x : \theta\ap\sigma' \ldotp handler_m~E[x]
        \end{array}
    \]
    \vspace{-3em}
    \[
        \hspace{-15em}\infer[\text{(step)}]{E[t]\longrightarrow E[t']}{t\longrightarrow t'}
    \]
    \caption{Operational semantics of $Core$.}
    \label{fig:core-operational}
\end{figure}

It is important to note that every \texttt{perform} operation in our system is explicitly directed to a particular handler instance.
As a result, there is no issue of accidental effect handling, so the effect encapsulation is achieved by default~\cite{lindley2018encapsulating}. % todo more citations

For instance, consider a function \texttt{withE1} that installs a handler for exception \texttt{E1}.
If a computation \texttt{f} potentially raises exception \texttt{E2}, \texttt{withE1} will not be able to intercept this exception, since it does not provide \texttt{f} with the corresponding capability for \texttt{E2}:
\begin{minted}{swift}
    func withE1(f: context(Handler<E1>) () -> r): r =
        try { f() } catch (e: E1) { ... } catch (e: E2) { /* unreachable */ }
\end{minted}

Since handlers are propagated explicitly to the operation call site, our approach eliminates the need for dynamic handler lookup and the collection of the continuation when the callee operation is tail-resumptive~\cite{xie2020effect}.
In a low-level implementation, such a \texttt{perform} construct can thus be compiled to a direct virtual call, further improving efficiency. % todo citation

TODO theorems % todo theorem about determinism (and mb others)

\subsection{Typing rules for $Core$}

\begin{itemize}
    \item The typing rules for $Core$ (see Figure~\ref{fig:core-typing}) are presented in algorithmic form.
    \item For conciseness, we omit both type well-formedness conditions and the (invariant) effect context~$\Sigma$.
    \item Each entry in the effect context~$\Sigma$ can be uniquely identified by its capability type; thus, we treat~$\Sigma$ as a mapping: $\Sigma(T) = \forall\overline{\alpha}\ldotp sig \iff K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap\overline{\alpha}\in\Sigma$.
    \item All variable bindings within the typing context are assumed to be unique with respect to variable names.
\end{itemize}

%! suppress = EscapeAmpersand
\begin{figure}
    \begin{gather*}
        \mathframebox{\Gamma\vdash t : \tau} \\
        \infer[Var]{\Gamma\vdash x\ap\overline{\tau} : [\overline{\alpha\to\tau}]\ap\sigma}{x : \forall\overline{\alpha}\ldotp \sigma \in \Gamma}
        \text{\hspace{2em}}
        \infer[CVar]{\Gamma\vdash x : \tau}{x :_c \tau \in \Gamma} \\
        \infer[Lam]{
            \Gamma\vdash \lambda \overline{x : \tau_1} ~ \overline{y : \tau_2} \ldotp t : ctx(\overline{\tau_1}) ~ \overline{\tau_2} \to \sigma
        }{
            \overline{x :_c \tau_1}, \overline{y : \tau_2}, \Gamma\vdash t : \sigma &
            \overline{\tau_1} \text{ distinct}
        }
        \text{\hspace{2em}}
        \infer[App]{
            \Gamma\vdash t \ap \overline{u_1} \ap \overline{u_2} : \sigma
        } {
            \Gamma\vdash t : ctx(\overline{\tau_1})~\overline{\tau_2}\to\sigma
            &
            \overline{\Gamma\vdash u_1 : \tau_1}
            &
            \overline{\Gamma\vdash u_2 : \tau_2}
        }\\
        \infer[Match]{
            \Gamma\vdash match ~ t ~with ~\{ \overline{K_i\ap \overline{x_j} \to u_i }\}  : \sigma
        }{
            K_i : \forall \overline{\alpha}\ldotp \overline{s_j} \to T\ap\overline{\alpha} &
            \Gamma\vdash t : T \ap\overline{\tau} &
            \overline{x_j : [\overline{\alpha\to\tau}]\ap s_j}, \Gamma \vdash u_i : \sigma
        }\\
        \infer[Perform]{
            \Gamma\vdash perform \ap op\ap \overline{\tau_2}\ap x\ap \overline{t} : \theta\ap\eta
        }{
            \Gamma\vdash x : T\ap \overline{\tau_1} &
            \Sigma(T) = \forall\overline{\alpha}\ldotp sig &
            op : \forall\overline{\beta}\ldotp \overline{\sigma}\to\eta \in sig &
            \theta = [\overline{\alpha\to\tau_1}, \overline{\beta\to\tau_2}] &
            \overline{\Gamma\vdash t : \theta\ap\sigma}
        }\\
        \infer[Handle]{
            \Gamma \vdash handle ~ x : T\ap\overline{\tau}~ with ~ \{\overline{op_i = t_i}\} ~in~u : \eta
        }{
            \begin{gathered}
                x :_c T\ap\overline{\tau}, \Gamma\vdash u : \eta
            \end{gathered}
            &
            \begin{array}{ll}
                \overline{\beta}\not\cap ftv(\eta) & % todo beautify intersection
                \Sigma(T) = \forall\overline{\alpha}\ldotp sig, \hspace{0.5em} op_i : \forall\overline{\beta}\ldotp \overline{\sigma}_i\to\sigma'_i \in sig
                \\
                \theta = [\overline{\alpha\to\tau}] &
                \Gamma\vdash\theta\ap t_i : \forall \overline{\beta}\ldotp \overline{\theta\ap\sigma_i}\to(\theta\ap\sigma_i'\to\eta)\to\eta
            \end{array}
        }\\
        \infer[Cap]{
            \Gamma\vdash K_{cap}\ap\overline{\tau}\ap m\ap h : T\ap\overline{\tau}
        }{
            K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap\overline{\alpha} \in \Sigma
        } % todo looks like a bull shit
        \hspace{2em}
        \infer[Handler]{
            \Gamma\vdash handler_m ~t : \tau
        }{
            \Gamma\vdash t : \tau
        }\\
        \begin{array}{ccccc}
            \mathframebox{\Gamma\vdash t : s} &
            \infer[TLam]{
                \Gamma\vdash\Lambda\overline{\alpha}\ldotp v : \forall\overline{\alpha}\ldotp\tau
            }{
                \Gamma\vdash v : \tau & ftv(\tau) = \overline{\alpha}
            } &
            \mathframebox{\Gamma\vdash p} &
            \infer[\epsilon Prog]{\Gamma\vdash\epsilon}{} &
            \infer[Prog]{\Gamma\vdash x : s = t, p}{\Gamma\vdash t : s & \Gamma\vdash p}
        \end{array}
    \end{gather*}
    \caption{Typing rules for $Core$.}
    \label{fig:core-typing}
\end{figure}

TODO formulate properties % todo

\section{Design of implicit parameters} \label{sec:implicits} % todo perplexityfy

In this section we discuss design decisions for implicit parameters feature that make it more suitable as a component of a practical effect system.
Along the discussion we introduce a formal calculi with implicit parameters $Core^{im}$ as an extension to $Core$.

\subsection{Syntax of $Core^{im}$}

We extend syntax of $Core^{ex}$ with an omitting application, which do not specify the first block of contextual arguments:
\[
    \begin{array}{lcc}
        \text{Terms} & t, u &\Coloneqq \ldots \vor t\ap\overline{t} \vor \ldots
    \end{array}
\]

\subsection{Inference of implicit parameters} \label{subsec:inference}

We give a type-directed translation from $Core^{im}$ to $Core$ (fig.\ \ref{fig:fim-fex-inference}).
Making translation rules for other constructs from typing rules for $Core$ is straight-forward.

$\Gamma\vdash_e \overline{x}$ relation selects from the typing context variables participating in the inference with given effect types.
Note that since the typing context only stores bindings with unique names, a user can shadow a contextual binding with an ordinary one, and it will not participate in the inference anymore.
This issue can be solved, for instance, by making typing context a list with duplications and assigning fresh names to contextual bindings.

\begin{figure}
    %! suppress = EscapeAmpersand
    \begin{gather*}
        \mathframebox{\Gamma\vdash t : \tau \step t_{c}} \\
        \infer[CtxApp]{
            \Gamma\vdash t\ap\overline{u} : \sigma \step t_{c} \ap \overline{x}\ap\overline{u_{c}}
        }{
            \Gamma\vdash t : \ctx{e} \overline{\tau} \to \sigma \step t_{c} &
            \Gamma\vdash_e\overline{x} &
            \overline{\Gamma\vdash u : \tau \step u_{c}}
        } \\
        \mathframebox{\Gamma\vdash_e \overline{x}}
        \text{\hspace{2em}}
        \infer[Infer]{\Gamma\vdash_{\overline{\tau}} \overline{x}}{\overline{x :_c \tau}\subset \Gamma}
    \end{gather*}
    \caption{Inference of implicit parameters.}
    \label{fig:fim-fex-inference}
\end{figure}

There is a design decision to be made, whether inference should rely only on types, or on variable names as well.
The second option is a bit more complicated than the first one, since it requires to store variables names in the effect rows.
Moreover, it excludes renaming of implicit parameters from $\alpha$-equivalence, making a program more fragile regarding renaming.
On the other hand, it allows to use simultaneously multiple effects of the same type.
This problem attracts many attention from researchers. % todo citations
However, we use the first option and argue that in practical programming using multiple effects of the same type is mostly undesired.
We believe that users should provide many domain-specific effects instead of using basic ones directly.
For example, some \texttt{UserRepository} effect is preferable to general \texttt{Database} effect, since it provides higher-level of abstraction.

Another decision is when to substitute implicit parameters, on mentioning or, deferred, on application.
It is a similar question to the type instantiation with first-class polymorphism (type inference infers type parameters)~\cite{emrich2020freezeml}. % todo verify citation
Both ways are useful: the first is convenient with contextually-polymorphic functions \texttt{map(xs, f)}, the second helps with effect abstraction \texttt{withSomeException(f)}. % todo introduce effect abstraction somewhere % todo citations to kotlin, haskell and something
Actually, the decision is about choosing the default, since one behaviour can be changed to another by the $\eta$-expansion. % todo explain better, examples
Namely, assume that the substitution occurs on application:
\begin{minted}{swift}
    f : context(IO) () -> Unit; g : (() -> Unit) -> Unit
    g(() => f())
\end{minted}
Or, assume that substitution occurs on mentioning:
\begin{minted}{swift}
    f : context(IO) () -> Unit; g : (context(IO) () -> Unit) -> Unit
    g(context(_: Eff) () => f()) // abstracts over contextual parameters
\end{minted}
% todo special syntax for explicitly passed implicits
% todo have i introduced surface implicit abstraction somewhere
% todo have i introduced the surface syntax anywhere

TODO properties % todo

\subsection{System $Core^{im+<:}$ with implicit parameters and subtyping} \label{subsec:im-sub}

It is convenient to have some form of subtyping on effect rows, since a function with less context requirements can naturally be used in more permissive contexts.
For example, \texttt{withStd} is a function that provides default implementation for many effects.
We should be able to pass a function that uses only some of them:
\begin{minted}{swift}
    func withStd(f: context(IO, Allocator, Random) () -> r): r
    withStd(g) // g : context(IO) () -> Unit
\end{minted}

% todo find literature
% todo row polymorphism can help somehow?
% todo cite papers about row types
Contexts can be seen as structural record types with width and permutation subtyping.
However, the naive implementation of such records as dictionaries is not very efficient in time and space.

To achieve an efficient implementation of subtyping, we restrict it to be shallow in a sense that one functional type subtypes another only if one effect row subtypes another, while arguments and return types should be the same:
\[
    \infer{\ctx{e} \tau \to \sigma <: \ctx{e'} \tau\to\sigma}{e' <: e}
\]

Now we can implement such shallow subtyping by $\eta$-expansion (fig.\ \ref{sig:fim-sub-app}).
Relation $\Gamma\vdash t\Leftarrow \tau \step t_c$ performs $\eta$-expansion if a functional type is expected.

\begin{figure}
    %! suppress = EscapeAmpersand
    \begin{gather*}
        \mathframebox{\Gamma\vdash t : \tau \step t_c} \\
        \infer[App]{
            \Gamma\vdash t\ap\overline{u} : \eta \step t_c \ap \overline{x} \ap \overline{u_c}
        }{
            \Gamma\vdash t : ctx(\overline{\tau})~\overline{\sigma}\to \eta \step t_c
            &
            \Gamma \vdash_{\overline{\tau}} \overline{x}
            &
            \overline{\Gamma\vdash u \Leftarrow \sigma \step u_c}
        } \\
        \mathframebox{\Gamma\vdash t \Leftarrow \tau \step t_c} \\
        \infer[AppArg]{
            \Gamma\vdash t \Leftarrow \tau \step t_c
        }{
            \Gamma\vdash t : \tau \step t_c
        }
        \text{\hspace{1em}}
        \infer[AppArgCtx]{
            \Gamma \vdash t \Leftarrow ctx(\overline{\tau}) ~\overline{\sigma}\to\eta\step \lambda \overline{x : \tau}~\overline{y : \sigma}\ldotp t_c\ap \overline{x'}\ap\overline{y}
        }{
            \Gamma \vdash t : ctx(\overline{\tau'}) ~\overline{\sigma}\to\eta \step t_c
            &
            \overline{x :_c \tau} \vdash_{\overline{\tau'}} \overline{x'}
            &
            \overline{x~y \text{ fresh}}
        }
    \end{gather*}
    \caption{Application rule for $Core^{im + <:}$.}
    \label{sig:fim-sub-app}
\end{figure}

% todo link to bidirectional typing

% todo big lambda inference

% todo will subtyping break inference?

% todo what if generate application (like for dictionaries) to reorder effect rows (do inhabitation of some form)?

\section{Design of type-based escape analysis} \label{sec:escape}

In this section we develop an extension to the previously discussed systems that statically guarantees that no capabilities escape their corresponding handlers.
The core aspects of this design have already been introduced in Section~\ref{subsec:escape}.

\subsection{Syntax of $Core_\Delta$}

Let us introduce $Core_\Delta$, an extension of $Core$ that incorporates lifetimes, lifetime polymorphism, and bounded polymorphism.
Modifications to the type syntax are presented in Figure~\ref{fig:core-delta-syntax}, with changes highlighted in gray.
\begin{itemize}
    \item Monotypes are now annotated with explicit lifetime labels.
    \item Type schemas support abstraction over lifetime variables and permit the specification of polymorphic bounds.
    \item We introduce utility operations that, given a type, return the set of lifetimes appearing in specified positions~--- positive and negative. % todo cite positions
    Additionally, the lifetime of a generic type variable is approximated by the lifetime of its bounding type.
    \item The resulting lifetime associated with data constructors is computed as the intersection of all lifetimes corresponding to those values that may later be extracted~--- that is, lifetimes encountered in positive positions.
\end{itemize}

%! suppress = MissingLabel
\begin{figure}
    \[
        \begin{array}{lrl}
            \text{Type variables} && \alpha, \beta \\
            \text{Type constructors} && T \\
            \text{Lifetime variables} && \graybox{l} \\
            \text{Lifetimes} & \graybox{\Delta} &\Coloneqq l \vor local \vor free \vor \&\overline{\Delta} \\
            \text{Monotypes} & \tau, \sigma, \eta &\Coloneqq \alpha \vor T \ap \graybox{\Delta} \ap \overline{\tau} \vor \ctx{e} \graybox{\Delta}~\overline{\tau} \to \sigma \\
            \text{Type schemas} & s &\Coloneqq \forall \graybox{\overline{l}}~\overline{(\alpha \graybox{<: \tau})}\ldotp \sigma \\
            \text{Effect rows} & e &\Coloneqq \epsilon\vor \tau, e \\
            \text{Typing contexts} & \Gamma &\Coloneqq \emptyset \vor x : s, \Gamma \vor x :_c \tau, \Gamma \vor \graybox{\alpha <: \tau, \Gamma} \\
            \text{Effect contexts} & \Sigma &\Coloneqq \{\overline{K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap \graybox{local} \ap\overline{\alpha}}\} \\
            \text{Effect signatures} & sig &\Coloneqq \{\overline{op : \forall\overline{(\alpha \graybox{<: \eta})}\ldotp\overline{\tau}\to\sigma}\} \\
            \text{Data constructors} & & K : \forall\graybox{\overline{l}}\ \overline{\alpha}\ldotp \overline{\tau}\to T \ap\graybox{(\&\overline{lt_+(\tau)})}\ap \overline{\alpha} \\
            \text{Free type variables} & & ftv(\cdot) \\
            \text{Positive lifetimes} & & \graybox{lt_+(\cdot)} \\
            \text{Free lifetime variables} & & \graybox{flt_+(\cdot)}, \graybox{flt_-(\cdot)}
        \end{array}
    \]
    \caption{Syntax of types for $Core_\Delta$.}
    \label{fig:core-delta-syntax}
\end{figure}

Syntax of terms follows the changes in the syntax of types:
\[
    \begin{array}{lll}
        \text{Values} & v & \Coloneqq \ldots \vor \Lambda \graybox{\overline{l}}\ap\overline{\alpha}\ldotp v \vor K\ap\graybox{\overline{\Delta}}\ap\overline{\tau}\ap\overline{v} \vor \ldots \\
        \text{Terms} & t, u &\Coloneqq \ldots \vor t\ap\graybox{\overline{\Delta}}\ap\overline{\tau} \vor handle ~ x : T \ap\graybox{local}\ap \overline{\tau} ~with ~h~in ~t \vor \ldots
    \end{array}
\]

\subsection{Typing rules for $Core_\Delta$}

Let us highlight some of the key aspects of the typing rules (fig.\ \ref{fig:core-delta-typing}):
\begin{itemize} % todo make rule names explicit for other enumerations as well
    \item \textbf{Lam:} The typing rule for $\lambda$-abstractions guarantees that no tracked value can escape the scope of the function via its return value.
    Analogous to the treatment of data constructors, the lifetime associated with a function type is determined as the intersection of the lifetimes of all captured variables.
    This ensures that the function itself cannot outlive any tracked resources it closes over.
    \item \textbf{Match:} Lifetime parameters appearing in positive positions are conservatively approximated by the lifetime of the enclosing composite data type.
    Since data types are covariant with respect to their lifetime parameters, lifetimes appearing in negative positions are replaced with the bottom lifetime \texttt{free}, analogous to covariant projections. % todo link to covariant projections
    \item \textbf{Handle:} The $Handle$ rule plays crucial role in ensuring effect safety.
    First, it annotates capabilities created within the handler with the lifetime label \texttt{local} and prohibits occurrences of \texttt{local} in positive positions within the result type $\eta$.
    This restriction prevents capabilities from escaping the handler’s scope via returned values.
    Second, the rule enforces a well-formedness condition on effect signatures to ensure that no capabilities are passed as arguments to operation calls.
    Without this constraint, a capability introduced by an inner handler could be propagated to an operation in an outer handler, thus escaping its scope.
    This restriction can be relaxed under certain conditions; further discussion is provided in Section. % todo ref
    \item \textbf{TypesOf:} This rule extracts the types of designated variables from the typing context without discriminating between ordinary bindings and contextual bindings.
\end{itemize}

%! suppress = EscapeAmpersand
\begin{figure}
    \begin{gather*}
        \mathframebox{\Gamma\vdash t : \tau} \\
        \begin{array}{cc}
            \infer[Var]{
                \Gamma\vdash x\ap\overline{\Delta}\ap\overline{\tau} : [\overline{l\to\Delta}]\ap[\overline{\alpha\to\tau}]\ap\sigma
            }{
                x : \forall\overline{l}\ap(\overline{\alpha <: \tau'})\ldotp \sigma \in \Gamma &
                \Gamma\vdash\tau <: [\overline{l\to\Delta}]\ap\tau'
            }
            &
            \infer[CVar]{\Gamma\vdash x : \tau}{x :_c \tau \in \Gamma}
        \end{array}
        \\
        \infer[Lam]{
            \Gamma\vdash \lambda \overline{x : \sigma} ~ \overline{y : \sigma'} \ldotp t : ctx(\overline{\sigma}) \left(\&{\overline{lt_+(\tau)}}\right)~ \overline{\sigma'} \to \eta
        }{
            \overline{x :_c \sigma}, \overline{y : \sigma'}, \Gamma\vdash t : \eta &
            \Gamma\vdash_{fv(t)}\overline{\tau} &
            local\not\in lt_+(\eta)
        } \\
        \infer[App]{
            \Gamma\vdash t \ap \overline{u_1} \ap \overline{u_2} : \eta
        } {
            \Gamma\vdash t : \ctx{\overline{\tau}} \Delta~\overline{\sigma}\to\eta
            &
            \begin{array}{c}
                \overline{\Gamma\vdash u_1 : \tau'} \\
                \overline{\Gamma\vdash\tau' <: \tau}
            \end{array}
            &
            \begin{array}{c}
                \overline{\Gamma\vdash u_2 : \sigma'} \\
                \overline{\Gamma\vdash\sigma' <: \sigma}
            \end{array}
        }\\
        \infer[Match]{
            \Gamma\vdash match ~ t ~with ~\{ \overline{K_i\ap \overline{x_j} \to u_i }\}  : \eta
        }{
            \begin{array}{c}
                K_i : \forall \overline{l}~\overline{\alpha}\ldotp \overline{\sigma_j} \to T\ap(\&\overline{lt_+(\sigma)})\ap\overline{\alpha}
                \text{\hspace{1em}}
                \Gamma\vdash t : T\ap\Delta \ap\overline{\tau}
                \\
                \overline{x_j : [\overline{\alpha\to\tau}, \overline{flt_+(\sigma_j)\to\Delta}, \overline{flt_{-}(\sigma_j)\to free}]\ap \sigma_j}, \Gamma \vdash u_i : \eta
            \end{array}
        }\\
        \infer[Perform]{
            \Gamma\vdash perform \ap op\ap \overline{\tau_2}\ap x\ap \overline{t} : \theta\ap\eta
        }{
            \begin{array}{ccc}
                \Sigma(T) = \forall\overline{\alpha}\ldotp sig &
                \Gamma\vdash x : T\ap \Delta \ap \overline{\tau_1} &
                \overline{\Gamma\vdash t : \sigma'}
                \\
                op : \forall\overline{\beta}\ldotp \overline{\sigma}\to\eta \in sig &
                \theta = [\overline{\alpha\to\tau_1}, \overline{\beta\to\tau_2}] &
                \overline{\Gamma\vdash\sigma' <: \theta\ap\sigma}
            \end{array}
        }\\
        \infer[Handle]{
            \Gamma \vdash handle ~ x : T\ap\overline{\tau}~ with ~ \{\overline{op_i = t_i}\} ~in~u : \eta
        }{
            \begin{array}{ccc}
                x :_c T\ap local\ap\overline{\tau}, \Gamma\vdash u : \eta & \overline{\beta}\not\cap ftv(\eta) & % todo beautify intersection
                \Sigma(T) = \forall\overline{\alpha}\ldotp sig \hspace{1em} op_i : \forall\overline{\beta}\ldotp \overline{\sigma}_i\to\sigma'_i \in sig
                \\
                local \not\in lt_+(\eta)\cup\overline{lt_+(\sigma)} & \theta = [\overline{\alpha\to\tau}] &
                \Gamma\vdash\theta\ap t_i : \forall \overline{\beta}\ldotp \overline{\theta\ap\sigma_i}\to(\theta\ap\sigma_i'\to\eta)\to\eta
            \end{array}
        }\\
        \infer[Cap]{
            \Gamma\vdash K_{cap}\ap\overline{\tau}\ap m\ap h : T\ap local \ap\overline{\tau}
        }{
            K_{cap} : \forall\overline{\alpha}\ldotp sig\to T\ap\overline{\alpha} \in \Sigma
        }
        \hspace{2em}
        \infer[Handler]{
            \Gamma\vdash handler_m ~t : \tau
        }{
            \Gamma\vdash t : \tau
        }\\
        \begin{array}{cccc}
            \mathframebox{\Gamma\vdash t : s} &
            \infer[TLam]{
                \Gamma\vdash\Lambda\overline{l}\ap\overline{(\alpha <: \sigma)}\ldotp v : \forall\overline{l}\ap\overline{(\alpha <: \sigma)}\ldotp\tau
            }{
                \overline{\alpha <: \sigma}, \Gamma\vdash v : \tau & flt(\tau) = \overline{l} & ftv(\tau) = \overline{\alpha}
            } &
            \mathframebox{\Gamma\vdash_{\overline{x}}\overline{\tau}}
            &
            \infer[TypesOf]{\Gamma\vdash_{\overline{x}}\overline{\tau}}{\overline{x :_\cdot \tau} \subset \Gamma}
        \end{array} \\
        \begin{array}{ccc}
            \mathframebox{\Gamma\vdash p} &
            \infer[\epsilon Prog]{\Gamma\vdash\epsilon}{} &
            \infer[Prog]{\Gamma\vdash x : s = t, p}{\Gamma\vdash t : s & \Gamma\vdash p}
        \end{array}\\
        \begin{array}{cccc}
            \mathframebox{\Gamma\vdash \sigma <: \tau} &
            \infer[SubAny]{\Gamma\vdash \sigma <: Any\ap local}{} &
            \infer[SubT]{\Gamma\vdash T\ap\Delta' <: T\ap\Delta}{\Delta' <: \Delta} &
            \infer[SubBound]{\Gamma\vdash \alpha <: \tau}{\alpha <: \tau \in \Gamma}
        \end{array} \\
        \begin{array}{cccc}
            \mathframebox{\Delta' <: \Delta} &
            \infer[SubFree]{free <: \Delta}{} &
            \infer[SubLocal]{\Delta <: local}{} &
            \infer[Sub\&]{\Delta' <: \&\overline{\Delta}}{local\in\overline{\Delta}}
        \end{array}
    \end{gather*}
    \caption{Typing rules for $Core_{\Delta}$}
    \label{fig:core-delta-typing}
\end{figure}

\subsection{Lifetime tunnelling}



TODO % todo reduce amount of boilerplate for polymorphic code
% todo bounds instead of boxing (from capturing types)
% todo why tunelling (otherwise too much code duplication on polymorphic code)
% todo resources that can leak
% todo невозможность отсылать локальные вещи операциям это слишком жестко, нужно ослабить, иначе даже в массив сложит трекаемые вещи в одном скоупе не получится
% todo lifetimes in the middle instead of `here` mode (to allow handlers consume tracked things)

\subsection{Integration with implicit parameters}

TODO % todo
% todo \overline{\sigma} \text{ distinct} &

\subsection{Using effects with tracked values}

TODO % todo



%todo \cite{hannan1998type, boruch2023capturing}

% todo future work: higher-ranked types, type inference
% todo higher-rank polymorphism is required for lambdas, иначе ничего не будет работать с абстракцией по хендлерам. Хотя можно просто всё сделать локалом в контексте по умолчанию, но тогда могут быть траблы с кепчурингом. Нужно исследовать, можно ли это как-то попроще добавить.

% todo some safety theorem


\section{Adoption in mainstream languages} \label{sec:mainstream}

% todo every method is a higher-order function (see citatioon in Capturing types)

\subsection{Simplifying lifetime polymorphism} \label{subsec:lifetime-elision}

% todo OOP
% todo escape hatches

TODO % todo

\subsection{Escaping from an effect system}

% todo unsafe escape hatches



TODO % todo

\subsection{Migrating to an effect system}

TODO % todo

\subsection{Working with OOP}



TODO % todo


% todo abstraction inference
% todo bidirectional semantics and higher-order effects


\section{Related work} \label{sec:related}

% todo capture calculus boxing

% todo row-types
% todo capability-based, Scala
% todo modal effect types
% todo coeffects, coeffect style vs effect style
% todo papers about regions?

TODO % todo

% todo type inference and symilarity with first-class polymorphism


\section{Conclusion} \label{sec:conclusion}

TODO % todo


%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
\begin{acks}
    TODO % todo
\end{acks}

% TODO appendix с полным исчислением

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
% todo add links where possible for convenience of readers
\bibliographystyle{ACM-Reference-Format}
\bibliography{bib}

\end{document}
